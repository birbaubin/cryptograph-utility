{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from deeprobust.graph.defense import GCN\n",
    "from deeprobust.graph.targeted_attack import FGA\n",
    "from deeprobust.graph.utils import *\n",
    "from deeprobust.graph.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from experiments import split_dataset\n",
    "from DistributedDefense import TwoPartyCNGCN\n",
    "import networkx as nx\n",
    "from scipy.sparse import csr_matrix\n",
    "import mahsa_backdoor as backdoor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random # for random choice of nodes\n",
    "import logging # for logging file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ split adjacency matrixes and find nodes which have changes##########################\n",
    "# Set up seeds\n",
    "seed = 42  # Seed for reproducibility\n",
    "# Function to set seeds for reproducibility\n",
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(filename='results.log', filemode='w', level=logging.INFO, format='%(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "\n",
    "################################ Data loading- features-test #######################################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "dataset = \"polblogs\"\n",
    "# Use the current directory for windows\n",
    "data = Dataset(root='.', name=dataset, setting='gcn')\n",
    "#data = Dataset(root='/tmp/', name=dataset): this is for unix-based systems\n",
    "\n",
    "#############################  preprocessing ############################\n",
    "adj, features, labels = data.adj, data.features, data.labels\n",
    "idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "# print (\"adj shape: \", adj.shape)\n",
    "# print (\"features shape: \", features.shape)\n",
    "# print (\"labels shape: \", labels.shape)  \n",
    "# print (features)\n",
    "\n",
    "\n",
    "# Split graph into two subgraphs for Crypto'Graph: by randomly removing some edges.but the nodes are the same\n",
    "proportion_of_common_links = 0.5\n",
    "adj1, adj2 = split_dataset(adj, proportion_of_common_links) \n",
    "\n",
    "print (\"adj1 shape: \", adj1.shape)\n",
    "print (\"adj2 shape: \", adj2.shape)\n",
    "\n",
    "\n",
    "# Assuming adj1 and adj2 are your adjacency matrices\n",
    "# Step 1: Check dimensions\n",
    "if adj1.shape != adj2.shape:\n",
    "    print(\"Matrices have different dimensions.\")\n",
    "else:\n",
    "    # Step 2: Find differences\n",
    "    differences = np.abs(adj1 - adj2)\n",
    "    \n",
    "    # Step 3: Count differences\n",
    "    total_differences = np.sum(differences)\n",
    "    print(f\"Total number of differences: {total_differences}\")\n",
    "    \n",
    "    # Count non-zero differences (i.e., actual changes)\n",
    "    # changes = np.count_nonzero(differences)\n",
    "    # print(f\"Number of elements that differ: {changes}\")\n",
    "    \n",
    "    # Step 4: Count rows\n",
    "    rows = adj1.shape[0]\n",
    "    print(f\"adj1. Number of rows: {rows}\")\n",
    "    rows_adj2= adj2.shape[0]\n",
    "    print(f\"adj2. Number of rows: {rows_adj2}\")\n",
    "\n",
    "    # Identify rows with changes\n",
    "    rows_with_changes = np.count_nonzero(np.sum(differences, axis=1))\n",
    "    print(f\"Number of rows with changes: {rows_with_changes}\")\n",
    "\n",
    "    # Print out the specific rows with changes\n",
    "    changed_rows = np.where(np.sum(differences, axis=1) > 0)[0]\n",
    "    print(f\"Rows with different connectivities: {changed_rows}\")\n",
    "    # f.write(f\"Rows with different connectivities: {changed_rows}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Visualization of the adjacency matrix and check if it is weighted or not\n",
    "adj1_dense = adj1.toarray()\n",
    "# print(adj1_dense)\n",
    "\n",
    "plt.imshow(adj1_dense, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "adj2_dense = adj2.toarray()\n",
    "plt.imshow(adj2_dense, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# Print the first 10x10 submatrix of the adjacency matrix\n",
    "print(adj1_dense[:10, :10])\n",
    "print(adj2_dense[:10, :10])\n",
    "\n",
    "# Check if the adjacency matrix is weighted or not\n",
    "def is_weighted(adj_matrix):\n",
    "    # Flatten the matrix to a 1D array for easy iteration\n",
    "    flat_matrix = adj_matrix.flatten()\n",
    "    # Check if all values are 0 or 1\n",
    "    return not np.all(np.logical_or(flat_matrix == 0, flat_matrix == 1))\n",
    "print(\"The adj1 is weighted:\", is_weighted(adj1_dense))\n",
    "print(\"The adj2 is weighted:\", is_weighted(adj2_dense))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### check only main adj matrix################\n",
    "\n",
    "node_id = 4\n",
    "adj_dense = adj.toarray()\n",
    "# adj2_dense = adj2.toarray()\n",
    "row_adj = adj_dense[node_id, :]  # Get the row for node_id from adj1\n",
    "# row_adj2 = adj2_dense[node_id, :]  # Get the row for node_id from adj2\n",
    "\n",
    "print(f\"Node {node_id} connectivities in adj: {row_adj}\")\n",
    "print(f\"Node {node_id} connectivities in adj: {[f'index {i}: value {v}' for i, v in enumerate(row_adj)]}\")\n",
    "print(f\"Node {node_id} connectivities in adj with value 1.0: {[f'index {i}: value {v}' for i, v in enumerate(row_adj) if v == 1.0]}\")\n",
    "\n",
    "gr = nx.from_scipy_sparse_array(adj)\n",
    "print(f\"adj is \",gr)\n",
    "\n",
    "# Directly compare edges for node 0 in both graphs\n",
    "edges_gr = set(gr.edges(node_id))\n",
    "print(f\"Edges of node {node_id} in gr: {edges_gr}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################  check the differences between adj1 and adj2 ############################\n",
    "# Adjust numpy print options to show full arrays\n",
    "# np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "node_id = 4\n",
    "adj1_dense = adj1.toarray()\n",
    "adj2_dense = adj2.toarray()\n",
    "row_adj1 = adj1_dense[node_id, :]  # Get the row for node_id from adj1\n",
    "row_adj2 = adj2_dense[node_id, :]  # Get the row for node_id from adj2\n",
    "\n",
    "# row_adj1 = adj1[node_id, :].toarray().flatten().tolist()  # Get the row for node_id from adj1\n",
    "# row_adj2 = adj2[node_id, :].toarray().flatten().tolist()  # Get the row for node_id from adj2\n",
    "# differences_for_node = row_adj1 != row_adj2\n",
    "# different_indices = np.where(differences_for_node)[0]  # Indices of differences\n",
    "\n",
    "differences_for_node = row_adj1 != row_adj2\n",
    "different_indices = np.where(differences_for_node)[0]\n",
    "\n",
    "# print(f\"Node {node_id} connectivities in adj1: {row_adj1}\")\n",
    "print(f\"Node {node_id} connectivities in adj1: {[f'index {i}: value {v}' for i, v in enumerate(row_adj1)]}\")\n",
    "# print(f\"Node {node_id} connectivities in adj2: {row_adj2}\")\n",
    "print(f\"Node {node_id} connectivities in adj2: {[f'index {i}: value {v}' for i, v in enumerate(row_adj2)]}\")\n",
    "print(f\"Differences for node {node_id}: {differences_for_node}\")\n",
    "print(f\"Indices with differences for node {node_id}: {different_indices}\")\n",
    "print(f\"only differences for node {node_id} in adj1: {[f'index {i}: value {v}' for i, v in enumerate(row_adj1) if differences_for_node[i]]}\")\n",
    "print(f\"only differences for node {node_id} in adj2: {[f'index {i}: value {v}' for i, v in enumerate(row_adj2) if differences_for_node[i]]}\")\n",
    "\n",
    "\n",
    "print(f\"Node {node_id} connectivities in adj1 with value 1.0: {[f'index {i}: value {v}' for i, v in enumerate(row_adj1) if v == 1.0]}\")\n",
    "print(f\"Node {node_id} connectivities in adj2 with value 1.0: {[f'index {i}: value {v}' for i, v in enumerate(row_adj2) if v == 1.0]}\")\n",
    "\n",
    "# logger.info(f\"Total number of differences: {total_differences}\")\n",
    "# logger.info(\"Node %s connectivities in adj1: %s\", node_id, row_adj1)\n",
    "# logger.info(\"Node %s connectivities in adj2: %s\", node_id, row_adj2)\n",
    "# logger.info(\"Differences for node %s: %s\", node_id, differences_for_node)\n",
    "# logger.info(\"Indices with differences for node %s: %s\", node_id, np.where(differences_for_node)[0])\n",
    "\n",
    "\n",
    "# Ensure adj1 and adj2 are in sparse format\n",
    "adj1 = sp.csr_matrix(adj1)\n",
    "adj2 = sp.csr_matrix(adj2)\n",
    "\n",
    "# Convert adjacency matrices to networkx graphs\n",
    "gr1 = nx.from_scipy_sparse_array(adj1)\n",
    "print(f\"after convert nx adj1 is \",gr1)\n",
    "gr2 = nx.from_scipy_sparse_array(adj2)\n",
    "print(f\"after convert nx adj2 is \",gr2)\n",
    "\n",
    "# Directly compare edges for node 0 in both graphs\n",
    "edges_gr1 = set(gr1.edges(node_id))\n",
    "edges_gr2 = set(gr2.edges(node_id))\n",
    "print(f\"Edges of node {node_id} in gr1: {edges_gr1}\")\n",
    "print(f\"Edges of node {node_id} in gr2: {edges_gr2}\")\n",
    "\n",
    "\n",
    "# Function to filter out zero-weight edges\n",
    "def filter_edges_with_weight(graph, node_id):\n",
    "    return set((u, v) for u, v, d in graph.edges(node_id, data=True) if d.get('weight', 1) > 0)\n",
    "\n",
    "# Directly compare edges for a specific node\n",
    "edges_gr1_filtered = filter_edges_with_weight(gr1, node_id)\n",
    "edges_gr2_filtered = filter_edges_with_weight(gr2, node_id)\n",
    "print(f\"Filtered edges of node {node_id} in gr1: {edges_gr1_filtered}\")\n",
    "print(f\"Filtered edges of node {node_id} in gr2: {edges_gr2_filtered}\")\n",
    "\n",
    "edges_gr1 = list(gr1.edges(node_id, data=True))\n",
    "edges_gr2 = list(gr2.edges(node_id,data=True))\n",
    "print(f\"Edges in gr1: {edges_gr1}\")\n",
    "print(f\"Edges in gr2: {edges_gr2}\")\n",
    "\n",
    "\n",
    "# Check for differences\n",
    "if edges_gr1 != edges_gr2:\n",
    "    print(\"Differences found in edges.\")\n",
    "else:\n",
    "    print(\"No differences found in edges.\")\n",
    "\n",
    "\n",
    "# Check if gr1 is directed or undirected\n",
    "if gr1.is_directed():\n",
    "    print(\"gr1 is a directed graph.\")\n",
    "else:\n",
    "    print(\"gr1 is an undirected graph.\")\n",
    "# Check if gr2 is directed or undirected\n",
    "if gr2.is_directed():\n",
    "    print(\"gr2 is a directed graph.\")\n",
    "else:\n",
    "    print(\"gr2 is an undirected graph.\")\n",
    "\n",
    "\n",
    "# Check if adjacency matrices are symmetric - if they are symmentirc graph is undirected \n",
    "def is_symmetric(matrix):\n",
    "    return np.array_equal(matrix, matrix.T)\n",
    "symmetry_check_adj1 = is_symmetric(adj1_dense)\n",
    "symmetry_check_adj2 = is_symmetric(adj2_dense)\n",
    "print(f\"adj1 is symmetric: {symmetry_check_adj1}\") # true or false\n",
    "print(f\"adj2 is symmetric: {symmetry_check_adj2}\")\n",
    "\n",
    "\n",
    "############## solution\n",
    "# # Function to remove zero-weight edges from an adjacency matrix\n",
    "# def remove_zero_weight_edges(adj):\n",
    "#     adj.data[adj.data == 0] = 0\n",
    "#     adj.eliminate_zeros()\n",
    "#     return adj\n",
    "\n",
    "# Remove zero-weight edges\n",
    "clean_adj1 = backdoor.remove_zero_weight_edges(adj1.copy())\n",
    "clean_adj2 = backdoor.remove_zero_weight_edges(adj2.copy())\n",
    "\n",
    "# Convert cleaned adjacency matrices to networkx graphs\n",
    "graph1 = nx.from_scipy_sparse_array(clean_adj1)\n",
    "graph2 = nx.from_scipy_sparse_array(clean_adj2)\n",
    "\n",
    "\n",
    "neighbors_gr1 = list(graph1.neighbors(node_id))\n",
    "print(f\"Neighbors of node {node_id} in gr1: {neighbors_gr1}\")\n",
    "neighbors_gr2 = list(graph2.neighbors(node_id))\n",
    "print(f\"Neighbors of node {node_id} in gr2: {neighbors_gr2}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# V0: adding edges - Attack repeatedly - consider crypto'Graph ###############################\n",
    "# Define the number of repeats\n",
    "num_repeats = 1\n",
    "accuracy_test_attack_1_values = []\n",
    "accuracy_test_clean_1_values = []\n",
    "accuracy_test_attack_2_values = []\n",
    "accuracy_test_clean_2_values = []\n",
    "accuracy_test_attack_3_values = []\n",
    "accuracy_test_clean_3_values = []\n",
    "\n",
    "seed = 42  # Seed for reproducibility\n",
    "# Function to set seeds for reproducibility\n",
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "################################ Data loading #######################################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "dataset = \"polblogs\"\n",
    "# Use the current directory for windows\n",
    "data = Dataset(root='.', name=dataset , setting='gcn', seed=15)   \n",
    "# setting='gcn' is for the GCN model, in latest experiments befor 2024-06-11 used default which is nettack\n",
    "# seed=15 is for the GCN model, in latest experiments befor 2024-06-11 no seeds were used. seed is used to make the results reproducible\n",
    "#data = Dataset(root='/tmp/', name=dataset): this is for unix-based systems\n",
    "\n",
    "\n",
    "for _ in range(num_repeats):\n",
    "    \n",
    "    #############################  preprocessing ############################\n",
    "    set_seeds(seed)\n",
    "    adj, features, labels = data.adj, data.features, data.labels\n",
    "    idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "    #split idx_test into two parts randomly\n",
    "    # test_size = 0.10  # 10% for test_attack, 90% for test_clean\n",
    "    # idx_test_clean , idx_test_attack = train_test_split(idx_test, test_size=test_size, random_state=seed)\n",
    "\n",
    "    #split idx_test into two parts : one node for attack and the rest for clean\n",
    "    # test_size = 1  # 1 node for attack others for test_clean\n",
    "    # idx_test_clean , idx_test_attack = train_test_split(idx_test, test_size=test_size, random_state=42)\n",
    "    # selected_node = idx_test_attack[0]\n",
    "    # print(f\"Selected node for attack: {selected_node}\")\n",
    "\n",
    "    #choose a node for attack manually (the one which has been chosen randomely from idx_test in the previous part)\n",
    "    selected_node = 1196\n",
    "    idx_test_attack = np.array([selected_node])\n",
    "    idx_test_clean = np.array([node for node in idx_test if node != selected_node])\n",
    "\n",
    "    # print (\"idx_test_clean\",len (idx_test_clean))\n",
    "    # print (\"idx_test_attack\",len (idx_test_attack))\n",
    "    # print (f\"idx_test_attack\",idx_test_attack)\n",
    "    # print (f\"idx_test_clean\",idx_test_clean)\n",
    "    # print (\"idx_test\",len (idx_test))\n",
    "    # print (\"train\",len (idx_train))\n",
    "    # print (idx_train)\n",
    "    # print (\"val\",len (idx_val))\n",
    "\n",
    "\n",
    "# Split graph into two subgraphs for Crypto'Graph: by randomly removing some edges.but the nodes are the same\n",
    "    proportion_of_common_links = 0.5\n",
    "    adj1, adj2 = split_dataset(adj, proportion_of_common_links) \n",
    "\n",
    "    print (\"adj1 shape: \", adj1.shape)\n",
    "    print (\"adj2 shape: \", adj2.shape)\n",
    "\n",
    "    print (\"adj shape: \", adj.shape)\n",
    "    print (\"features shape: \", features.shape)\n",
    "    print (\"labels shape: \", labels.shape)\n",
    "   \n",
    "    #check neighbors of the selected node\n",
    "    neighbors_vector = adj1[selected_node, :].toarray()\n",
    "    neighbors_indices = np.nonzero(neighbors_vector)[1]  #  Get the indices of the neighbors\n",
    "    print(f\"num of neighbors of node {selected_node} is: {len(neighbors_indices)}\")\n",
    "    print(\"Neighbors of node\", selected_node, \"are:\", neighbors_indices)\n",
    "\n",
    "\n",
    "    # Ensure adj1 and adj2 are in sparse format\n",
    "    adj1 = sp.csr_matrix(adj1)\n",
    "    adj2 = sp.csr_matrix(adj2)\n",
    "    # Remove zero-weight edges\n",
    "    clean_adj1 = backdoor.remove_zero_weight_edges(adj1.copy())\n",
    "    clean_adj2 = backdoor.remove_zero_weight_edges(adj2.copy())\n",
    "    # Convert cleaned adjacency matrices to networkx graphs\n",
    "    graph1 = nx.from_scipy_sparse_array(clean_adj1)\n",
    "    graph2 = nx.from_scipy_sparse_array(clean_adj2)\n",
    "\n",
    "   \n",
    "    ############################ train model initially and test accuracy ###########################\n",
    "    # Perform evaluation before attack to find the baseline accuracy\n",
    "\n",
    "    # Train GCN model \n",
    "    # 1. Model definition\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    # 2. Train model - patience= number of epochs to wait before early stopping , train_iters= number of iterations\n",
    "    model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    #model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200,metric=metric,\n",
    "               #object=object, initialize=True, verbose=False )\n",
    "    # 3. Evaluate model\n",
    "    model.eval()\n",
    "    output = model.test(idx_test)\n",
    "    #acc_test = accuracy(output, labels, idx_test)\n",
    "\n",
    "    accuracy_test_attack_1 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_1 = model.test(idx_test_clean)\n",
    "\n",
    "    print(\"Test accuracy on attack set: \", accuracy_test_attack_1)\n",
    "    print(\"Test accuracy on clean set: \", accuracy_test_clean_1)\n",
    "\n",
    "    ################################ Mahsa attack ##############################\n",
    "    # Perform the attack\n",
    "    # version 0: attack on the whole graph - on idx_test_attack nodes\n",
    "\n",
    "    modified_adj1 =  clean_adj1.copy()\n",
    "    # modified_adj1 =  adj2.copy()\n",
    "\n",
    "    # Create a NetworkX graph from the adjacency matrix\n",
    "    graph = nx.from_scipy_sparse_array(modified_adj1)\n",
    "\n",
    "\n",
    "    # Add labels to the graph\n",
    "    for node_id, label in enumerate(labels):\n",
    "        graph.nodes[node_id]['label'] = label\n",
    "    # print(f\"lenght of the labels : {len(labels)}\") \n",
    "    print(f\"graph edges : {graph.number_of_edges()}\")\n",
    "    print(f\"graph nodes : {graph.number_of_nodes()}\")\n",
    "    print(\"*************** mahsa attack ***************\")\n",
    "    # Set the budget for the attack\n",
    "    budget = 90\n",
    "\n",
    "    #attacked_graph is initially set to graph, and then updated after each attack\n",
    "    # This means that each attack is performed on the graph resulting from the previous attacks.\n",
    "    attacked_graph = graph\n",
    "    for target_node in idx_test_attack:\n",
    "        non_neighbor_opposit = backdoor.find_non_neighbor_opposit_label(attacked_graph, target_node)\n",
    "        max_same_min_opposit_label_neighbors = backdoor.find_max_same_min_opposit_label_neighbors(attacked_graph, non_neighbor_opposit)\n",
    "        nodes_for_attack = backdoor.nodes_for_attack(attacked_graph, target_node, max_same_min_opposit_label_neighbors, budget)\n",
    "        attacked_graph = backdoor.insert_edge(attacked_graph, target_node, nodes_for_attack)\n",
    "        backdoor.evaluate_graph(attacked_graph, nodes_for_attack, target_node, budget)\n",
    "        \n",
    "    print(attacked_graph)\n",
    "    print(f\"total inserted edges : {attacked_graph.number_of_edges() - graph.number_of_edges()}\")\n",
    "\n",
    "    # check for the differences between the initial graph and the attacked graph----- adj wise\n",
    "    # Convert the graph to a CSR matrix\n",
    "    modified_adj1 =backdoor.convert(attacked_graph)\n",
    "    #compare adjs check\n",
    "    diff_adj_attack = modified_adj1 - clean_adj1\n",
    "    non_zero_diff = diff_adj_attack.nonzero()\n",
    "    print(f\"adj wise : modifications after attack: {non_zero_diff}\")\n",
    "    # Count the number of changes\n",
    "    num_changes = len(non_zero_diff[0])/2\n",
    "    print(f\"adj wise: Number of modifications after attack: {num_changes}\")\n",
    "    \n",
    "    # compare graphs check\n",
    "    initial_edges = graph.number_of_edges()\n",
    "    attacked_edges = attacked_graph.number_of_edges()\n",
    "    print(f\"graph check : Initial edges: {initial_edges} and attacked edges: {attacked_edges}\")\n",
    "    print(f\"graph check: Total inserted edges after attack: {attacked_edges - initial_edges}\")\n",
    "    \n",
    "    n1=list(graph.neighbors(selected_node))\n",
    "    print(f\"{selected_node} has {len(n1)} neighbors ofter attack and they are: {n1}\")\n",
    "    n2=list(attacked_graph.neighbors(selected_node))\n",
    "    print(f\"{selected_node} has {len(n2)} neighbors ofter attack and they are: {n2}\")\n",
    "\n",
    "    ################################ evaluation after attack ##############################\n",
    "    # accuracy after attack\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    #data = data.to(device)\n",
    "    model.fit(features, modified_adj1, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    model.eval()\n",
    "\n",
    "    accuracy_test_attack_2 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_2 = model.test(idx_test_clean)\n",
    "\n",
    "    print(\"Test accuracy on attack set: \", accuracy_test_attack_2)\n",
    "    print(\"Test accuracy on clean set: \", accuracy_test_clean_2)\n",
    "\n",
    "    ############################ Crypto'Graph defense ###########################\n",
    "    # Perform Crypto'Graph distributed defense\n",
    "    print(\"*************** Crypto'Graph defense ***************\")\n",
    "\n",
    "    threshold = 2               # threshold for dropping dissimilar edges\n",
    "    metric = \"neighbors\"        # metric for dropping dissimilar edges (neighbors, jaccard, cosine)\n",
    "    object = \"links\"            # object for defense (links, features)\n",
    "\n",
    "    model = TwoPartyCNGCN(dataset=dataset, nfeat=features.shape[1], nhid=16, nclass=labels.max().item() + 1,\n",
    "                            device=device)\n",
    "    defense_duration, defense_duration, training_duration1, training_duration2, CG_defended_adj1, CG_defended_adj2 = model.fit(modified_adj1.copy(), adj2.copy(), \n",
    "                features, features, labels, idx_train, threshold, metric=metric, object=object,\n",
    "                train_iters=200, initialize=True, verbose=False, idx_val=idx_val)\n",
    "    model.eval()\n",
    "    accuracies = model.test(idx_test)  #accuracy of the model after the defense on all the test data - (all the nodes)\n",
    "    accuracy_test_attack_3 = model.test(idx_test_attack)\n",
    "    accuracy_test_clean_3 = model.test(idx_test_clean)\n",
    "    print(\"Test accuracy on attack set: \", accuracy_test_attack_3)\n",
    "    print(\"Test accuracy on clean set: \", accuracy_test_clean_3)\n",
    "\n",
    "\n",
    "\n",
    "    rows = CG_defended_adj1.shape[0]\n",
    "    print(f\"CG_defended_adj1. Number of rows: {rows}\")\n",
    "   \n",
    "    \n",
    "    ################# adj wise compare by adj1 and modified_adj1 (before and after defense)\n",
    "    print(\"*************** adj wise compare (before and after defense) ***************\")\n",
    "    differences = np.abs(CG_defended_adj1 - modified_adj1)\n",
    "    total_differences = np.sum(differences)\n",
    "    # print(f\"adj check: differences: {differences}\")\n",
    "    print(f\"adj check: Total number of differences: {total_differences}\")\n",
    "    rows_with_changes = np.count_nonzero(np.sum(differences, axis=1))\n",
    "    print(f\"Number of rows with changes: {rows_with_changes}\")\n",
    "    changed_rows = np.where(np.sum(differences, axis=1) > 0)[0]\n",
    "    print(f\"Rows with different connectivities: {changed_rows}\")\n",
    "\n",
    "\n",
    "    # Compute the difference matrix for the full symmetric matrix\n",
    "    difference_matrix = CG_defended_adj1 - modified_adj1\n",
    "    # Identify the removed edges (negative values in the difference matrix)\n",
    "    removed_edges = np.argwhere(difference_matrix < 0)\n",
    "    # print(\"Removed edges (row, col):\")\n",
    "    # for edge in removed_edges:\n",
    "    #     print(edge)\n",
    "    total_removed_edges = len(removed_edges)\n",
    "    print(f\"Total number of removed edges considering full symetric matrix: {total_removed_edges}\")\n",
    "\n",
    "    # compute the difference matrix for the upper triangle of the symmetric matrix \n",
    "    # Get the indices of the upper triangle of the matrix, excluding the diagonal\n",
    "    rows, cols = np.triu_indices_from(difference_matrix, k=1)\n",
    "    # Select only the upper triangle (excluding diagonal) from the difference matrix\n",
    "    upper_triangle_differences = difference_matrix[rows, cols]\n",
    "    # Identify the removed edges in the upper triangle (negative values)\n",
    "    removed_edges = np.argwhere(upper_triangle_differences < 0)\n",
    "    # Count the total number of removed edges\n",
    "    total_removed_edges = len(removed_edges)\n",
    "    print(f\"Total number of removed edges(adj): {total_removed_edges}\")\n",
    "    # Print the removed edges\n",
    "    # print(\"Removed edges in adjacency matrix (row, col):\")\n",
    "    # for edge in removed_edges:\n",
    "    #     print(edge)\n",
    "\n",
    "\n",
    "   \n",
    "    ################# check exact edges which are removed by CG defense ################\n",
    "    # Identify the edges added during the attack\n",
    "    added_edges = []\n",
    "    modified_adj1_array = modified_adj1.toarray()\n",
    "    clean_adj1_array = clean_adj1.toarray()\n",
    "\n",
    "    rows, cols = np.triu_indices(modified_adj1_array.shape[0], k=1)\n",
    "    for i, j in zip(rows, cols):\n",
    "        if modified_adj1_array[i, j] == 1 and clean_adj1_array[i, j] == 0:\n",
    "            added_edges.append((i, j))\n",
    "    print(f\"Added edges during attack: {added_edges}\")\n",
    "\n",
    "    # Check if the added edges are removed by CG defense\n",
    "    removed_edges_by_CG = []\n",
    "    CG_defended_adj1_array = CG_defended_adj1.toarray()\n",
    "\n",
    "    for edge in added_edges:\n",
    "        i, j = edge\n",
    "        if CG_defended_adj1_array[i, j] == 0:\n",
    "            removed_edges_by_CG.append(edge)\n",
    "    print(f\"Removed edges by CG defense: {removed_edges_by_CG}\")\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ##################  graph wise compare by adj1 and modified_adj1 (before and after defense) \n",
    "    print(\"*************** graph wise compare (before and after defense) ***************\")\n",
    "    # Remove zero-weight edges\n",
    "    modified_adj1_cleaned = backdoor.remove_zero_weight_edges(modified_adj1.copy())\n",
    "    CG_defended_adj1_cleaned = backdoor.remove_zero_weight_edges(CG_defended_adj1.copy())\n",
    "\n",
    "    #Create a NetworkX graph from the adjacency matrix\n",
    "    graph_modified_adj1 = nx.from_scipy_sparse_array(modified_adj1_cleaned) #before defense\n",
    "    graph_CG_1 = nx.from_scipy_sparse_array(CG_defended_adj1_cleaned) # after defense\n",
    "\n",
    "    # print(graph_CG_1)\n",
    "    print(f\"graph graph_modifeid_adj1 before CG: {graph_modified_adj1.number_of_edges()} edges\")\n",
    "    print(f\"graph graph_CG_1 after CG: {graph_CG_1.number_of_edges()} edges\")\n",
    "\n",
    "    # Identify removed edges in the graph\n",
    "    removed_edges_graph = set(graph_modified_adj1.edges()) - set(graph_CG_1.edges())\n",
    "    # Print the removed edges\n",
    "    # print(\"Removed edges in NetworkX graphs (node1, node2):\")\n",
    "    # for edge in removed_edges_graph:\n",
    "    #     print(edge)\n",
    "\n",
    "    # Total number of removed edges\n",
    "    total_removed_edges_graph = len(removed_edges_graph)\n",
    "    print(f\"Total number of removed edges (NetworkX graphs): {total_removed_edges_graph}\")\n",
    "\n",
    "\n",
    "    print(\"*************** graph wise - check if inserted edges are removed ***************\")\n",
    "    # if inserted edges are eremoved or not: NX graphs\n",
    "    inserted_edges = set(attacked_graph.edges()) - set(graph.edges())\n",
    "    # Print inserted edges\n",
    "    print(\"Inserted edges (node1, node2):\")\n",
    "    for edge in inserted_edges:\n",
    "        print(edge)\n",
    "   \n",
    "    # Check if inserted edges have been deleted by Crypto'Graph defense\n",
    "    deleted_inserted_edges = inserted_edges - set(graph_CG_1.edges())\n",
    "\n",
    "    # Print deleted inserted edges\n",
    "    print(\"Deleted inserted edges by Crypto'Graph defense (node1, node2):\")\n",
    "    for edge in deleted_inserted_edges:\n",
    "        print(edge)\n",
    "\n",
    "    # Total number of deleted inserted edges\n",
    "    total_deleted_inserted_edges = len(deleted_inserted_edges)\n",
    "    print(f\"Total number of deleted inserted edges: {total_deleted_inserted_edges}\")\n",
    "\n",
    "    ####another ay : \n",
    "    # Calculate intersection of inserted and removed edges\n",
    "    intersected_edges = inserted_edges.intersection(removed_edges_graph)\n",
    "    # Check if any inserted edge was removed\n",
    "    if intersected_edges:\n",
    "        print(\"Inserted edges that were removed (node1, node2):\")\n",
    "        for edge in intersected_edges:\n",
    "            print(edge)\n",
    "    else:\n",
    "        print(\"No inserted edges were removed.\")\n",
    "        \n",
    "    # At the end of each repeat, append the accuracy values to the lists:\n",
    "    accuracy_test_attack_1_values.append(accuracy_test_attack_1)\n",
    "    accuracy_test_clean_1_values.append(accuracy_test_clean_1)\n",
    "    accuracy_test_attack_2_values.append(accuracy_test_attack_2)\n",
    "    accuracy_test_clean_2_values.append(accuracy_test_clean_2)\n",
    "    accuracy_test_attack_3_values.append(accuracy_test_attack_3)\n",
    "    accuracy_test_clean_3_values.append(accuracy_test_clean_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# V0 - Plotting ACcuracies #######################################\n",
    "####################### Standard deviation values ############################\n",
    "# Calculate the standard deviation of the accuracy values:\n",
    "accuracy_test_attack_1_std = np.std(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_std = np.std(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_std = np.std(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_std = np.std(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_std = np.std(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_std = np.std(accuracy_test_clean_3_values)\n",
    "\n",
    "# print(\"Standard deviation of test accuracy on attack set 1: \", accuracy_test_attack_1_std)\n",
    "# print(\"Standard deviation of test accuracy on clean set 1: \", accuracy_test_clean_1_std)\n",
    "# print(\"Standard deviation of test accuracy on attack set 2: \", accuracy_test_attack_2_std)\n",
    "# print(\"Standard deviation of test accuracy on clean set 2: \", accuracy_test_clean_2_std)\n",
    "# print(\"Standard deviation of test accuracy on attack set 3: \", accuracy_test_attack_3_std)\n",
    "# print(\"Standard deviation of test accuracy on clean set 3: \", accuracy_test_clean_3_std)\n",
    "\n",
    "# Save the standard deviation values to a file\n",
    "with open('variables_std.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "                 accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "                 accuracy_test_attack_3_std, accuracy_test_clean_3_std], f)\n",
    "\n",
    "\n",
    "####################### Average accuracy values ############################\n",
    "# Calculate the average accuracy values:\n",
    "accuracy_test_attack_1_avg = np.mean(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_avg = np.mean(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_avg = np.mean(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_avg = np.mean(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_avg = np.mean(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_avg = np.mean(accuracy_test_clean_3_values)\n",
    "\n",
    "# print(\"Average test accuracy on attack set 1: \", accuracy_test_attack_1_avg)\n",
    "# print(\"Average test accuracy on clean set 1: \", accuracy_test_clean_1_avg)\n",
    "# print(\"Average test accuracy on attack set 2: \", accuracy_test_attack_2_avg)\n",
    "# print(\"Average test accuracy on clean set 2: \", accuracy_test_clean_2_avg)\n",
    "# print(\"Average test accuracy on attack set 3: \", accuracy_test_attack_3_avg)\n",
    "# print(\"Average test accuracy on clean set 3: \", accuracy_test_clean_3_avg)\n",
    "\n",
    "with open('variables.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "                 accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "                 accuracy_test_attack_3_avg, accuracy_test_clean_3_avg], f)\n",
    "    \n",
    "##################################\n",
    "          \n",
    "labels = ['ACCs before attack', 'ACCs before attack', \n",
    "          'ACCs after attack', 'ACCs after attack', \n",
    "          'ACCs after CryptoGraph', 'ACCs after CryptoGraph']\n",
    "values = [accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "          accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "          accuracy_test_attack_3_avg, accuracy_test_clean_3_avg]\n",
    "std_devs = [accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "            accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "            accuracy_test_attack_3_std, accuracy_test_clean_3_std]\n",
    "\n",
    "# Define the x-coordinates of the bars and the width of the bars\n",
    "x = np.arange(len(labels)//2)\n",
    "width = 0.35\n",
    "\n",
    "# # Create the bar chart\n",
    "# bars1 = plt.bar(x - width/2, values[::2], width, label='Attack set', color='red')\n",
    "# bars2 = plt.bar(x + width/2, values[1::2], width, label='Clean set', color='blue')\n",
    "\n",
    "# Create the bar chart with error bars\n",
    "bars1 = plt.bar(x - width/2, values[::2], width, yerr=std_devs[::2], label='Attack set', color='red', capsize=5)\n",
    "bars2 = plt.bar(x + width/2, values[1::2], width, yerr=std_devs[1::2], label='Clean set', color='blue', capsize=5)\n",
    "\n",
    "# Add a title and labels to the axes\n",
    "plt.title('Average Accuracies')\n",
    "plt.xlabel('Levels of Attack and Defense')\n",
    "plt.ylabel('Average Accuracy')\n",
    "\n",
    "# Make the x-labels vertical\n",
    "plt.xticks(x, labels[::2])\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Add exact values on each bar\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "\n",
    "# Adjust the layout to prevent the labels from being cut off\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Attack one node (adding label) each time to discover node conditions ###############################\n",
    "# Define the number of repeats\n",
    "num_repeats = 1\n",
    "accuracy_test_attack_1_values = []\n",
    "accuracy_test_clean_1_values = []\n",
    "accuracy_test_attack_2_values = []\n",
    "accuracy_test_clean_2_values = []\n",
    "accuracy_test_attack_3_values = []\n",
    "accuracy_test_clean_3_values = []\n",
    "\n",
    "################################ Data loading #######################################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "dataset = \"polblogs\"\n",
    "# Use the current directory for windows\n",
    "data = Dataset(root='.', name=dataset, setting='gcn')\n",
    "#data = Dataset(root='/tmp/', name=dataset): this is for unix-based systems\n",
    "\n",
    "for _ in range(num_repeats):\n",
    "    \n",
    "    #############################  preprocessing ############################\n",
    "    adj, features, labels = data.adj, data.features, data.labels\n",
    "    idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "    #split idx_test into two parts : one node for attack and the rest for clean\n",
    "    # test_size = 1  # 1 node for attack others for test_clean\n",
    "    # idx_test_clean , idx_test_attack = train_test_split(idx_test, test_size=test_size, random_state=42)\n",
    "    # selected_node = idx_test_attack[0]\n",
    "    # print(f\"Selected node for attack: {selected_node}\")\n",
    "\n",
    "    #choose a node for attack manually (the one which has been chosen randomely from idx_test in the previous part)\n",
    "    selected_node = 611\n",
    "    idx_test_attack = np.array([selected_node])\n",
    "    idx_test_clean = np.array([node for node in idx_test if node != selected_node])\n",
    "\n",
    "    # Split graph into two graphs for Crypto'Graph\n",
    "    proportion_of_common_links = 0.5\n",
    "    adj1, adj2 = split_dataset(adj, proportion_of_common_links) \n",
    "\n",
    "   \n",
    "    # print (\"idx_test_clean\",len (idx_test_clean))\n",
    "    # print (\"idx_test_attack\",len (idx_test_attack))\n",
    "    # print (\"idx_test\",len (idx_test))\n",
    "    # print (\"train\",len (idx_train))\n",
    "    # print (\"val\",len (idx_val))\n",
    "\n",
    "    # print (\"idx_test_clean\",idx_test_clean)\n",
    "    # print (\"idx_test_attack\",idx_test_attack)\n",
    "\n",
    "    ############################ tarin model initially and test accuracy ###########################\n",
    "    # Perform evaluation before attack to find the baseline accuracy\n",
    "\n",
    "    # Train GCN model \n",
    "    # 1. Model definition\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    # 2. Train model - patience= number of epochs to wait before early stopping , train_iters= number of iterations\n",
    "    model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    #model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200,metric=metric,\n",
    "               #object=object, initialize=True, verbose=False )\n",
    "    # 3. Evaluate model\n",
    "    model.eval()\n",
    "    output = model.test(idx_test)\n",
    "    #acc_test = accuracy(output, labels, idx_test)\n",
    "\n",
    "    # accuracies = model.test(idx_test) \n",
    "    # print(\"Test accuracy: \", accuracies)\n",
    "\n",
    "    # output_1 = model.test(idx_test_attack)\n",
    "    # output_2 = model.test(idx_test_clean)\n",
    "\n",
    "    accuracy_test_attack_1 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_1 = model.test(idx_test_clean)\n",
    "\n",
    "    print(\"Test accuracy on attack set: \", accuracy_test_attack_1)\n",
    "    print(\"Test accuracy on clean set: \", accuracy_test_clean_1)\n",
    "\n",
    "    \n",
    "    ################################ Mahsa attack ##############################\n",
    "    # Perform the attack\n",
    "    # version 0: attack on the whole graph - on idx_test_attack nodes\n",
    "\n",
    "    modified_adj1 =  adj1.copy()\n",
    "\n",
    "    # Create a NetworkX graph from the adjacency matrix\n",
    "    graph = nx.from_scipy_sparse_array(modified_adj1)\n",
    "\n",
    "    # Add labels to the graph\n",
    "    for node_id, label in enumerate(labels):\n",
    "        graph.nodes[node_id]['label'] = label\n",
    "    # print(f\"lenght of the labels : {len(labels)}\") \n",
    "    print(f\"graph edges : {graph.number_of_edges()}\")\n",
    "    print(f\"graph nodes : {graph.number_of_nodes()}\")\n",
    "    # Set the budget for the attack\n",
    "    budget = 5\n",
    "\n",
    "    #attacked_graph is initially set to graph, and then updated after each attack\n",
    "    # This means that each attack is performed on the graph resulting from the previous attacks.\n",
    "    attacked_graph = graph\n",
    "    for target_node in idx_test_attack:\n",
    "        non_neighbor_opposit = backdoor.find_non_neighbor_opposit_label(attacked_graph, target_node)\n",
    "        max_same_min_opposit_label_neighbors = backdoor.find_max_same_min_opposit_label_neighbors(attacked_graph, non_neighbor_opposit)\n",
    "        nodes_for_attack = backdoor.nodes_for_attack(attacked_graph, target_node, max_same_min_opposit_label_neighbors, budget)\n",
    "        attacked_graph = backdoor.insert_edge(attacked_graph, target_node, nodes_for_attack)\n",
    "        backdoor.evaluate_graph(attacked_graph, nodes_for_attack, target_node, budget)\n",
    "   \n",
    "    print ( f\"idx_test_attack: {idx_test_attack}\")\n",
    "    neighbors_same_label = backdoor.find_same_neighbor(graph, selected_node)\n",
    "    neighbors_opposit_label = backdoor.find_opposit_neighbor(graph, selected_node)\n",
    "    print ( f\"number of target same label neighbors: {len(neighbors_same_label)}\")\n",
    "    print ( f\"number of target opposit label neighbors: {len(neighbors_opposit_label)}\")\n",
    "    print ( f\"idx_test_attack same label neighbors: {neighbors_same_label}\")\n",
    "    print ( f\"idx_test_attack opposit label neighbors: {neighbors_opposit_label}\")\n",
    "    print ( f\"number of target NONE neighbors opposite label: {len(backdoor.find_non_neighbor_opposit_label(graph, selected_node))}\")\n",
    "    print ( f\"idx_test_attack opposit label NONE neighbors: {backdoor.find_non_neighbor_opposit_label(graph, selected_node)}\")\n",
    "\n",
    "    ################################## Plotting target node before attack  #######################################\n",
    "    target_subgraph = graph.subgraph([selected_node] + list(neighbors_same_label) + list(neighbors_opposit_label))\n",
    "    pos = nx.spring_layout(target_subgraph)  # positions for all nodes\n",
    "    # nodes\n",
    "    nx.draw_networkx_nodes(target_subgraph, pos, nodelist=neighbors_same_label, node_color='green')\n",
    "    nx.draw_networkx_nodes(target_subgraph, pos, nodelist=neighbors_opposit_label, node_color='pink')\n",
    "    # edges\n",
    "    nx.draw_networkx_edges(target_subgraph, pos, width=1.0, alpha=0.5)\n",
    "    # labels\n",
    "    nx.draw_networkx_labels(target_subgraph, pos, font_size=16)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "   \n",
    "    # Convert the graph to a CSR matrix\n",
    "    modified_adj1 =backdoor.convert(attacked_graph)\n",
    "    print(attacked_graph)\n",
    "    print(f\"total inserted edges : {(attacked_graph.number_of_edges() - graph.number_of_edges())}\")\n",
    "\n",
    "    ################################ evaluation after attack ##############################\n",
    "    # accuracy after attack\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    #data = data.to(device)\n",
    "    model.fit(features, modified_adj1, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    model.eval()\n",
    "\n",
    "    # output = model.test(idx_test)\n",
    "\n",
    "    #acc_test = accuracy(output, labels, idx_test)\n",
    "\n",
    "    # output_1 = model.test(idx_test_attack)\n",
    "    # output_2 = model.test(idx_test_clean)\n",
    "\n",
    "    accuracy_test_attack_2 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_2 = model.test(idx_test_clean)\n",
    "\n",
    "    print(\"Test accuracy on attack set after attack: \", accuracy_test_attack_2)\n",
    "    print(\"Test accuracy on clean set after attack: \", accuracy_test_clean_2)\n",
    "\n",
    "    ############################ Crypto'Graph defense ###########################\n",
    "    # Perform Crypto'Graph distributed defense\n",
    "\n",
    "    threshold = 2               # threshold for dropping dissimilar edges\n",
    "    metric = \"neighbors\"        # metric for dropping dissimilar edges (neighbors, jaccard, cosine)\n",
    "    object = \"links\"            # object for defense (links, features)\n",
    "\n",
    "    model = TwoPartyCNGCN(dataset=dataset, nfeat=features.shape[1], nhid=16, nclass=labels.max().item() + 1,\n",
    "                            device=device)\n",
    "    model.fit(modified_adj1.copy(), adj2.copy(), features, features, labels, idx_train, threshold, metric=metric, object=object,\n",
    "                train_iters=200, initialize=True, verbose=False, idx_val=idx_val)\n",
    "    model.eval()\n",
    "    accuracies = model.test(idx_test)  #accuracy of the model after the defense on all the test data - (all the nodes)\n",
    "    accuracy_test_attack_3 = model.test(idx_test_attack)\n",
    "    accuracy_test_clean_3 = model.test(idx_test_clean)\n",
    "    print(\"Test accuracy on attack set after Crypto'Graph: \", accuracy_test_attack_3)\n",
    "    print(\"Test accuracy on clean set after Crypto'Graph: \", accuracy_test_clean_3)\n",
    "\n",
    "    # At the end of each repeat, append the accuracy values to the lists:\n",
    "    accuracy_test_attack_1_values.append(accuracy_test_attack_1)\n",
    "    accuracy_test_clean_1_values.append(accuracy_test_clean_1)\n",
    "    accuracy_test_attack_2_values.append(accuracy_test_attack_2)\n",
    "    accuracy_test_clean_2_values.append(accuracy_test_clean_2)\n",
    "    accuracy_test_attack_3_values.append(accuracy_test_attack_3)\n",
    "    accuracy_test_clean_3_values.append(accuracy_test_clean_3)\n",
    "\n",
    "\n",
    "\n",
    "####################### Standard deviation values ############################\n",
    "# Calculate the standard deviation of the accuracy values:\n",
    "accuracy_test_attack_1_std = np.std(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_std = np.std(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_std = np.std(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_std = np.std(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_std = np.std(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_std = np.std(accuracy_test_clean_3_values)\n",
    "\n",
    "# print(\"Standard deviation of test accuracy on attack set 1: \", accuracy_test_attack_1_std)\n",
    "# print(\"Standard deviation of test accuracy on clean set 1: \", accuracy_test_clean_1_std)\n",
    "# print(\"Standard deviation of test accuracy on attack set 2: \", accuracy_test_attack_2_std)\n",
    "# print(\"Standard deviation of test accuracy on clean set 2: \", accuracy_test_clean_2_std)\n",
    "# print(\"Standard deviation of test accuracy on attack set 3: \", accuracy_test_attack_3_std)\n",
    "# print(\"Standard deviation of test accuracy on clean set 3: \", accuracy_test_clean_3_std)\n",
    "\n",
    "# Save the standard deviation values to a file\n",
    "with open('variables_std.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "                 accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "                 accuracy_test_attack_3_std, accuracy_test_clean_3_std], f)\n",
    "\n",
    "\n",
    "####################### Average accuracy values ############################\n",
    "# Calculate the average accuracy values:\n",
    "accuracy_test_attack_1_avg = np.mean(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_avg = np.mean(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_avg = np.mean(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_avg = np.mean(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_avg = np.mean(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_avg = np.mean(accuracy_test_clean_3_values)\n",
    "\n",
    "\n",
    "with open('variables.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "                 accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "                 accuracy_test_attack_3_avg, accuracy_test_clean_3_avg], f)\n",
    "    \n",
    "\n",
    "################################# Plotting Training Results#######################################\n",
    "labels = ['ACCs before attack', 'ACCs before attack', \n",
    "          'ACCs after attack', 'ACCs after attack', \n",
    "          'ACCs after CryptoGraph', 'ACCs after CryptoGraph']\n",
    "values = [accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "          accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "          accuracy_test_attack_3_avg, accuracy_test_clean_3_avg]\n",
    "std_devs = [accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "            accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "            accuracy_test_attack_3_std, accuracy_test_clean_3_std]\n",
    "\n",
    "# Define the x-coordinates of the bars and the width of the bars\n",
    "x = np.arange(len(labels)//2)\n",
    "width = 0.35\n",
    "\n",
    "# Create the bar chart with error bars\n",
    "bars1 = plt.bar(x - width/2, values[::2], width, yerr=std_devs[::2], label='Attack set', color='red', capsize=5)\n",
    "bars2 = plt.bar(x + width/2, values[1::2], width, yerr=std_devs[1::2], label='Clean set', color='blue', capsize=5)\n",
    "\n",
    "# Add a title and labels to the axes\n",
    "plt.title('Average Accuracies')\n",
    "plt.xlabel('Levels of Attack and Defense')\n",
    "plt.ylabel('Average Accuracy')\n",
    "\n",
    "# Make the x-labels vertical\n",
    "plt.xticks(x, labels[::2])\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "# Add exact values on each bar\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "\n",
    "# Adjust the layout to prevent the labels from being cut off\n",
    "plt.tight_layout()\n",
    "# Display the chart\n",
    "plt.show()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# V1: Attack by removing edges ###############################\n",
    "################################# V2: Attack by removing edges + consider cummon neighbors for Crypto ###############################\n",
    "\n",
    "# Define the number of repeats\n",
    "num_repeats = 1\n",
    "accuracy_test_attack_1_values = []\n",
    "accuracy_test_clean_1_values = []\n",
    "accuracy_test_attack_2_values = []\n",
    "accuracy_test_clean_2_values = []\n",
    "accuracy_test_attack_3_values = []\n",
    "accuracy_test_clean_3_values = []\n",
    "\n",
    "seed = 42  # Seed for reproducibility\n",
    "# Function to set seeds for reproducibility\n",
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "################################ Data loading #######################################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "dataset = \"polblogs\"\n",
    "# Use the current directory for windows\n",
    "data = Dataset(root='.', name=dataset, setting='gcn' , seed=15)\n",
    "#data = Dataset(root='/tmp/', name=dataset): this is for unix-based systems\n",
    "\n",
    "for _ in range(num_repeats):\n",
    "    \n",
    "    #############################  preprocessing ############################\n",
    "    set_seeds(seed)\n",
    "    adj, features, labels = data.adj, data.features, data.labels\n",
    "    idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "    #split idx_test into two parts : one node for attack and the rest for clean\n",
    "    # test_size = 1  # 1 node for attack others for test_clean\n",
    "    # idx_test_clean , idx_test_attack = train_test_split(idx_test, test_size=test_size, random_state=42)\n",
    "    # selected_node = idx_test_attack[0]\n",
    "    # print(f\"Selected node for attack: {selected_node}\")\n",
    "\n",
    "    # choose a node for attack manually (the one which has been chosen randomely from idx_test in the previous part)\n",
    "    selected_node = 1196\n",
    "    idx_test_attack = np.array([selected_node])\n",
    "    idx_test_clean = np.array([node for node in idx_test if node != selected_node])\n",
    "    \n",
    "    #split idx_test into two parts randomly\n",
    "    # test_size = 0.10  # 10% for test_attack, 90% for test_clean\n",
    "    # idx_test_clean , idx_test_attack = train_test_split(idx_test, test_size=test_size, random_state=seed)\n",
    "\n",
    "    # Split graph into two graphs for Crypto'Graph\n",
    "    proportion_of_common_links = 0.5\n",
    "    adj1, adj2 = split_dataset(adj, proportion_of_common_links) \n",
    "\n",
    "#check neighbors of the selected node\n",
    "    neighbors_vector = adj1[selected_node, :].toarray()\n",
    "    neighbors_indices = np.nonzero(neighbors_vector)[1]  #  Get the indices of the neighbors\n",
    "    print(f\"num of neighbors of node {selected_node} is: {len(neighbors_indices)}\")\n",
    "    print(\"Neighbors of node\", selected_node, \"are:\", neighbors_indices)\n",
    "\n",
    "\n",
    "   # Ensure adj1 and adj2 are in sparse format\n",
    "    adj1 = sp.csr_matrix(adj1)\n",
    "    adj2 = sp.csr_matrix(adj2)\n",
    "    # Remove zero-weight edges\n",
    "    clean_adj1 = backdoor.remove_zero_weight_edges(adj1.copy())\n",
    "    clean_adj2 = backdoor.remove_zero_weight_edges(adj2.copy())\n",
    "    # Convert cleaned adjacency matrices to networkx graphs\n",
    "    graph1 = nx.from_scipy_sparse_array(clean_adj1)\n",
    "    graph2 = nx.from_scipy_sparse_array(clean_adj2)\n",
    "\n",
    "\n",
    "    # print (\"idx_test_clean\",len (idx_test_clean))\n",
    "    # print (\"idx_test_attack\",len (idx_test_attack))\n",
    "    # print (\"idx_test\",len (idx_test))\n",
    "    # print (\"train\",len (idx_train))\n",
    "    # print(f\"idx_test_attack\",idx_test_attack)\n",
    "    # print(f\"idx_test_clean\",idx_test_clean)\n",
    "    # print (idx_train)\n",
    "    # print (\"val\",len (idx_val))\n",
    "    # print (\"idx_test_clean\",idx_test_clean)\n",
    "    # print (\"idx_test_attack\",idx_test_attack)\n",
    "\n",
    "    ############################ tarin model initially and test accuracy ###########################\n",
    "    # Perform evaluation before attack to find the baseline accuracy\n",
    "\n",
    "    # Train GCN model \n",
    "    # 1. Model definition\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    # 2. Train model - patience= number of epochs to wait before early stopping , train_iters= number of iterations\n",
    "    model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    #model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200,metric=metric,\n",
    "               #object=object, initialize=True, verbose=False )\n",
    "    # 3. Evaluate model\n",
    "    model.eval()\n",
    "    output = model.test(idx_test)\n",
    "    #acc_test = accuracy(output, labels, idx_test)\n",
    "    # accuracies = model.test(idx_test) \n",
    "    # print(\"Test accuracy: \", accuracies)\n",
    "    # output_1 = model.test(idx_test_attack)\n",
    "    # output_2 = model.test(idx_test_clean)\n",
    "\n",
    "    accuracy_test_attack_1 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_1 = model.test(idx_test_clean)\n",
    "    print(\"Test accuracy on attack set: \", accuracy_test_attack_1)\n",
    "    print(\"Test accuracy on clean set: \", accuracy_test_clean_1)\n",
    "\n",
    "    \n",
    "    ################################ Mahsa attack ##############################\n",
    "    # Perform the attack\n",
    "    # version 1: attack on the whole graph - on idx_test_attack nodes - by only removing edges\n",
    "\n",
    "    modified_adj1 =  clean_adj1.copy()\n",
    "\n",
    "    # Create a NetworkX graph from the adjacency matrix\n",
    "    graph = nx.from_scipy_sparse_array(modified_adj1)\n",
    "    \n",
    "    # Add labels to the graph\n",
    "    for node_id, label in enumerate(labels):\n",
    "        graph.nodes[node_id]['label'] = label\n",
    "    # print(f\"lenght of the labels : {len(labels)}\") \n",
    "    print(f\"graph edges : {graph.number_of_edges()}\")\n",
    "    print(f\"graph nodes : {graph.number_of_nodes()}\")\n",
    "    print(\"*************** mahsa attack ***************\")\n",
    "\n",
    "\n",
    "    # Set the budget for the attack\n",
    "    budget = 40\n",
    "\n",
    "\n",
    "    #attacked_graph is initially set to graph, and then updated after each attack\n",
    "    # This means that each attack is performed on the graph resulting from the previous attacks.\n",
    "    attacked_graph = graph\n",
    "    for target_node in idx_test_attack:\n",
    "        neighbor_same = backdoor.find_same_neighbor(attacked_graph, target_node)\n",
    "        max_same_min_opposit_label_neighbors = backdoor.find_max_same_min_opposit_label_neighbors(attacked_graph, neighbor_same)\n",
    "        # step1: we dont consider common neighbors\n",
    "        # attacked_graph = backdoor.remove_edge1(attacked_graph, target_node, max_same_min_opposit_label_neighbors, budget)\n",
    "        \n",
    "        # step2: we consider common neighbors\n",
    "        nodes_for_remove = backdoor.nodes_for_remove(attacked_graph, target_node, max_same_min_opposit_label_neighbors, budget)\n",
    "        attacked_graph = backdoor.remove_edge2(attacked_graph, target_node, nodes_for_remove)\n",
    "        backdoor.check_removing(attacked_graph,nodes_for_remove , target_node, budget)\n",
    "   \n",
    "    # print ( f\"idx_test_attack: {idx_test_attack}\")\n",
    "    # neighbors_same_label = backdoor.find_same_neighbor(graph, selected_node)\n",
    "    # neighbors_opposit_label = backdoor.find_opposit_neighbor(graph, selected_node)\n",
    "    # print ( f\"number of target same label neighbors: {len(neighbors_same_label)}\")\n",
    "    # print ( f\"number of target opposit label neighbors: {len(neighbors_opposit_label)}\")\n",
    "    # print ( f\"idx_test_attack same label neighbors: {neighbors_same_label}\")\n",
    "    # print ( f\"idx_test_attack opposit label neighbors: {neighbors_opposit_label}\")\n",
    "    # print ( f\"number of target NONE neighbors opposite label: {len(backdoor.find_non_neighbor_opposit_label(graph, selected_node))}\")\n",
    "    # print ( f\"idx_test_attack opposit label NONE neighbors: {backdoor.find_non_neighbor_opposit_label(graph, selected_node)}\")\n",
    "\n",
    "    print(attacked_graph)\n",
    "    print(f\"total removed edges : {attacked_graph.number_of_edges() - graph.number_of_edges()}\")\n",
    "\n",
    "    # check for the differences between the initial graph and the attacked graph----- adj wise\n",
    "    # Convert the graph to a CSR matrix\n",
    "    modified_adj1 =backdoor.convert(attacked_graph)\n",
    "    #compare adjs check\n",
    "    diff_adj_attack = modified_adj1 - clean_adj1\n",
    "    non_zero_diff = diff_adj_attack.nonzero()\n",
    "    print(f\"adj wise : modifications after attack: {non_zero_diff}\")\n",
    "    # Count the number of changes\n",
    "    num_changes = len(non_zero_diff[0])/2\n",
    "    print(f\"adj wise: Number of modifications after attack: {num_changes}\")\n",
    "    \n",
    "    # compare graphs check\n",
    "    initial_edges = graph.number_of_edges()\n",
    "    attacked_edges = attacked_graph.number_of_edges()\n",
    "    print(f\"graph check : Initial edges: {initial_edges} and attacked edges: {attacked_edges}\")\n",
    "    print(f\"graph check: Total inserted edges after attack: {attacked_edges - initial_edges}\")\n",
    "    \n",
    "    n1=list(graph.neighbors(selected_node))\n",
    "    print(f\"{selected_node} has {len(n1)} neighbors ofter attack and they are: {n1}\")\n",
    "    n2=list(attacked_graph.neighbors(selected_node))\n",
    "    print(f\"{selected_node} has {len(n2)} neighbors ofter attack and they are: {n2}\")\n",
    "\n",
    "\n",
    "     # Convert the graph to a CSR matrix\n",
    "    modified_adj1 =backdoor.convert(attacked_graph)\n",
    "    print(attacked_graph)\n",
    "    print(f\"total removed edges : {(graph.number_of_edges() - attacked_graph.number_of_edges())}\")\n",
    "\n",
    "    ################################## Plotting target node before attack  #######################################\n",
    "    # target_subgraph = graph.subgraph([selected_node] + list(neighbors_same_label) + list(neighbors_opposit_label))\n",
    "    # pos = nx.spring_layout(target_subgraph)  # positions for all nodes\n",
    "    # # nodes\n",
    "    # nx.draw_networkx_nodes(target_subgraph, pos, nodelist=neighbors_same_label, node_color='green')\n",
    "    # nx.draw_networkx_nodes(target_subgraph, pos, nodelist=neighbors_opposit_label, node_color='pink')\n",
    "    # # edges\n",
    "    # nx.draw_networkx_edges(target_subgraph, pos, width=1.0, alpha=0.5)\n",
    "    # # labels\n",
    "    # nx.draw_networkx_labels(target_subgraph, pos, font_size=16)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "   \n",
    "   \n",
    "    ################################ evaluation after attack ##############################\n",
    "    # accuracy after attack\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    #data = data.to(device)\n",
    "    model.fit(features, modified_adj1, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    model.eval()\n",
    "\n",
    "    # output = model.test(idx_test)\n",
    "\n",
    "    #acc_test = accuracy(output, labels, idx_test)\n",
    "\n",
    "    # output_1 = model.test(idx_test_attack)\n",
    "    # output_2 = model.test(idx_test_clean)\n",
    "\n",
    "    accuracy_test_attack_2 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_2 = model.test(idx_test_clean)\n",
    "\n",
    "    print(\"Test accuracy on attack set after attack: \", accuracy_test_attack_2)\n",
    "    print(\"Test accuracy on clean set after attack: \", accuracy_test_clean_2)\n",
    "\n",
    "    ############################ Crypto'Graph defense ###########################\n",
    "    # Perform Crypto'Graph distributed defense\n",
    "    print(\"*************** Crypto'Graph defense ***************\")\n",
    "\n",
    "    threshold = 2               # threshold for dropping dissimilar edges\n",
    "    metric = \"neighbors\"        # metric for dropping dissimilar edges (neighbors, jaccard, cosine)\n",
    "    object = \"links\"            # object for defense (links, features)\n",
    "\n",
    "    model = TwoPartyCNGCN(dataset=dataset, nfeat=features.shape[1], nhid=16, nclass=labels.max().item() + 1,\n",
    "                            device=device)\n",
    "    defense_duration, defense_duration, training_duration1, training_duration2, CG_defended_adj1, CG_defended_adj2 = model.fit(modified_adj1.copy(), adj2.copy(), features, features, labels, idx_train, threshold, metric=metric, object=object,\n",
    "                train_iters=200, initialize=True, verbose=False, idx_val=idx_val)\n",
    "    model.eval()\n",
    "    accuracies = model.test(idx_test)  #accuracy of the model after the defense on all the test data - (all the nodes)\n",
    "    accuracy_test_attack_3 = model.test(idx_test_attack)\n",
    "    accuracy_test_clean_3 = model.test(idx_test_clean)\n",
    "    print(\"Test accuracy on attack set after Crypto'Graph: \", accuracy_test_attack_3)\n",
    "    print(\"Test accuracy on clean set after Crypto'Graph: \", accuracy_test_clean_3)\n",
    "\n",
    "        \n",
    "    rows = CG_defended_adj1.shape[0]\n",
    "    print(f\"CG_defended_adj1. Number of rows: {rows}\")\n",
    "    \n",
    "    ###### adj wise compare by adj1 and modified_adj1 (before and after defense)\n",
    "    print(\"*************** adj wise compare (before and after defense) ***************\")\n",
    "    differences = np.abs(CG_defended_adj1 - modified_adj1)\n",
    "    total_differences = np.sum(differences)\n",
    "    # print(f\"adj check: differences: {differences}\")\n",
    "    print(f\"adj check: Total number of differences: {total_differences}\")\n",
    "    rows_with_changes = np.count_nonzero(np.sum(differences, axis=1))\n",
    "    print(f\"Number of rows with changes: {rows_with_changes}\")\n",
    "    changed_rows = np.where(np.sum(differences, axis=1) > 0)[0]\n",
    "    print(f\"Rows with different connectivities: {changed_rows}\")\n",
    "\n",
    "\n",
    "    # Compute the difference matrix for the full symmetric matrix\n",
    "    difference_matrix = CG_defended_adj1 - modified_adj1\n",
    "    # Identify the removed edges (negative values in the difference matrix)\n",
    "    removed_edges = np.argwhere(difference_matrix < 0)\n",
    "    # print(\"Removed edges (row, col):\")\n",
    "    # for edge in removed_edges:\n",
    "    #     print(edge)\n",
    "    total_removed_edges = len(removed_edges)\n",
    "    print(f\"Total number of removed edges considering full symetric matrix: {total_removed_edges}\")\n",
    "\n",
    "    # compute the difference matrix for the upper triangle of the symmetric matrix \n",
    "    # Get the indices of the upper triangle of the matrix, excluding the diagonal\n",
    "    rows, cols = np.triu_indices_from(difference_matrix, k=1)\n",
    "    # Select only the upper triangle (excluding diagonal) from the difference matrix\n",
    "    upper_triangle_differences = difference_matrix[rows, cols]\n",
    "    # Identify the removed edges in the upper triangle (negative values)\n",
    "    removed_edges = np.argwhere(upper_triangle_differences < 0)\n",
    "    total_removed_edges = len(removed_edges)\n",
    "    print(f\"Total number of removed edges via CG(adj): {total_removed_edges}\")\n",
    "    # Print the removed edges\n",
    "    # print(\"Removed edges in adjacency matrix (row, col):\")\n",
    "    # for edge in removed_edges:\n",
    "    #     print(edge)\n",
    "\n",
    "    # added edges via CG defense\n",
    "    difference_matrix_add = modified_adj1 - CG_defended_adj1 \n",
    "    rows, cols = np.triu_indices_from(difference_matrix_add, k=1)\n",
    "    upper_triangle_add = difference_matrix_add[rows, cols]\n",
    "    added_edges = np.argwhere(upper_triangle_add < 0)\n",
    "    total_added_edges = len(added_edges)\n",
    "    print(f\"Total number of added edges via CG (adj): {total_added_edges}\")\n",
    "   \n",
    "\n",
    "\n",
    "    #######  graph wise compare by adj1 and modified_adj1 (before and after defense) \n",
    "    print(\"*************** graph wise compare for removed or added edges by CG (before and after defense) ***************\")\n",
    "    # Remove zero-weight edges\n",
    "    modified_adj1_cleaned = backdoor.remove_zero_weight_edges(modified_adj1.copy())\n",
    "    CG_defended_adj1_cleaned = backdoor.remove_zero_weight_edges(CG_defended_adj1.copy())\n",
    "\n",
    "    #Create a NetworkX graph from the adjacency matrix\n",
    "    graph_modified_adj1 = nx.from_scipy_sparse_array(modified_adj1_cleaned) #before defense\n",
    "    graph_CG_1 = nx.from_scipy_sparse_array(CG_defended_adj1_cleaned) # after defense\n",
    "\n",
    "    # print(graph_CG_1)\n",
    "    print(f\"graph graph_modifeid_adj1 before CG: {graph_modified_adj1.number_of_edges()} edges\")\n",
    "    print(f\"graph graph_CG_1 after CG: {graph_CG_1.number_of_edges()} edges\")\n",
    "\n",
    "    # Identify removed edges in the graph\n",
    "    # removed_edges_graph = set(graph_modified_adj1.edges()) - set(graph_CG_1.edges())\n",
    "    removed_edges_graph = set(attacked_graph.edges()) - set(graph_CG_1.edges())\n",
    "    # Print the removed edges\n",
    "    # print(\"Removed edges in NetworkX graphs (node1, node2):\")\n",
    "    # for edge in removed_edges_graph:\n",
    "    #     print(edge)\n",
    "    # Total number of removed edges\n",
    "    total_removed_edges_graph = len(removed_edges_graph)\n",
    "    print(f\"Total number of removed edges (NetworkX graphs): {total_removed_edges_graph}\")\n",
    "\n",
    "    edges_added_by_CryptoGraph = set(graph_CG_1.edges()) - set(attacked_graph.edges())\n",
    "    print(f\"Total number of edges added by Crypto'Graph: {len(edges_added_by_CryptoGraph)}\")\n",
    "    print(\"Edges added by Crypto'Graph (node1, node2):\")\n",
    "    for edge in edges_added_by_CryptoGraph:\n",
    "        print(edge)\n",
    "\n",
    "    print(\"*************** graph wise - check if removed edges are back via CG ***************\")\n",
    "    # if inserted edges are eremoved or not: NX graphs\n",
    "    removed = (set(graph.edges()) - set(attacked_graph.edges()) )\n",
    "    print(f\"Total number of edges deleted by the attack: {len(removed)}\")\n",
    "    print(\"removed edges (node1, node2):\")\n",
    "    for edge in removed:\n",
    "        print(edge)\n",
    "   \n",
    "    # Check if inserted edges have been deleted by Crypto'Graph defense\n",
    "    readded_removed_edges = removed & set(graph_CG_1.edges())\n",
    "    print(f\"Total number of edges re-added by Crypto'Graph: {len(readded_removed_edges)}\")\n",
    "    print(\"added removed edges by Crypto'Graph defense (node1, node2):\")\n",
    "    for edge in readded_removed_edges:\n",
    "        print(edge)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # At the end of each repeat, append the accuracy values to the lists:\n",
    "    accuracy_test_attack_1_values.append(accuracy_test_attack_1)\n",
    "    accuracy_test_clean_1_values.append(accuracy_test_clean_1)\n",
    "    accuracy_test_attack_2_values.append(accuracy_test_attack_2)\n",
    "    accuracy_test_clean_2_values.append(accuracy_test_clean_2)\n",
    "    accuracy_test_attack_3_values.append(accuracy_test_attack_3)\n",
    "    accuracy_test_clean_3_values.append(accuracy_test_clean_3)\n",
    "\n",
    "\n",
    "\n",
    "####################### Standard deviation values ############################\n",
    "# Calculate the standard deviation of the accuracy values:\n",
    "accuracy_test_attack_1_std = np.std(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_std = np.std(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_std = np.std(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_std = np.std(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_std = np.std(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_std = np.std(accuracy_test_clean_3_values)\n",
    "\n",
    "# print(\"Standard deviation of test accuracy on attack set 1: \", accuracy_test_attack_1_std)\n",
    "# print(\"Standard deviation of test accuracy on clean set 1: \", accuracy_test_clean_1_std)\n",
    "# print(\"Standard deviation of test accuracy on attack set 2: \", accuracy_test_attack_2_std)\n",
    "# print(\"Standard deviation of test accuracy on clean set 2: \", accuracy_test_clean_2_std)\n",
    "# print(\"Standard deviation of test accuracy on attack set 3: \", accuracy_test_attack_3_std)\n",
    "# print(\"Standard deviation of test accuracy on clean set 3: \", accuracy_test_clean_3_std)\n",
    "\n",
    "# Save the standard deviation values to a file\n",
    "with open('variables_std.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "                 accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "                 accuracy_test_attack_3_std, accuracy_test_clean_3_std], f)\n",
    "\n",
    "\n",
    "####################### Average accuracy values ############################\n",
    "# Calculate the average accuracy values:\n",
    "accuracy_test_attack_1_avg = np.mean(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_avg = np.mean(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_avg = np.mean(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_avg = np.mean(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_avg = np.mean(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_avg = np.mean(accuracy_test_clean_3_values)\n",
    "\n",
    "\n",
    "with open('variables.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "                 accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "                 accuracy_test_attack_3_avg, accuracy_test_clean_3_avg], f)\n",
    "    \n",
    "\n",
    "################################# Plotting Training Results #######################################\n",
    "labels = ['ACCs before attack', 'ACCs before attack', \n",
    "          'ACCs after attack', 'ACCs after attack', \n",
    "          'ACCs after CryptoGraph', 'ACCs after CryptoGraph']\n",
    "values = [accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "          accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "          accuracy_test_attack_3_avg, accuracy_test_clean_3_avg]\n",
    "std_devs = [accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "            accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "            accuracy_test_attack_3_std, accuracy_test_clean_3_std]\n",
    "\n",
    "# Define the x-coordinates of the bars and the width of the bars\n",
    "x = np.arange(len(labels)//2)\n",
    "width = 0.35\n",
    "\n",
    "# Create the bar chart with error bars\n",
    "bars1 = plt.bar(x - width/2, values[::2], width, yerr=std_devs[::2], label='Attack set', color='red', capsize=5)\n",
    "bars2 = plt.bar(x + width/2, values[1::2], width, yerr=std_devs[1::2], label='Clean set', color='blue', capsize=5)\n",
    "\n",
    "# Add a title and labels to the axes\n",
    "plt.title('Average Accuracies')\n",
    "plt.xlabel('Levels of Attack and Defense')\n",
    "plt.ylabel('Average Accuracy')\n",
    "\n",
    "# Make the x-labels vertical\n",
    "plt.xticks(x, labels[::2])\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "# Add exact values on each bar\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "\n",
    "# Adjust the layout to prevent the labels from being cut off\n",
    "plt.tight_layout()\n",
    "# Display the chart\n",
    "plt.show()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# TESTTTTTTT for analysis of the graph and nodes before attack ###############################\n",
    "\n",
    "################################ Data loading #######################################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "dataset = \"polblogs\"\n",
    "# Use the current directory for windows\n",
    "data = Dataset(root='.', name=dataset)\n",
    "#data = Dataset(root='/tmp/', name=dataset): this is for unix-based systems\n",
    "\n",
    "#############################  preprocessing ############################\n",
    "adj, features, labels = data.adj, data.features, data.labels\n",
    "idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "modified_adj =  adj.copy()\n",
    "\n",
    "# Create a NetworkX graph from the adjacency matrix\n",
    "graph = nx.from_scipy_sparse_array(modified_adj)\n",
    "# Add labels to the graph\n",
    "for node_id, label in enumerate(labels):\n",
    "    graph.nodes[node_id]['label'] = label\n",
    "# print(f\"lenght of the labels : {len(labels)}\") \n",
    "print(f\"graph edges : {graph.number_of_edges()}\")\n",
    "print(f\"graph nodes : {graph.number_of_nodes()}\")\n",
    "\n",
    "#########################analysis of the graph and nodes before attack ###############################\n",
    "\n",
    "# all \n",
    "def count_neighbor_labels(graph, labels):\n",
    "    count_dict = {} # dictionary type variable with key: node, and value of: (same_label, opposite_label)\n",
    "    for node in graph.nodes():\n",
    "        neighbors = list(graph.neighbors(node))\n",
    "        same_label = sum(labels[neighbor] == labels[node] for neighbor in neighbors)\n",
    "        opposite_label = len(neighbors) - same_label\n",
    "        count_dict[node] = (same_label, opposite_label)\n",
    "    return count_dict\n",
    "\n",
    "count_dict = count_neighbor_labels(graph, labels)\n",
    "# Sort nodes by the number of same-label neighbors. \n",
    "# x is tuple (node, (same_label, opposite_label)). so x[1][0] is index 0 from the second element of the tuple = same_lable \n",
    "sorted_nodes = sorted(count_dict.items(), key=lambda x: x[1][0], reverse=True) \n",
    "\n",
    "# print(f\"Nodes and their same-label and opposite-label neighbors: {count_dict}\")\n",
    "print(f\"sorted nodes based on the number of same-label neighbors: {sorted_nodes}\")\n",
    "\n",
    "# returns a dict of nodes which have most same label and most opposite labels with the target node\n",
    "def sort_classly(count_dict, labels, target_node):\n",
    "    nodes_class_same = {node: counts for node, counts in count_dict.items() if labels[node] == labels[target_node]}\n",
    "    nodes_class_opp = {node: counts for node, counts in count_dict.items() if labels[node] != labels[target_node]}\n",
    "    sorted_nodes_same = sorted(nodes_class_same.items(), key=lambda x: x[1][0], reverse=True)\n",
    "    sorted_nodes_opp = sorted(nodes_class_opp.items(), key=lambda x: x[1][0], reverse=True)\n",
    "    return sorted_nodes_same, sorted_nodes_opp\n",
    "\n",
    "sorted_nodes_same, sorted_nodes_opp = sort_classly(count_dict, labels, 499)\n",
    "# Print the top 10 nodes for each class\n",
    "# print(f\"The most same-label neighbors in same class of label with node {499}: {sorted_nodes_same[:10]}\")\n",
    "# print(f\"The most same-label neighbors in class 1: {sorted_nodes_opp[:10]}\")\n",
    "# print (f\"label of node is: {labels[671]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### V3-0 : Attack by removing edges + adding edge: (le budget égal pour ajouter, enlever) ###############\n",
    "################### Attack by removing edges + adding edges: for 10% nodes, for one node, for manually selection of nodes \n",
    "# Define the number of repeats\n",
    "num_repeats = 1\n",
    "accuracy_test_attack_1_values = []\n",
    "accuracy_test_clean_1_values = []\n",
    "accuracy_test_attack_2_values = []\n",
    "accuracy_test_clean_2_values = []\n",
    "accuracy_test_attack_3_values = []\n",
    "accuracy_test_clean_3_values = []\n",
    "\n",
    "seed = 42  # Seed for reproducibility\n",
    "# Function to set seeds for reproducibility\n",
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "################################ Data loading #######################################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "dataset = \"polblogs\"\n",
    "# Use the current directory for windows\n",
    "data = Dataset(root='.', name=dataset,setting='gcn', seed=15)\n",
    "#data = Dataset(root='/tmp/', name=dataset): this is for unix-based systems\n",
    "\n",
    "for _ in range(num_repeats):\n",
    "    \n",
    "    #############################  preprocessing ############################\n",
    "    set_seeds(seed)\n",
    "    adj, features, labels = data.adj, data.features, data.labels\n",
    "    idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "    ################### split idx_test into two parts : one node for attack randomley and the rest for clean\n",
    "    # test_size = 1  # 1 node for attack others for test_clean\n",
    "    # idx_test_clean , idx_test_attack = train_test_split(idx_test, test_size=test_size, random_state=42)\n",
    "    # selected_node = idx_test_attack[0]\n",
    "    # print(f\"Selected node for attack: {selected_node}\")\n",
    "    ######################\n",
    "\n",
    "    ############### choose a node for attack manually (the one which has been chosen randomely from idx_test in the previous part)\n",
    "    selected_node = 1196\n",
    "    idx_test_attack = np.array([selected_node])\n",
    "    idx_test_clean = np.array([node for node in idx_test if node != selected_node])\n",
    "    ######################\n",
    "\n",
    "    ################ split idx_test into two parts randomly with a specific ratio %\n",
    "    # test_size = 0.10  # 10% for test_attack, 90% for test_clean\n",
    "    # idx_test_clean , idx_test_attack = train_test_split(idx_test, test_size=test_size, random_state=seed)\n",
    "    ######################\n",
    "\n",
    "    # Split graph into two graphs for Crypto'Graph\n",
    "    proportion_of_common_links = 0.5\n",
    "    adj1, adj2 = split_dataset(adj, proportion_of_common_links) \n",
    "\n",
    "  # Ensure adj1 and adj2 are in sparse format\n",
    "    adj1 = sp.csr_matrix(adj1)\n",
    "    adj2 = sp.csr_matrix(adj2)\n",
    "    # Remove zero-weight edges\n",
    "    clean_adj1 = backdoor.remove_zero_weight_edges(adj1.copy())\n",
    "    clean_adj2 = backdoor.remove_zero_weight_edges(adj2.copy())\n",
    "    # Convert cleaned adjacency matrices to networkx graphs\n",
    "    graph1 = nx.from_scipy_sparse_array(clean_adj1)\n",
    "    graph2 = nx.from_scipy_sparse_array(clean_adj2)\n",
    "\n",
    "\n",
    "#check neighbors of the selected node\n",
    "    neighbors_vector = adj1[selected_node, :].toarray()\n",
    "    neighbors_indices = np.nonzero(neighbors_vector)[1]  #  Get the indices of the neighbors\n",
    "    print(f\"num of neighbors of node {selected_node} is: {len(neighbors_indices)}\")\n",
    "    print(\"Neighbors of node\", selected_node, \"are:\", neighbors_indices)\n",
    "\n",
    "   \n",
    "    # print (\"idx_test_clean\",len (idx_test_clean))\n",
    "    # print (\"idx_test_attack\",len (idx_test_attack))\n",
    "    # print (\"idx_test\",len (idx_test))\n",
    "    # print (\"train\",len (idx_train))\n",
    "    # print(f\"idx_test_attack\",idx_test_attack)\n",
    "    # print(f\"idx_test_clean\",idx_test_clean)\n",
    "    # print (\"val\",len (idx_val))\n",
    "    # print (idx_train)\n",
    "    # print (\"idx_test_clean\",idx_test_clean)\n",
    "    # print (\"idx_test_attack\",idx_test_attack)\n",
    "\n",
    "    ############################ train model initially and test accuracy ###########################\n",
    "    # Perform evaluation before attack to find the baseline accuracy\n",
    "\n",
    "    # Train GCN model \n",
    "    # 1. Model definition\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    # 2. Train model - patience= number of epochs to wait before early stopping , train_iters= number of iterations\n",
    "    model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    #model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200,metric=metric,\n",
    "               #object=object, initialize=True, verbose=False )\n",
    "    # 3. Evaluate model\n",
    "    model.eval()\n",
    "    output = model.test(idx_test)\n",
    "\n",
    "    accuracy_test_attack_1 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_1 = model.test(idx_test_clean)\n",
    "    print(\"Test accuracy on attack set: \", accuracy_test_attack_1)\n",
    "    print(\"Test accuracy on clean set: \", accuracy_test_clean_1)\n",
    "\n",
    "    \n",
    "    ################################ Mahsa attack ##############################\n",
    "    # Perform the attack\n",
    "    # version 1: attack on the whole graph - on idx_test_attack nodes - by only removing edges\n",
    "\n",
    "    modified_adj1 =  clean_adj1.copy()\n",
    "\n",
    "    # Create a NetworkX graph from the adjacency matrix\n",
    "    graph = nx.from_scipy_sparse_array(modified_adj1)\n",
    "    # Add labels to the graph\n",
    "    for node_id, label in enumerate(labels):\n",
    "        graph.nodes[node_id]['label'] = label\n",
    "    # print(f\"lenght of the labels : {len(labels)}\") \n",
    "    print(f\"graph edges : {graph.number_of_edges()}\")\n",
    "    print(f\"graph nodes : {graph.number_of_nodes()}\")\n",
    "    print(\"*************** mahsa attack ***************\")\n",
    "\n",
    "    # Set the budget for the attack\n",
    "    budget = 90\n",
    "\n",
    "    #attacked_graph is initially set to graph, and then updated after each attack\n",
    "    # This means that each attack is performed on the graph resulting from the previous attacks.\n",
    "    attacked_graph = graph\n",
    "    count_dict = backdoor.count_neighbor_labels_0(graph, labels)\n",
    "    print (count_dict)        \n",
    "\n",
    "\n",
    "    for target_node in idx_test_attack:\n",
    "        sorted_nodes_same, sorted_nodes_opp = backdoor.sort_classly(count_dict, labels, target_node)# sort nodes based on the number of same and opposite label neighbors\n",
    "        remove_budget = budget // 2\n",
    "        add_budget = budget - remove_budget\n",
    "        attacked_graph,removed_edges,added_edges = backdoor.add_remove(attacked_graph, target_node, sorted_nodes_same, sorted_nodes_opp, remove_budget, add_budget)\n",
    "            \n",
    "\n",
    "    print(f\"Removed {len(removed_edges)} edges: {removed_edges}\")\n",
    "    print(f\"Added {len(added_edges)} edges: {added_edges}\")    \n",
    "    \n",
    "    print ( f\"idx_test_attack: {idx_test_attack}\")\n",
    "    # neighbors_same_label = backdoor.find_same_neighbor(graph, selected_node)\n",
    "    # neighbors_opposit_label = backdoor.find_opposit_neighbor(graph, selected_node)\n",
    "    # print ( f\"number of target same label neighbors before attack: {len(neighbors_same_label)}\")\n",
    "    # print ( f\"number of target opposit label neighbors before attack: {len(neighbors_opposit_label)}\")\n",
    "    # print( f\"idx_test_attack same all over the graph : {len(sorted_nodes_same)}\")\n",
    "    # print( f\"idx_test_attack opposit label all over the graph: {len(sorted_nodes_opp)}\")\n",
    "    \n",
    "    # # neighbors_same_after = backdoor.find_same_neighbor(attacked_graph, selected_node)\n",
    "    # # neighbors_opposit_after = backdoor.find_opposit_neighbor(attacked_graph, selected_node)\n",
    "    # print ( f\"idx_test_attack same label neighbors after attack: {len(neighbors_same_after)}\")\n",
    "    # print ( f\"idx_test_attack opposit label neighbors after attack: {len(neighbors_opposit_after)}\")\n",
    "\n",
    "\n",
    "    # print ( f\"idx_test_attack same label neighbors: {neighbors_same_label}\")\n",
    "    # print ( f\"idx_test_attack opposit label neighbors: {neighbors_opposit_label}\")\n",
    "    # print (f\"same label all over graph : (node, (num of same label, num of opposit label)){sorted_nodes_same}\")\n",
    "    # print (f\"as above for opposite lables{sorted_nodes_opp}\")\n",
    "    \n",
    "    def is_neighbor(graph, node1, node2):\n",
    "        return graph.has_edge(node1, node2) or graph.has_edge(node2, node1)\n",
    "\n",
    "    # is_neighbor = is_neighbor(attacked_graph, 300, 499)\n",
    "    # print ( f\"label of target node is: {labels[499]}\")\n",
    "    # print ( f\"label of node 300 is: {labels[300]}\")\n",
    "    # print ( is_neighbor)\n",
    "\n",
    "    # Convert the graph to a CSR matrix\n",
    "    modified_adj1 =backdoor.convert(attacked_graph)\n",
    "    print(attacked_graph)\n",
    "    #print(f\"total removed edges : {(graph.number_of_edges() - attacked_graph.number_of_edges())}\")\n",
    "\n",
    "    print(attacked_graph)\n",
    "    # print(f\"total removed edges : {attacked_graph.number_of_edges() - graph.number_of_edges()}\")\n",
    "\n",
    "    # check for the differences between the initial graph and the attacked graph----- adj wise\n",
    "    #compare adjs check\n",
    "    diff_adj_attack = modified_adj1 - clean_adj1\n",
    "    non_zero_diff = diff_adj_attack.nonzero()\n",
    "    print(f\"adj wise : modifications after attack: {non_zero_diff}\")\n",
    "    # Count the number of changes\n",
    "    num_changes = len(non_zero_diff[0])/2\n",
    "    print(f\"adj wise: Number of modifications after attack: {num_changes}\")\n",
    "    \n",
    "    n1=list(graph.neighbors(selected_node))\n",
    "    print(f\"{selected_node} has {len(n1)} neighbors before attack and they are: {n1}\")\n",
    "    n2=list(attacked_graph.neighbors(selected_node))\n",
    "    print(f\"{selected_node} has {len(n2)} neighbors after attack and they are: {n2}\")\n",
    "\n",
    "\n",
    "\n",
    "    ################################## Plotting target node before attack  #######################################\n",
    "    # target_subgraph = graph.subgraph([selected_node] + list(neighbors_same_label) + list(neighbors_opposit_label))\n",
    "    # pos = nx.spring_layout(target_subgraph)  # positions for all nodes\n",
    "    # # nodes\n",
    "    # nx.draw_networkx_nodes(target_subgraph, pos, nodelist=neighbors_same_label, node_color='green')\n",
    "    # nx.draw_networkx_nodes(target_subgraph, pos, nodelist=neighbors_opposit_label, node_color='pink')\n",
    "    # # edges\n",
    "    # nx.draw_networkx_edges(target_subgraph, pos, width=1.0, alpha=0.5)\n",
    "    # # labels\n",
    "    # nx.draw_networkx_labels(target_subgraph, pos, font_size=16)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "   \n",
    "    ################################ evaluation after attack ##############################\n",
    "    # accuracy after attack\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    #data = data.to(device)\n",
    "    model.fit(features, modified_adj1, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    model.eval()\n",
    "\n",
    "    # output = model.test(idx_test)\n",
    "\n",
    "    #acc_test = accuracy(output, labels, idx_test)\n",
    "\n",
    "    # output_1 = model.test(idx_test_attack)\n",
    "    # output_2 = model.test(idx_test_clean)\n",
    "\n",
    "    accuracy_test_attack_2 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_2 = model.test(idx_test_clean)\n",
    "\n",
    "    print(\"Test accuracy on attack set after attack: \", accuracy_test_attack_2)\n",
    "    print(\"Test accuracy on clean set after attack: \", accuracy_test_clean_2)\n",
    "\n",
    "    ############################ Crypto'Graph defense ###########################\n",
    "    # Perform Crypto'Graph distributed defense\n",
    "    print(\"*************** Crypto'Graph defense ***************\")\n",
    "\n",
    "    threshold = 2               # threshold for dropping dissimilar edges\n",
    "    metric = \"neighbors\"        # metric for dropping dissimilar edges (neighbors, jaccard, cosine)\n",
    "    object = \"links\"            # object for defense (links, features)\n",
    "\n",
    "    model = TwoPartyCNGCN(dataset=dataset, nfeat=features.shape[1], nhid=16, nclass=labels.max().item() + 1,\n",
    "                            device=device)\n",
    "    defense_duration, defense_duration, training_duration1, training_duration2, CG_defended_adj1, CG_defended_adj2 = model.fit(modified_adj1.copy(), adj2.copy(), features, features, labels, idx_train, threshold, metric=metric, object=object,\n",
    "                train_iters=200, initialize=True, verbose=False, idx_val=idx_val)\n",
    "    model.eval()\n",
    "    accuracies = model.test(idx_test)  #accuracy of the model after the defense on all the test data - (all the nodes)\n",
    "    accuracy_test_attack_3 = model.test(idx_test_attack)\n",
    "    accuracy_test_clean_3 = model.test(idx_test_clean)\n",
    "    print(\"Test accuracy on attack set after Crypto'Graph: \", accuracy_test_attack_3)\n",
    "    print(\"Test accuracy on clean set after Crypto'Graph: \", accuracy_test_clean_3)\n",
    "\n",
    "    rows = CG_defended_adj1.shape[0]\n",
    "    print(f\"CG_defended_adj1. Number of rows: {rows}\")\n",
    "    \n",
    "    \n",
    "    ############################## adj wise compare by adj1 and modified_adj1 (before and after defense)\n",
    "    print(\"*************** adj wise compare (before and after defense) ***************\")\n",
    "    differences = np.abs(CG_defended_adj1 - modified_adj1)\n",
    "    total_differences = np.sum(differences)\n",
    "    # print(f\"adj check: differences: {differences}\")\n",
    "    print(f\"adj check: Total number of differences: {total_differences}\")\n",
    "    rows_with_changes = np.count_nonzero(np.sum(differences, axis=1))\n",
    "    print(f\"Number of rows with changes: {rows_with_changes}\")\n",
    "    changed_rows = np.where(np.sum(differences, axis=1) > 0)[0]\n",
    "    print(f\"Rows with different connectivities: {changed_rows}\")\n",
    "\n",
    "\n",
    "    # Compute the difference matrix for the full symmetric matrix\n",
    "    difference_matrix = CG_defended_adj1 - modified_adj1\n",
    "    # Identify the removed edges (negative values in the difference matrix)\n",
    "    removed_edges = np.argwhere(difference_matrix < 0)\n",
    "    # print(\"Removed edges (row, col):\")\n",
    "    # for edge in removed_edges:\n",
    "    #     print(edge)\n",
    "    total_removed_edges = len(removed_edges)\n",
    "    print(f\"Total number of removed edges considering full symetric matrix: {total_removed_edges}\")\n",
    "\n",
    "    # compute the difference matrix for the upper triangle of the symmetric matrix \n",
    "    # Get the indices of the upper triangle of the matrix, excluding the diagonal\n",
    "    rows, cols = np.triu_indices_from(difference_matrix, k=1)\n",
    "    # Select only the upper triangle (excluding diagonal) from the difference matrix\n",
    "    upper_triangle_differences = difference_matrix[rows, cols]\n",
    "    # Identify the removed edges in the upper triangle (negative values)\n",
    "    removed_edges = np.argwhere(upper_triangle_differences < 0)\n",
    "    # Count the total number of removed edges\n",
    "    total_removed_edges = len(removed_edges)\n",
    "    print(f\"Total number of removed edges(adj): {total_removed_edges}\")\n",
    "    # Print the removed edges\n",
    "    # print(\"Removed edges in adjacency matrix (row, col):\")\n",
    "    # for edge in removed_edges:\n",
    "    #     print(edge)\n",
    "\n",
    "\n",
    "      \n",
    "    ################# check exact edges which are removed by CG defense ################\n",
    "    # Identify the edges added during the attack\n",
    "    added_edges = []\n",
    "    modified_adj1_array = modified_adj1.toarray()\n",
    "    clean_adj1_array = clean_adj1.toarray()\n",
    "\n",
    "    rows, cols = np.triu_indices(modified_adj1_array.shape[0], k=1)\n",
    "    for i, j in zip(rows, cols):\n",
    "        if modified_adj1_array[i, j] == 1 and clean_adj1_array[i, j] == 0:\n",
    "            added_edges.append((i, j))\n",
    "    print(f\"Added edges during attack: {added_edges}\")\n",
    "\n",
    "    # Check if the added edges are removed by CG defense\n",
    "    removed_edges_by_CG = []\n",
    "    CG_defended_adj1_array = CG_defended_adj1.toarray()\n",
    "\n",
    "    for edge in added_edges:\n",
    "        i, j = edge\n",
    "        if CG_defended_adj1_array[i, j] == 0:\n",
    "            removed_edges_by_CG.append(edge)\n",
    "    print(f\"Removed edges by CG defense: {removed_edges_by_CG}\")\n",
    "   \n",
    "\n",
    "    \n",
    "     ###### check if  added edges via CG defense\n",
    "    difference_matrix_add = modified_adj1 - CG_defended_adj1 \n",
    "    rows, cols = np.triu_indices_from(difference_matrix_add, k=1)\n",
    "    upper_triangle_add = difference_matrix_add[rows, cols]\n",
    "    added_edges = np.argwhere(upper_triangle_add < 0)\n",
    "    total_added_edges = len(added_edges)\n",
    "    print(f\"Total number of added edges via CG (adj): {total_added_edges}\")\n",
    "   \n",
    "\n",
    "\n",
    "    #######  graph wise compare by adj1 and modified_adj1 (before and after defense) \n",
    "    print(\"*************** graph wise compare for removed or added edges by CG (before and after defense) ***************\")\n",
    "    # Remove zero-weight edges\n",
    "    modified_adj1_cleaned = backdoor.remove_zero_weight_edges(modified_adj1.copy())\n",
    "    CG_defended_adj1_cleaned = backdoor.remove_zero_weight_edges(CG_defended_adj1.copy())\n",
    "\n",
    "    #Create a NetworkX graph from the adjacency matrix\n",
    "    graph_modified_adj1 = nx.from_scipy_sparse_array(modified_adj1_cleaned) #before defense\n",
    "    graph_CG_1 = nx.from_scipy_sparse_array(CG_defended_adj1_cleaned) # after defense\n",
    "\n",
    "    # print(graph_CG_1)\n",
    "    print(f\"graph graph_modifeid_adj1 before CG: {graph_modified_adj1.number_of_edges()} edges\")\n",
    "    print(f\"graph graph_CG_1 after CG: {graph_CG_1.number_of_edges()} edges\")\n",
    "\n",
    "    # Identify removed edges in the graph\n",
    "    # removed_edges_graph = set(graph_modified_adj1.edges()) - set(graph_CG_1.edges())\n",
    "    removed_edges_graph = set(attacked_graph.edges()) - set(graph_CG_1.edges())\n",
    "    # Print the removed edges\n",
    "    # print(\"Removed edges in NetworkX graphs (node1, node2):\")\n",
    "    # for edge in removed_edges_graph:\n",
    "    #     print(edge)\n",
    "    # Total number of removed edges\n",
    "    total_removed_edges_graph = len(removed_edges_graph)\n",
    "    print(f\"Total number of removed edges (NetworkX graphs): {total_removed_edges_graph}\")\n",
    "\n",
    "    edges_added_by_CryptoGraph = set(graph_CG_1.edges()) - set(attacked_graph.edges())\n",
    "    print(f\"Total number of edges added by Crypto'Graph: {len(edges_added_by_CryptoGraph)}\")\n",
    "    print(\"Edges added by Crypto'Graph (node1, node2):\")\n",
    "    for edge in edges_added_by_CryptoGraph:\n",
    "        print(edge)\n",
    "\n",
    "    print(\"*************** graph wise - check if removed/added edges are detected by CG ***************\")\n",
    "    # if inserted edges are eremoved or not: NX graphs\n",
    "    added_by_attack = (set(attacked_graph.edges()) - set(graph.edges()) )\n",
    "    print(f\"Total number of edges added by the attack: {len(added_by_attack)}\")\n",
    "    print(\"added edges (node1, node2):\")\n",
    "    for edge in added_by_attack:\n",
    "        print(edge)\n",
    "    \n",
    "    removed_by_attack = (set(graph.edges()) - set(attacked_graph.edges()) )\n",
    "    print(f\"Total number of edges deleted by the attack: {len(removed_by_attack)}\")\n",
    "    print(\"removed edges (node1, node2):\")\n",
    "    for edge in removed_by_attack:\n",
    "        print(edge)\n",
    "   \n",
    "    # Check if changed edges via attack have been detected by Crypto'Graph defense\n",
    "    added_edges_detected = added_by_attack - set(graph_CG_1.edges())\n",
    "    # Print deleted inserted edges\n",
    "    print(\"added edges detected and removed by Crypto'Graph defense (node1, node2):\")\n",
    "    for edge in added_edges_detected:\n",
    "        print(edge)\n",
    "    print(f\"Total number of added edges detected and removed by Crypto'Graph: {len(added_edges_detected)}\")\n",
    "\n",
    "\n",
    "    removed_edges_detected = removed_by_attack & set(graph_CG_1.edges())\n",
    "    print(\"removed edges detected and readded by Crypto'Graph defense (node1, node2):\")\n",
    "    for edge in removed_edges_detected:\n",
    "        print(edge)\n",
    "    print(f\"Total number of removed edges detected and readded by Crypto'Graph: {len(removed_edges_detected)}\")\n",
    "\n",
    "  \n",
    "    ####another ay : \n",
    "    # Calculate intersection of inserted and removed edges\n",
    "    intersected_edges = added_by_attack.intersection(removed_edges_graph)\n",
    "    # Check if any inserted edge was removed\n",
    "    if intersected_edges:\n",
    "        print(\"Inserted edges that were removed (node1, node2):\")\n",
    "        for edge in intersected_edges:\n",
    "            print(edge)\n",
    "    else:\n",
    "        print(\"No inserted edges were removed.\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # At the end of each repeat, append the accuracy values to the lists:\n",
    "    accuracy_test_attack_1_values.append(accuracy_test_attack_1)\n",
    "    accuracy_test_clean_1_values.append(accuracy_test_clean_1)\n",
    "    accuracy_test_attack_2_values.append(accuracy_test_attack_2)\n",
    "    accuracy_test_clean_2_values.append(accuracy_test_clean_2)\n",
    "    accuracy_test_attack_3_values.append(accuracy_test_attack_3)\n",
    "    accuracy_test_clean_3_values.append(accuracy_test_clean_3)\n",
    "\n",
    "\n",
    "\n",
    "####################### Standard deviation values ############################\n",
    "# Calculate the standard deviation of the accuracy values:\n",
    "accuracy_test_attack_1_std = np.std(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_std = np.std(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_std = np.std(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_std = np.std(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_std = np.std(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_std = np.std(accuracy_test_clean_3_values)\n",
    "\n",
    "# Save the standard deviation values to a file\n",
    "with open('variables_std.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "                 accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "                 accuracy_test_attack_3_std, accuracy_test_clean_3_std], f)\n",
    "\n",
    "\n",
    "####################### Average accuracy values ############################\n",
    "# Calculate the average accuracy values:\n",
    "accuracy_test_attack_1_avg = np.mean(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_avg = np.mean(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_avg = np.mean(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_avg = np.mean(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_avg = np.mean(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_avg = np.mean(accuracy_test_clean_3_values)\n",
    "\n",
    "\n",
    "with open('variables.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "                 accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "                 accuracy_test_attack_3_avg, accuracy_test_clean_3_avg], f)\n",
    "    \n",
    "\n",
    "################################# Plotting Training Results #######################################\n",
    "labels = ['ACCs before attack', 'ACCs before attack', \n",
    "          'ACCs after attack', 'ACCs after attack', \n",
    "          'ACCs after CryptoGraph', 'ACCs after CryptoGraph']\n",
    "values = [accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "          accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "          accuracy_test_attack_3_avg, accuracy_test_clean_3_avg]\n",
    "std_devs = [accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "            accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "            accuracy_test_attack_3_std, accuracy_test_clean_3_std]\n",
    "\n",
    "# Define the x-coordinates of the bars and the width of the bars\n",
    "x = np.arange(len(labels)//2)\n",
    "width = 0.35\n",
    "\n",
    "# Create the bar chart with error bars\n",
    "bars1 = plt.bar(x - width/2, values[::2], width, yerr=std_devs[::2], label='Attack set', color='red', capsize=5)\n",
    "bars2 = plt.bar(x + width/2, values[1::2], width, yerr=std_devs[1::2], label='Clean set', color='blue', capsize=5)\n",
    "\n",
    "# Add a title and labels to the axes\n",
    "plt.title('Average Accuracies')\n",
    "plt.xlabel('Levels of Attack and Defense')\n",
    "plt.ylabel('Average Accuracy')\n",
    "\n",
    "# Make the x-labels vertical\n",
    "plt.xticks(x, labels[::2])\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "# Add exact values on each bar\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "\n",
    "# Adjust the layout to prevent the labels from being cut off\n",
    "plt.tight_layout()\n",
    "# Display the chart\n",
    "plt.show()      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### V3.1 : Attack by removing edges + adding edge: (le budget change selon l’importance pour ajouter/enlever) ###############\n",
    "################### Attack by removing edges + adding edges: for 10% nodes, for one node, for manually selection of nodes \n",
    "# Define the number of repeats\n",
    "num_repeats = 1\n",
    "accuracy_test_attack_1_values = []\n",
    "accuracy_test_clean_1_values = []\n",
    "accuracy_test_attack_2_values = []\n",
    "accuracy_test_clean_2_values = []\n",
    "accuracy_test_attack_3_values = []\n",
    "accuracy_test_clean_3_values = []\n",
    "\n",
    "seed = 42  # Seed for reproducibility\n",
    "# Function to set seeds for reproducibility\n",
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "################################ Data loading #######################################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "dataset = \"polblogs\"\n",
    "# Use the current directory for windows\n",
    "data = Dataset(root='.', name=dataset, setting='gcn', seed=15)\n",
    "#data = Dataset(root='/tmp/', name=dataset): this is for unix-based systems\n",
    "\n",
    "for _ in range(num_repeats):\n",
    "    \n",
    "    #############################  preprocessing ############################\n",
    "    set_seeds(seed)\n",
    "    adj, features, labels = data.adj, data.features, data.labels\n",
    "    idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "    ################### split idx_test into two parts : one node for attack randomley and the rest for clean\n",
    "    # test_size = 1  # 1 node for attack others for test_clean\n",
    "    # idx_test_clean , idx_test_attack = train_test_split(idx_test, test_size=test_size, random_state=42)\n",
    "    # selected_node = idx_test_attack[0]\n",
    "    # print(f\"Selected node for attack: {selected_node}\")\n",
    "    # print(f\"Label of the selected node: {labels[selected_node]}\")\n",
    "    ######################\n",
    "\n",
    "    ############### choose a node for attack manually (the one which has been chosen randomely from idx_test in the previous part)\n",
    "    selected_node = 1196\n",
    "    idx_test_attack = np.array([selected_node])\n",
    "    idx_test_clean = np.array([node for node in idx_test if node != selected_node])\n",
    "    print(f\"Selected node for attack: {selected_node}\")\n",
    "    print(f\"Label of the selected node: {labels[selected_node]}\")\n",
    "    ######################\n",
    "\n",
    "    ################ split idx_test into two parts randomly with a specific ratio %\n",
    "    # test_size = 0.10  # 10% for test_attack, 90% for test_clean\n",
    "    # idx_test_clean , idx_test_attack = train_test_split(idx_test, test_size=test_size, random_state=seed)\n",
    "    ######################\n",
    "\n",
    "    # Split graph into two graphs for Crypto'Graph\n",
    "    proportion_of_common_links = 0.5\n",
    "    adj1, adj2 = split_dataset(adj, proportion_of_common_links) \n",
    "\n",
    "   \n",
    "     # Ensure adj1 and adj2 are in sparse format\n",
    "    adj1 = sp.csr_matrix(adj1)\n",
    "    adj2 = sp.csr_matrix(adj2)\n",
    "    # Remove zero-weight edges\n",
    "    clean_adj1 = backdoor.remove_zero_weight_edges(adj1.copy())\n",
    "    clean_adj2 = backdoor.remove_zero_weight_edges(adj2.copy())\n",
    "    # Convert cleaned adjacency matrices to networkx graphs\n",
    "    graph1 = nx.from_scipy_sparse_array(clean_adj1)\n",
    "    graph2 = nx.from_scipy_sparse_array(clean_adj2)\n",
    "\n",
    "    #check neighbors of the selected node\n",
    "    neighbors_vector = adj1[selected_node, :].toarray()\n",
    "    neighbors_indices = np.nonzero(neighbors_vector)[1]  #  Get the indices of the neighbors\n",
    "    print(f\"num of neighbors of node {selected_node} is: {len(neighbors_indices)}\")\n",
    "    print(\"Neighbors of node\", selected_node, \"are:\", neighbors_indices)\n",
    "\n",
    "\n",
    "    # print (\"len of idx_test_clean\",len (idx_test_clean))\n",
    "    # print (\"len of idx_test_attack\",len (idx_test_attack))\n",
    "    # print (\"idx_test\",len (idx_test))\n",
    "    # print(f\"idx_test_attack\",idx_test_attack)\n",
    "    # print(f\"idx_test_clean\",idx_test_clean)\n",
    "    # print (\"train\",len (idx_train))\n",
    "    # print (\"val\",len (idx_val))\n",
    "    # print (idx_train)\n",
    "    # print (\"idx_test_clean\",idx_test_clean)\n",
    "    # print (\"idx_test_attack\",idx_test_attack)\n",
    "\n",
    "    ############################ train model initially and test accuracy ###########################\n",
    "    # Perform evaluation before attack to find the baseline accuracy\n",
    "\n",
    "    # Train GCN model \n",
    "    # 1. Model definition\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    # 2. Train model - patience= number of epochs to wait before early stopping , train_iters= number of iterations\n",
    "    model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    #model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200,metric=metric,\n",
    "               #object=object, initialize=True, verbose=False )\n",
    "    # 3. Evaluate model\n",
    "    model.eval()\n",
    "    output = model.test(idx_test)\n",
    "\n",
    "    accuracy_test_attack_1 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_1 = model.test(idx_test_clean)\n",
    "    print(\"Test accuracy on attack set: \", accuracy_test_attack_1)\n",
    "    print(\"Test accuracy on clean set: \", accuracy_test_clean_1)\n",
    "\n",
    "    \n",
    "    ################################ Mahsa attack ##############################\n",
    "    # Perform the attack\n",
    "    # version 1: attack on the whole graph - on idx_test_attack nodes - by only removing edges\n",
    "\n",
    "    modified_adj1 =  clean_adj1.copy()\n",
    "\n",
    "    # Create a NetworkX graph from the adjacency matrix\n",
    "    graph = nx.from_scipy_sparse_array(modified_adj1)\n",
    "    # Add labels to the graph\n",
    "    for node_id, label in enumerate(labels):\n",
    "        graph.nodes[node_id]['label'] = label\n",
    "    # print(f\"lenght of the labels : {len(labels)}\") \n",
    "    print(f\"graph edges : {graph.number_of_edges()}\")\n",
    "    print(f\"graph nodes : {graph.number_of_nodes()}\")\n",
    "    \n",
    "    # Set the budget for the attack\n",
    "    budget = 470\n",
    "\n",
    "    #attacked_graph is initially set to graph, and then updated after each attack \n",
    "    # This means that each attack is performed on the graph resulting from the previous attacks.\n",
    "    attacked_graph = graph\n",
    "    sorted_count_dict = backdoor.count_neighbor_labels(graph, labels)\n",
    "    print ( f\"idx_test_attack: {idx_test_attack}\")\n",
    "    for target_node in idx_test_attack:\n",
    "        print(f\"target node is: {target_node} with label: {labels[target_node]}\")\n",
    "        neighbors_same_label = backdoor.find_same_neighbor(graph, target_node)\n",
    "        neighbors_opposit_label = backdoor.find_opposit_neighbor(graph, target_node)\n",
    "        print ( f\"number of target same label neighbors before attack: {len(neighbors_same_label)}\")\n",
    "        print ( f\"number of target opposit label neighbors before attack: {len(neighbors_opposit_label)}\")\n",
    "   \n",
    "        attacked_graph,removed_edges,added_edges = backdoor.add_remove_v3(attacked_graph, target_node,sorted_count_dict ,budget)\n",
    "        print(f\"Removed {len(removed_edges)} edges: {removed_edges}\")\n",
    "        print(f\"Added {len(added_edges)} edges: {added_edges}\")    \n",
    "    \n",
    "      \n",
    "    # Convert the graph to a CSR matrix\n",
    "    modified_adj1 =backdoor.convert(attacked_graph)\n",
    "    print(attacked_graph)\n",
    "    #print(f\"total removed edges : {(graph.number_of_edges() - attacked_graph.number_of_edges())}\")\n",
    "\n",
    "\n",
    "    # print( f\"idx_test_attack same all over the graph : {len(sorted_nodes_same)}\")\n",
    "    # print( f\"idx_test_attack opposit label all over the graph: {len(sorted_nodes_opp)}\")\n",
    "    # neighbors_same_after = backdoor.find_same_neighbor(attacked_graph, selected_node)\n",
    "    # neighbors_opposit_after = backdoor.find_opposit_neighbor(attacked_graph, selected_node)\n",
    "    # print ( f\"idx_test_attack same label neighbors after attack: {len(neighbors_same_after)}\")\n",
    "    # print ( f\"idx_test_attack opposit label neighbors after attack: {len(neighbors_opposit_after)}\")\n",
    "    # print ( f\"idx_test_attack same label neighbors: {neighbors_same_label}\")\n",
    "    # print ( f\"idx_test_attack opposit label neighbors: {neighbors_opposit_label}\")\n",
    "    # print (f\"same label all over graph : (node, (num of same label, num of opposit label)){sorted_nodes_same}\")\n",
    "    # print (f\"as above for opposite lables{sorted_nodes_opp}\")\n",
    "    \n",
    "    # def is_neighbor(graph, node1, node2):\n",
    "    #     return graph.has_edge(node1, node2) or graph.has_edge(node2, node1)\n",
    "\n",
    "    # is_neighbor = is_neighbor(attacked_graph, 300, 499)\n",
    "    # print ( f\"label of target node is: {labels[499]}\")\n",
    "    # print ( f\"label of node 300 is: {labels[300]}\")\n",
    "    # print ( is_neighbor)\n",
    "\n",
    "\n",
    "\n",
    "      # check for the differences between the initial graph and the attacked graph----- adj wise\n",
    "    #compare adjs check\n",
    "    diff_adj_attack = modified_adj1 - clean_adj1\n",
    "    non_zero_diff = diff_adj_attack.nonzero()\n",
    "    print(f\"adj wise : modifications after attack: {non_zero_diff}\")\n",
    "    # Count the number of changes\n",
    "    num_changes = len(non_zero_diff[0])/2\n",
    "    print(f\"adj wise: Number of modifications after attack: {num_changes}\")\n",
    "    \n",
    "    n1=list(graph.neighbors(selected_node))\n",
    "    print(f\"{selected_node} has {len(n1)} neighbors before attack and they are: {n1}\")\n",
    "    n2=list(attacked_graph.neighbors(selected_node))\n",
    "    print(f\"{selected_node} has {len(n2)} neighbors after attack and they are: {n2}\")\n",
    "\n",
    "\n",
    "    ################################## Plotting target node before attack  #######################################\n",
    "    # target_subgraph = graph.subgraph([selected_node] + list(neighbors_same_label) + list(neighbors_opposit_label))\n",
    "    # pos = nx.spring_layout(target_subgraph)  # positions for all nodes\n",
    "    # # nodes\n",
    "    # nx.draw_networkx_nodes(target_subgraph, pos, nodelist=neighbors_same_label, node_color='green')\n",
    "    # nx.draw_networkx_nodes(target_subgraph, pos, nodelist=neighbors_opposit_label, node_color='pink')\n",
    "    # # edges\n",
    "    # nx.draw_networkx_edges(target_subgraph, pos, width=1.0, alpha=0.5)\n",
    "    # # labels\n",
    "    # nx.draw_networkx_labels(target_subgraph, pos, font_size=16)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    " \n",
    "    ################################ evaluation after attack ##############################\n",
    "    # accuracy after attack\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    #data = data.to(device)\n",
    "    model.fit(features, modified_adj1, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    model.eval()\n",
    "\n",
    "    # output = model.test(idx_test)\n",
    "\n",
    "    #acc_test = accuracy(output, labels, idx_test)\n",
    "\n",
    "    # output_1 = model.test(idx_test_attack)\n",
    "    # output_2 = model.test(idx_test_clean)\n",
    "\n",
    "    accuracy_test_attack_2 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_2 = model.test(idx_test_clean)\n",
    "\n",
    "    print(\"Test accuracy on attack set after attack: \", accuracy_test_attack_2)\n",
    "    print(\"Test accuracy on clean set after attack: \", accuracy_test_clean_2)\n",
    "\n",
    "    \n",
    "    \n",
    "    ############################ Crypto'Graph defense ###########################\n",
    "    # Perform Crypto'Graph distributed defense\n",
    "    print(\"*************** Crypto'Graph defense ***************\")\n",
    "\n",
    "    threshold = 2               # threshold for dropping dissimilar edges\n",
    "    metric = \"neighbors\"        # metric for dropping dissimilar edges (neighbors, jaccard, cosine)\n",
    "    object = \"links\"            # object for defense (links, features)\n",
    "\n",
    "    model = TwoPartyCNGCN(dataset=dataset, nfeat=features.shape[1], nhid=16, nclass=labels.max().item() + 1,\n",
    "                            device=device)\n",
    "    defense_duration, defense_duration, training_duration1, training_duration2, CG_defended_adj1, CG_defended_adj2 = model.fit(modified_adj1.copy(), adj2.copy(), features, features, labels, idx_train, threshold, metric=metric, object=object,\n",
    "                train_iters=200, initialize=True, verbose=False, idx_val=idx_val)\n",
    "    model.eval()\n",
    "    accuracies = model.test(idx_test)  #accuracy of the model after the defense on all the test data - (all the nodes)\n",
    "    accuracy_test_attack_3 = model.test(idx_test_attack)\n",
    "    accuracy_test_clean_3 = model.test(idx_test_clean)\n",
    "    print(\"Test accuracy on attack set after Crypto'Graph: \", accuracy_test_attack_3)\n",
    "    print(\"Test accuracy on clean set after Crypto'Graph: \", accuracy_test_clean_3)\n",
    "\n",
    "    \n",
    "    rows = CG_defended_adj1.shape[0]\n",
    "    print(f\"CG_defended_adj1. Number of rows: {rows}\")\n",
    "    \n",
    "    \n",
    "     ############################## adj wise compare by adj1 and modified_adj1 (before and after defense)\n",
    "    print(\"*************** adj wise compare (before and after defense) ***************\")\n",
    "    differences = np.abs(CG_defended_adj1 - modified_adj1)\n",
    "    total_differences = np.sum(differences)\n",
    "    # print(f\"adj check: differences: {differences}\")\n",
    "    print(f\"adj check: Total number of differences: {total_differences}\")\n",
    "    rows_with_changes = np.count_nonzero(np.sum(differences, axis=1))\n",
    "    print(f\"Number of rows with changes: {rows_with_changes}\")\n",
    "    changed_rows = np.where(np.sum(differences, axis=1) > 0)[0]\n",
    "    print(f\"Rows with different connectivities: {changed_rows}\")\n",
    "\n",
    "\n",
    "    # Compute the difference matrix for the full symmetric matrix\n",
    "    difference_matrix = CG_defended_adj1 - modified_adj1\n",
    "    # Identify the removed edges (negative values in the difference matrix)\n",
    "    removed_edges = np.argwhere(difference_matrix < 0)\n",
    "    # print(\"Removed edges (row, col):\")\n",
    "    # for edge in removed_edges:\n",
    "    #     print(edge)\n",
    "    total_removed_edges = len(removed_edges)\n",
    "    print(f\"Total number of removed edges considering full symetric matrix: {total_removed_edges}\")\n",
    "\n",
    "    # compute the difference matrix for the upper triangle of the symmetric matrix \n",
    "    # Get the indices of the upper triangle of the matrix, excluding the diagonal\n",
    "    rows, cols = np.triu_indices_from(difference_matrix, k=1)\n",
    "    # Select only the upper triangle (excluding diagonal) from the difference matrix\n",
    "    upper_triangle_differences = difference_matrix[rows, cols]\n",
    "    # Identify the removed edges in the upper triangle (negative values)\n",
    "    removed_edges = np.argwhere(upper_triangle_differences < 0)\n",
    "    # Count the total number of removed edges\n",
    "    total_removed_edges = len(removed_edges)\n",
    "    print(f\"Total number of removed edges(adj): {total_removed_edges}\")\n",
    "    # Print the removed edges\n",
    "    # print(\"Removed edges in adjacency matrix (row, col):\")\n",
    "    # for edge in removed_edges:\n",
    "    #     print(edge)\n",
    "\n",
    "\n",
    "      \n",
    "    ################################ check exact edges which are removed by CG defense ################\n",
    "    # Identify the edges added during the attack\n",
    "    added_edges = []\n",
    "    modified_adj1_array = modified_adj1.toarray()\n",
    "    clean_adj1_array = clean_adj1.toarray()\n",
    "\n",
    "    rows, cols = np.triu_indices(modified_adj1_array.shape[0], k=1)\n",
    "    for i, j in zip(rows, cols):\n",
    "        if modified_adj1_array[i, j] == 1 and clean_adj1_array[i, j] == 0:\n",
    "            added_edges.append((i, j))\n",
    "    print(f\"Added edges during attack: {added_edges}\")\n",
    "\n",
    "    # Check if the added edges are removed by CG defense\n",
    "    removed_edges_by_CG = []\n",
    "    CG_defended_adj1_array = CG_defended_adj1.toarray()\n",
    "\n",
    "    for edge in added_edges:\n",
    "        i, j = edge\n",
    "        if CG_defended_adj1_array[i, j] == 0:\n",
    "            removed_edges_by_CG.append(edge)\n",
    "    print(f\"Removed edges by CG defense: {removed_edges_by_CG}\")\n",
    "   \n",
    "\n",
    "    \n",
    "     ###### check if  added edges via CG defense\n",
    "    difference_matrix_add = modified_adj1 - CG_defended_adj1 \n",
    "    rows, cols = np.triu_indices_from(difference_matrix_add, k=1)\n",
    "    upper_triangle_add = difference_matrix_add[rows, cols]\n",
    "    added_edges = np.argwhere(upper_triangle_add < 0)\n",
    "    total_added_edges = len(added_edges)\n",
    "    print(f\"Total number of added edges via CG (adj): {total_added_edges}\")\n",
    "   \n",
    "\n",
    "\n",
    "    #######  graph wise compare by adj1 and modified_adj1 (before and after defense) \n",
    "    print(\"*************** graph wise compare for removed or added edges by CG (before and after defense) ***************\")\n",
    "    # Remove zero-weight edges\n",
    "    modified_adj1_cleaned = backdoor.remove_zero_weight_edges(modified_adj1.copy())\n",
    "    CG_defended_adj1_cleaned = backdoor.remove_zero_weight_edges(CG_defended_adj1.copy())\n",
    "\n",
    "    #Create a NetworkX graph from the adjacency matrix\n",
    "    graph_modified_adj1 = nx.from_scipy_sparse_array(modified_adj1_cleaned) #before defense\n",
    "    graph_CG_1 = nx.from_scipy_sparse_array(CG_defended_adj1_cleaned) # after defense\n",
    "\n",
    "    # print(graph_CG_1)\n",
    "    print(f\"graph graph_modifeid_adj1 before CG: {graph_modified_adj1.number_of_edges()} edges\")\n",
    "    print(f\"graph graph_CG_1 after CG: {graph_CG_1.number_of_edges()} edges\")\n",
    "\n",
    "    # Identify removed edges in the graph\n",
    "    # removed_edges_graph = set(graph_modified_adj1.edges()) - set(graph_CG_1.edges())\n",
    "    removed_edges_graph = set(attacked_graph.edges()) - set(graph_CG_1.edges())\n",
    "    # Print the removed edges\n",
    "    # print(\"Removed edges in NetworkX graphs (node1, node2):\")\n",
    "    # for edge in removed_edges_graph:\n",
    "    #     print(edge)\n",
    "    # Total number of removed edges\n",
    "    total_removed_edges_graph = len(removed_edges_graph)\n",
    "    print(f\"Total number of removed edges (NetworkX graphs): {total_removed_edges_graph}\")\n",
    "\n",
    "    edges_added_by_CryptoGraph = set(graph_CG_1.edges()) - set(attacked_graph.edges())\n",
    "    print(f\"Total number of edges added by Crypto'Graph: {len(edges_added_by_CryptoGraph)}\")\n",
    "    print(\"Edges added by Crypto'Graph (node1, node2):\")\n",
    "    for edge in edges_added_by_CryptoGraph:\n",
    "        print(edge)\n",
    "\n",
    "    print(\"*************** graph wise - check if removed/added edges are detected by CG ***************\")\n",
    "    # if inserted edges are eremoved or not: NX graphs\n",
    "    added_by_attack = (set(attacked_graph.edges()) - set(graph.edges()) )\n",
    "    print(f\"Total number of edges added by the attack: {len(added_by_attack)}\")\n",
    "    print(\"added edges (node1, node2):\")\n",
    "    for edge in added_by_attack:\n",
    "        print(edge)\n",
    "    \n",
    "    removed_by_attack = (set(graph.edges()) - set(attacked_graph.edges()) )\n",
    "    print(f\"Total number of edges deleted by the attack: {len(removed_by_attack)}\")\n",
    "    print(\"removed edges (node1, node2):\")\n",
    "    for edge in removed_by_attack:\n",
    "        print(edge)\n",
    "   \n",
    "    # Check if changed edges via attack have been detected by Crypto'Graph defense\n",
    "    added_edges_detected = added_by_attack - set(graph_CG_1.edges())\n",
    "    # Print deleted inserted edges\n",
    "    print(\"added edges detected and removed by Crypto'Graph defense (node1, node2):\")\n",
    "    for edge in added_edges_detected:\n",
    "        print(edge)\n",
    "    print(f\"Total number of added edges detected and removed by Crypto'Graph: {len(added_edges_detected)}\")\n",
    "\n",
    "\n",
    "    removed_edges_detected = removed_by_attack & set(graph_CG_1.edges())\n",
    "    print(\"removed edges detected and readded by Crypto'Graph defense (node1, node2):\")\n",
    "    for edge in removed_edges_detected:\n",
    "        print(edge)\n",
    "    print(f\"Total number of removed edges detected and readded by Crypto'Graph: {len(removed_edges_detected)}\")\n",
    "\n",
    "  \n",
    "    ####another ay : \n",
    "    # Calculate intersection of inserted and removed edges\n",
    "    intersected_edges = added_by_attack.intersection(removed_edges_graph)\n",
    "    # Check if any inserted edge was removed\n",
    "    if intersected_edges:\n",
    "        print(\"Inserted edges that were removed (node1, node2):\")\n",
    "        for edge in intersected_edges:\n",
    "            print(edge)\n",
    "    else:\n",
    "        print(\"No inserted edges were removed.\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    # At the end of each repeat, append the accuracy values to the lists:\n",
    "    accuracy_test_attack_1_values.append(accuracy_test_attack_1)\n",
    "    accuracy_test_clean_1_values.append(accuracy_test_clean_1)\n",
    "    accuracy_test_attack_2_values.append(accuracy_test_attack_2)\n",
    "    accuracy_test_clean_2_values.append(accuracy_test_clean_2)\n",
    "    accuracy_test_attack_3_values.append(accuracy_test_attack_3)\n",
    "    accuracy_test_clean_3_values.append(accuracy_test_clean_3)\n",
    "\n",
    "\n",
    "\n",
    "####################### Standard deviation values ############################\n",
    "# Calculate the standard deviation of the accuracy values:\n",
    "accuracy_test_attack_1_std = np.std(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_std = np.std(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_std = np.std(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_std = np.std(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_std = np.std(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_std = np.std(accuracy_test_clean_3_values)\n",
    "\n",
    "# Save the standard deviation values to a file\n",
    "with open('variables_std.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "                 accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "                 accuracy_test_attack_3_std, accuracy_test_clean_3_std], f)\n",
    "\n",
    "\n",
    "####################### Average accuracy values ############################\n",
    "# Calculate the average accuracy values:\n",
    "accuracy_test_attack_1_avg = np.mean(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_avg = np.mean(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_avg = np.mean(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_avg = np.mean(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_avg = np.mean(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_avg = np.mean(accuracy_test_clean_3_values)\n",
    "\n",
    "with open('variables.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "                 accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "                 accuracy_test_attack_3_avg, accuracy_test_clean_3_avg], f)\n",
    "\n",
    "################################# Plotting Training Results #######################################\n",
    "labels = ['ACCs before attack', 'ACCs before attack', \n",
    "          'ACCs after attack', 'ACCs after attack', \n",
    "          'ACCs after CryptoGraph', 'ACCs after CryptoGraph']\n",
    "values = [accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "          accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "          accuracy_test_attack_3_avg, accuracy_test_clean_3_avg]\n",
    "std_devs = [accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "            accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "            accuracy_test_attack_3_std, accuracy_test_clean_3_std]\n",
    "# Define the x-coordinates of the bars and the width of the bars\n",
    "x = np.arange(len(labels)//2)\n",
    "width = 0.35\n",
    "# Create the bar chart with error bars\n",
    "bars1 = plt.bar(x - width/2, values[::2], width, yerr=std_devs[::2], label='Attack set', color='red', capsize=5)\n",
    "bars2 = plt.bar(x + width/2, values[1::2], width, yerr=std_devs[1::2], label='Clean set', color='blue', capsize=5)\n",
    "# Add a title and labels to the axes\n",
    "plt.title('Average Accuracies')\n",
    "plt.xlabel('Levels of Attack and Defense')\n",
    "plt.ylabel('Average Accuracy')\n",
    "# Make the x-labels vertical\n",
    "plt.xticks(x, labels[::2])\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "# Add exact values on each bar\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "# Adjust the layout to prevent the labels from being cut off\n",
    "plt.tight_layout()\n",
    "# Display the chart\n",
    "plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###nemoodar mese aubin baraye graph ha\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "t_values = np.linspace(0, 0.5, 50)\n",
    "accuracy_values = {\n",
    "    'local_jaccard_defense': np.random.random(50),\n",
    "    'local_cosine_defense': np.random.random(50),\n",
    "    'local_common_neighbors_defense': np.random.random(50),\n",
    "    'distributed_jaccard_defense': np.random.random(50),\n",
    "    'distributed_cosine_defense': np.random.random(50),\n",
    "    'distributed_common_neighbors_defense': np.random.random(50),\n",
    "}\n",
    "\n",
    "# Creating subplots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Plotting on the first subplot\n",
    "for key, values in accuracy_values.items():\n",
    "    axs[0, 0].plot(t_values, values, label=key.replace('_', ' '))\n",
    "\n",
    "axs[0, 0].set_title('No Attack')\n",
    "axs[0, 0].set_xlabel('t (Jaccard and Cosine)')\n",
    "axs[0, 0].set_ylabel('Accuracy')\n",
    "axs[0, 0].legend(loc='best')\n",
    "axs[0, 0].grid(True)\n",
    "\n",
    "# Similarly, you can plot on other subplots\n",
    "# This is a placeholder for illustration. You need to plot the actual data accordingly.\n",
    "\n",
    "# Adding titles and labels for remaining subplots (repeat as necessary)\n",
    "# axs[0, 1].set_title('FGSM')\n",
    "# axs[1, 0].set_title('NETTACK')\n",
    "# axs[1, 1].set_title('DICE')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### change V3.1 for working just in adj mode #############\n",
    "################### V3.1 : Attack by removing edges + adding edge: (le budget change selon l’importance pour ajouter/enlever) ###############\n",
    "################### Attack by removing edges + adding edges: for 10% nodes, for one node, for manually selection of nodes \n",
    "# Define the number of repeats\n",
    "num_repeats = 1\n",
    "accuracy_test_attack_1_values = []\n",
    "accuracy_test_clean_1_values = []\n",
    "accuracy_test_attack_2_values = []\n",
    "accuracy_test_clean_2_values = []\n",
    "accuracy_test_attack_3_values = []\n",
    "accuracy_test_clean_3_values = []\n",
    "\n",
    "seed = 42  # Seed for reproducibility\n",
    "# Function to set seeds for reproducibility\n",
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "################################ Data loading #######################################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "dataset = \"polblogs\"\n",
    "# Use the current directory for windows\n",
    "data = Dataset(root='.', name=dataset, setting='gcn', seed=15)\n",
    "#data = Dataset(root='/tmp/', name=dataset): this is for unix-based systems\n",
    "\n",
    "for _ in range(num_repeats):\n",
    "    \n",
    "    #############################  preprocessing ############################\n",
    "    set_seeds(seed)\n",
    "    adj, features, labels = data.adj, data.features, data.labels\n",
    "    idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "    ################### split idx_test into two parts : one node for attack randomley and the rest for clean\n",
    "    # test_size = 1  # 1 node for attack others for test_clean\n",
    "    # idx_test_clean , idx_test_attack = train_test_split(idx_test, test_size=test_size, random_state=42)\n",
    "    # selected_node = idx_test_attack[0]\n",
    "    # print(f\"Selected node for attack: {selected_node}\")\n",
    "    # print(f\"Label of the selected node: {labels[selected_node]}\")\n",
    "    ######################\n",
    "\n",
    "    ############### choose a node for attack manually (the one which has been chosen randomely from idx_test in the previous part)\n",
    "    selected_node = 1196\n",
    "    idx_test_attack = np.array([selected_node])\n",
    "    idx_test_clean = np.array([node for node in idx_test if node != selected_node])\n",
    "    print(f\"Selected node for attack: {selected_node}\")\n",
    "    print(f\"Label of the selected node: {labels[selected_node]}\")\n",
    "    ######################\n",
    "\n",
    "    ################ split idx_test into two parts randomly with a specific ratio %\n",
    "    # test_size = 0.10  # 10% for test_attack, 90% for test_clean\n",
    "    # idx_test_clean , idx_test_attack = train_test_split(idx_test, test_size=test_size, random_state=seed)\n",
    "    ######################\n",
    "\n",
    "    # Split graph into two graphs for Crypto'Graph\n",
    "    proportion_of_common_links = 0.5\n",
    "    adj1, adj2 = split_dataset(adj, proportion_of_common_links) \n",
    "\n",
    "   \n",
    "     # Ensure adj1 and adj2 are in sparse format\n",
    "    adj1 = sp.csr_matrix(adj1)\n",
    "    adj2 = sp.csr_matrix(adj2)\n",
    "    # Remove zero-weight edges\n",
    "    clean_adj1 = backdoor.remove_zero_weight_edges(adj1.copy())\n",
    "    clean_adj2 = backdoor.remove_zero_weight_edges(adj2.copy())\n",
    "    \n",
    "    #check neighbors of the selected node\n",
    "    neighbors_vector = adj1[selected_node, :].toarray()\n",
    "    neighbors_indices = np.nonzero(neighbors_vector)[1]  #  Get the indices of the neighbors\n",
    "    print(f\"num of neighbors of node {selected_node} is: {len(neighbors_indices)}\")\n",
    "    print(\"Neighbors of node\", selected_node, \"are:\", neighbors_indices)\n",
    "\n",
    "\n",
    "    ############################ train model initially and test accuracy ###########################\n",
    "    # Perform evaluation before attack to find the baseline accuracy\n",
    "\n",
    "    # Train GCN model \n",
    "    # 1. Model definition\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    # 2. Train model - patience= number of epochs to wait before early stopping , train_iters= number of iterations\n",
    "    model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    #model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200,metric=metric,\n",
    "               #object=object, initialize=True, verbose=False )\n",
    "    # 3. Evaluate model\n",
    "    model.eval()\n",
    "    output = model.test(idx_test)\n",
    "\n",
    "    accuracy_test_attack_1 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_1 = model.test(idx_test_clean)\n",
    "    print(\"Test accuracy on attack set: \", accuracy_test_attack_1)\n",
    "    print(\"Test accuracy on clean set: \", accuracy_test_clean_1)\n",
    "\n",
    "    \n",
    "    ################################ Mahsa attack ##############################\n",
    "    # Perform the attack\n",
    "    modified_adj1 =  clean_adj1.copy()\n",
    "    print(f\"Initial number of edges: {modified_adj1.nnz // 2}\")\n",
    "    print(f\"Number of nodes: {modified_adj1.shape[0]}\")\n",
    "\n",
    "    # Set the budget for the attack\n",
    "    budget = 20\n",
    "\n",
    "    #attack adj \n",
    "    attacked_adj = modified_adj1.copy()\n",
    "    sorted_count_dict = backdoor.count_neighbor_labels_adj(attacked_adj, labels)\n",
    "    print(f\"idx_test_attack: {idx_test_attack}\")\n",
    "    for target_node in idx_test_attack:\n",
    "        print(f\"Target node is: {target_node} with label: {labels[target_node]}\")\n",
    "        neighbors_same_label = backdoor.find_same_neighbor_adj(attacked_adj, labels, target_node)\n",
    "        neighbors_opposit_label = backdoor.find_opposite_neighbor_adj(attacked_adj, labels, target_node)\n",
    "        print(f\"Number of target same label neighbors before attack: {len(neighbors_same_label)}\")\n",
    "        print(f\"Number of target opposite label neighbors before attack: {len(neighbors_opposit_label)}\")\n",
    "\n",
    "        attacked_adj, removed_edges, added_edges = backdoor.add_remove_adj(attacked_adj, target_node, sorted_count_dict, labels, budget)\n",
    "        print(f\"Removed {len(removed_edges)} edges: {removed_edges}\")\n",
    "        print(f\"Added {len(added_edges)} edges: {added_edges}\")\n",
    "\n",
    "\n",
    "    # Convert the adjacency matrix to a CSR matrix\n",
    "    #we can omit this and just replace the modified_adj1 with attacked_adj\n",
    "    modified_adj1 = csr_matrix(attacked_adj)\n",
    "    print(modified_adj1)\n",
    "\n",
    "\n",
    "    # check for the differences between the initial graph and the attacked graph----- adj wise\n",
    "    #compare adjs check\n",
    "    diff_adj_attack = modified_adj1 - clean_adj1\n",
    "    non_zero_diff = diff_adj_attack.nonzero()\n",
    "    print(f\"adj wise : modifications after attack: {non_zero_diff}\")\n",
    "    # Count the number of changes\n",
    "    num_changes = len(non_zero_diff[0])/2\n",
    "    print(f\"adj wise: Number of modifications after attack: {num_changes}\")\n",
    "    \n",
    "\n",
    "    ################################ evaluation after attack ##############################\n",
    "    # accuracy after attack\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    #data = data.to(device)\n",
    "    model.fit(features, modified_adj1, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    model.eval()\n",
    "\n",
    "    accuracy_test_attack_2 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_2 = model.test(idx_test_clean)\n",
    "\n",
    "    print(\"Test accuracy on attack set after attack: \", accuracy_test_attack_2)\n",
    "    print(\"Test accuracy on clean set after attack: \", accuracy_test_clean_2)\n",
    "\n",
    "    \n",
    "    \n",
    "    ############################ Crypto'Graph defense ###########################\n",
    "    # Perform Crypto'Graph distributed defense\n",
    "    print(\"*************** Crypto'Graph defense ***************\")\n",
    "\n",
    "    threshold = 2               # threshold for dropping dissimilar edges\n",
    "    metric = \"neighbors\"        # metric for dropping dissimilar edges (neighbors, jaccard, cosine)\n",
    "    object = \"links\"            # object for defense (links, features)\n",
    "\n",
    "    model = TwoPartyCNGCN(dataset=dataset, nfeat=features.shape[1], nhid=16, nclass=labels.max().item() + 1,\n",
    "                            device=device)\n",
    "    defense_duration, defense_duration, training_duration1, training_duration2, CG_defended_adj1, CG_defended_adj2 = model.fit(modified_adj1.copy(), adj2.copy(), features, features, labels, idx_train, threshold, metric=metric, object=object,\n",
    "                train_iters=200, initialize=True, verbose=False, idx_val=idx_val)\n",
    "    model.eval()\n",
    "    accuracies = model.test(idx_test)  #accuracy of the model after the defense on all the test data - (all the nodes)\n",
    "    accuracy_test_attack_3 = model.test(idx_test_attack)\n",
    "    accuracy_test_clean_3 = model.test(idx_test_clean)\n",
    "    print(\"Test accuracy on attack set after Crypto'Graph: \", accuracy_test_attack_3)\n",
    "    print(\"Test accuracy on clean set after Crypto'Graph: \", accuracy_test_clean_3)\n",
    "\n",
    "    \n",
    "    rows = CG_defended_adj1.shape[0]\n",
    "    print(f\"CG_defended_adj1. Number of rows: {rows}\")\n",
    "    \n",
    "    \n",
    "     ############################## adj wise compare by adj1 and modified_adj1 (before and after defense)\n",
    "    print(\"*************** adj wise compare (before and after defense) ***************\")\n",
    "    differences = np.abs(CG_defended_adj1 - modified_adj1)\n",
    "    total_differences = np.sum(differences)\n",
    "    # print(f\"adj check: differences: {differences}\")\n",
    "    print(f\"adj check: Total number of differences: {total_differences}\")\n",
    "    rows_with_changes = np.count_nonzero(np.sum(differences, axis=1))\n",
    "    print(f\"Number of rows with changes: {rows_with_changes}\")\n",
    "    changed_rows = np.where(np.sum(differences, axis=1) > 0)[0]\n",
    "    print(f\"Rows with different connectivities: {changed_rows}\")\n",
    "\n",
    "\n",
    "    # Compute the difference matrix for the full symmetric matrix\n",
    "    difference_matrix = CG_defended_adj1 - modified_adj1\n",
    "\n",
    "    # compute the difference matrix for the upper triangle of the symmetric matrix \n",
    "    # Get the indices of the upper triangle of the matrix, excluding the diagonal\n",
    "    rows, cols = np.triu_indices_from(difference_matrix, k=1)\n",
    "    # Select only the upper triangle (excluding diagonal) from the difference matrix\n",
    "    upper_triangle_differences = difference_matrix[rows, cols]\n",
    "    # Identify the removed edges in the upper triangle (negative values)\n",
    "    removed_edges = np.argwhere(upper_triangle_differences < 0)\n",
    "    # Count the total number of removed edges\n",
    "    total_removed_edges = len(removed_edges)\n",
    "    print(f\"Total number of removed edges(adj): {total_removed_edges}\")\n",
    "    # Print the removed edges\n",
    "    # print(\"Removed edges in adjacency matrix (row, col):\")\n",
    "    # for edge in removed_edges:\n",
    "    #     print(edge)\n",
    "\n",
    "\n",
    "      \n",
    "    ################################ check exact edges which are removed by CG defense ################\n",
    "    # Identify the edges added during the attack\n",
    "    added_edges = []\n",
    "    modified_adj1_array = modified_adj1.toarray()\n",
    "    clean_adj1_array = clean_adj1.toarray()\n",
    "\n",
    "    rows, cols = np.triu_indices(modified_adj1_array.shape[0], k=1)\n",
    "    for i, j in zip(rows, cols):\n",
    "        if modified_adj1_array[i, j] == 1 and clean_adj1_array[i, j] == 0:\n",
    "            added_edges.append((i, j))\n",
    "    print(f\"Added edges during attack: {added_edges}\")\n",
    "    print(f\"Total number of added edges during attack: {len(added_edges)}\")\n",
    "\n",
    "    # Check if the added edges are removed by CG defense\n",
    "    removed_edges_by_CG = []\n",
    "    CG_defended_adj1_array = CG_defended_adj1.toarray()\n",
    "\n",
    "    for edge in added_edges:\n",
    "        i, j = edge\n",
    "        if CG_defended_adj1_array[i, j] == 0:\n",
    "            removed_edges_by_CG.append(edge)\n",
    "    print(f\"Removed edges which have been added during attack by CG defense: {removed_edges_by_CG}\")\n",
    "   \n",
    "\n",
    "    ###### check if CG defense adds any edges\n",
    "    difference_matrix_add = modified_adj1 - CG_defended_adj1 \n",
    "    rows, cols = np.triu_indices_from(difference_matrix_add, k=1)\n",
    "    upper_triangle_add = difference_matrix_add[rows, cols]\n",
    "    added_edges = np.argwhere(upper_triangle_add < 0)\n",
    "    total_added_edges = len(added_edges)\n",
    "    print(f\"CG doesn't add edges. Total number of added edges via CG (adj): {total_added_edges}\")\n",
    "   \n",
    "\n",
    "     \n",
    "    # At the end of each repeat, append the accuracy values to the lists:\n",
    "    accuracy_test_attack_1_values.append(accuracy_test_attack_1)\n",
    "    accuracy_test_clean_1_values.append(accuracy_test_clean_1)\n",
    "    accuracy_test_attack_2_values.append(accuracy_test_attack_2)\n",
    "    accuracy_test_clean_2_values.append(accuracy_test_clean_2)\n",
    "    accuracy_test_attack_3_values.append(accuracy_test_attack_3)\n",
    "    accuracy_test_clean_3_values.append(accuracy_test_clean_3)\n",
    "\n",
    "\n",
    "\n",
    "####################### Standard deviation values ############################\n",
    "# Calculate the standard deviation of the accuracy values:\n",
    "accuracy_test_attack_1_std = np.std(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_std = np.std(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_std = np.std(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_std = np.std(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_std = np.std(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_std = np.std(accuracy_test_clean_3_values)\n",
    "\n",
    "# Save the standard deviation values to a file\n",
    "with open('variables_std.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "                 accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "                 accuracy_test_attack_3_std, accuracy_test_clean_3_std], f)\n",
    "\n",
    "\n",
    "####################### Average accuracy values ############################\n",
    "# Calculate the average accuracy values:\n",
    "accuracy_test_attack_1_avg = np.mean(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_avg = np.mean(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_avg = np.mean(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_avg = np.mean(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_avg = np.mean(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_avg = np.mean(accuracy_test_clean_3_values)\n",
    "\n",
    "with open('variables.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "                 accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "                 accuracy_test_attack_3_avg, accuracy_test_clean_3_avg], f)\n",
    "\n",
    "################################# Plotting Training Results #######################################\n",
    "labels = ['ACCs before attack', 'ACCs before attack', \n",
    "          'ACCs after attack', 'ACCs after attack', \n",
    "          'ACCs after CryptoGraph', 'ACCs after CryptoGraph']\n",
    "values = [accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "          accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "          accuracy_test_attack_3_avg, accuracy_test_clean_3_avg]\n",
    "std_devs = [accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "            accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "            accuracy_test_attack_3_std, accuracy_test_clean_3_std]\n",
    "# Define the x-coordinates of the bars and the width of the bars\n",
    "x = np.arange(len(labels)//2)\n",
    "width = 0.35\n",
    "# Create the bar chart with error bars\n",
    "bars1 = plt.bar(x - width/2, values[::2], width, yerr=std_devs[::2], label='Attack set', color='red', capsize=5)\n",
    "bars2 = plt.bar(x + width/2, values[1::2], width, yerr=std_devs[1::2], label='Clean set', color='blue', capsize=5)\n",
    "# Add a title and labels to the axes\n",
    "plt.title('Average Accuracies')\n",
    "plt.xlabel('Levels of Attack and Defense')\n",
    "plt.ylabel('Average Accuracy')\n",
    "# Make the x-labels vertical\n",
    "plt.xticks(x, labels[::2])\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "# Add exact values on each bar\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "# Adjust the layout to prevent the labels from being cut off\n",
    "plt.tight_layout()\n",
    "# Display the chart\n",
    "plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### mahsa-V4.1: using surrogate model for attack ################\n",
    "# attack adding/removing edge: (le budget adaptatif pour ajouter/enlever) ###############\n",
    "# surrogat model for each edge to be added or removed, target nodes selected manually\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from deeprobust.graph.defense import GCN\n",
    "from deeprobust.graph.targeted_attack import FGA\n",
    "from deeprobust.graph.utils import *\n",
    "from deeprobust.graph.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from experiments import split_dataset\n",
    "from DistributedDefense import TwoPartyCNGCN\n",
    "import networkx as nx\n",
    "from scipy.sparse import csr_matrix\n",
    "import mahsa_backdoor as backdoor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random # for random choice of nodes\n",
    "import logging # for logging file\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import scipy.sparse as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Define the number of repeats\n",
    "num_repeats = 1\n",
    "accuracy_test_attack_1_values = []\n",
    "accuracy_test_clean_1_values = []\n",
    "accuracy_test_attack_2_values = []\n",
    "accuracy_test_clean_2_values = []\n",
    "accuracy_test_attack_3_values = []\n",
    "accuracy_test_clean_3_values = []\n",
    "\n",
    "seed = 42  # Seed for reproducibility\n",
    "\n",
    "# Function to set seeds for reproducibility\n",
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# fonction to train surrogate model\n",
    "def train_surrogate_model(features, adj, labels, idx_train, idx_val):\n",
    "    surrogate_model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                          nhid=16, device=device, dropout=0.5)   # lr=0.01, weight_decay=5e-4, with_relu=True, with_bias=True\n",
    "    surrogate_model = surrogate_model.to(device)\n",
    "    surrogate_model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    return surrogate_model\n",
    "\n",
    "# function to evaluate the impact of adding/removing an edge on the model's output using the surrogate model\n",
    "def evaluate_edge_impact(surrogate_model, features, adj, labels, edge, target_node, add=True):\n",
    "    adj = adj.copy()\n",
    "    if add:\n",
    "        adj[edge[0], edge[1]] = 1\n",
    "        adj[edge[1], edge[0]] = 1\n",
    "    else:\n",
    "        adj[edge[0], edge[1]] = 0\n",
    "        adj[edge[1], edge[0]] = 0\n",
    "    \n",
    "    surrogate_model.eval()\n",
    "    output = surrogate_model.predict(features, adj)\n",
    "    target_label_change = output[target_node].argmax().item() != labels[target_node]\n",
    "    other_labels_unchanged = all(output[node].argmax().item() == labels[node] for node in range(adj.shape[0]) if node != target_node)\n",
    "    \n",
    "\n",
    "    print(f\"Edge: {edge}, Target node: {target_node}, Add: {add}, Target label change: {target_label_change}, Other labels unchanged: {other_labels_unchanged}\")\n",
    "    # Return True if the target node’s label changes and other nodes' labels remain unchanged.\n",
    "    return target_label_change # and other_labels_unchanged\n",
    "\n",
    "#  define potential edges to add and evaluate the impact of adding each edge\n",
    "def select_best_edge_to_add(adj, labels, target_node, surrogate_model, features):\n",
    "    potential_edges = []    \n",
    "    for i in range(adj.shape[0]):\n",
    "        if adj[target_node, i] == 0:\n",
    "            potential_edges.append((target_node, i))\n",
    "    \n",
    "    best_edge = None\n",
    "    for edge in potential_edges:\n",
    "        if evaluate_edge_impact(surrogate_model, features, adj, labels, edge, target_node, add=True):\n",
    "            best_edge = edge\n",
    "            break\n",
    "    \n",
    "    return best_edge\n",
    "\n",
    "def select_best_edge_to_remove(adj, labels, target_node, surrogate_model, features):\n",
    "    neighbors = np.nonzero(adj[target_node])[1]\n",
    "    best_edge = None\n",
    "    for neighbor in neighbors:\n",
    "        edge = (target_node, neighbor)\n",
    "        if evaluate_edge_impact(surrogate_model, features, adj, labels, edge, target_node, add=False):\n",
    "            best_edge = edge\n",
    "            break\n",
    "    \n",
    "    return best_edge\n",
    "################################ Data loading #######################################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "dataset = \"polblogs\"\n",
    "data = Dataset(root='.', name=dataset, setting='gcn', seed=15)\n",
    "\n",
    "for _ in range(num_repeats):\n",
    "    set_seeds(seed)\n",
    "    adj, features, labels = data.adj, data.features, data.labels\n",
    "    idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "    selected_node = 1196\n",
    "    idx_test_attack = np.array([selected_node])\n",
    "    idx_test_clean = np.array([node for node in idx_test if node != selected_node])\n",
    "    print(f\"Selected node for attack: {selected_node}\")\n",
    "    print(f\"Label of the selected node: {labels[selected_node]}\")\n",
    "\n",
    "    proportion_of_common_links = 0.5\n",
    "    adj1, adj2 = split_dataset(adj, proportion_of_common_links) \n",
    "\n",
    "    adj1 = sp.csr_matrix(adj1)\n",
    "    adj2 = sp.csr_matrix(adj2)\n",
    "    clean_adj1 = backdoor.remove_zero_weight_edges(adj1.copy())\n",
    "    clean_adj2 = backdoor.remove_zero_weight_edges(adj2.copy())\n",
    "    \n",
    "    neighbors_vector = adj1[selected_node, :].toarray()\n",
    "    neighbors_indices = np.nonzero(neighbors_vector)[1]\n",
    "    print(f\"num of neighbors of node {selected_node} is: {len(neighbors_indices)}\")\n",
    "    print(\"Neighbors of node\", selected_node, \"are:\", neighbors_indices)\n",
    "\n",
    "    ###### Train GCN model initially for evaluation before attack\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    model.eval()\n",
    "    output = model.test(idx_test)\n",
    "\n",
    "    accuracy_test_attack_1 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_1 = model.test(idx_test_clean)\n",
    "    print(\"Test accuracy on attack set: \", accuracy_test_attack_1)\n",
    "    print(\"Test accuracy on clean set: \", accuracy_test_clean_1)\n",
    "\n",
    "    ######## train surrogate model to find the importance of each edge\n",
    "    surrogate_model = train_surrogate_model(features, adj, labels, idx_train, idx_val)\n",
    "\n",
    "    modified_adj1 =  clean_adj1.copy()\n",
    "    print(f\"Initial number of edges: {modified_adj1.nnz // 2}\")\n",
    "    print(f\"Number of nodes: {modified_adj1.shape[0]}\")\n",
    "\n",
    "    budget = 9\n",
    "\n",
    "    ############### attack adj ################\n",
    "    attacked_adj = modified_adj1.copy()\n",
    "    sorted_count_dict = backdoor.count_neighbor_labels_adj(attacked_adj, labels)\n",
    "    print(f\"idx_test_attack: {idx_test_attack}\")\n",
    "\n",
    "    for target_node in idx_test_attack:\n",
    "        print(f\"Target node is: {target_node} with label: {labels[target_node]}\")\n",
    "        neighbors_same_label = backdoor.find_same_neighbor_adj(attacked_adj, labels, target_node)\n",
    "        neighbors_opposit_label = backdoor.find_opposite_neighbor_adj(attacked_adj, labels, target_node)\n",
    "        print(f\"Number of target same label neighbors before attack: {len(neighbors_same_label)}\")\n",
    "        print(f\"Number of target opposite label neighbors before attack: {len(neighbors_opposit_label)}\")\n",
    "\n",
    "\n",
    "        # attacked_adj, removed_edges, added_edges = backdoor.add_remove_adj(attacked_adj, target_node, sorted_count_dict, labels, budget)\n",
    "\n",
    "        for _ in range(budget):\n",
    "            edge_add = select_best_edge_to_add(attacked_adj, labels, target_node, surrogate_model, features)\n",
    "            edge_remove = select_best_edge_to_remove(attacked_adj, labels, target_node, surrogate_model, features)\n",
    "            print (f\"edge_add: {edge_add}, edge_remove: {edge_remove}\")\n",
    "            # print(f\" num of added edges: {len(edge_add)}, num of removed edges: {len(edge_remove)}\")\n",
    "\n",
    "            if edge_add:\n",
    "                attacked_adj[edge_add[0], edge_add[1]] = 1\n",
    "                attacked_adj[edge_add[1], edge_add[0]] = 1\n",
    "                print(f\"Added edge: {edge_add}\")\n",
    "            \n",
    "            if edge_remove:\n",
    "                attacked_adj[edge_remove[0], edge_remove[1]] = 0\n",
    "                attacked_adj[edge_remove[1], edge_remove[0]] = 0\n",
    "                print(f\"Removed edge: {edge_remove}\")\n",
    "\n",
    "    \n",
    "    ########## checkin the adj wise changes after attack ##########\n",
    "    modified_adj1 = csr_matrix(attacked_adj)\n",
    "    print(modified_adj1)\n",
    "\n",
    "    # check for the differences between the initial graph and the attacked graph\n",
    "    diff_adj_attack = modified_adj1 - clean_adj1\n",
    "    non_zero_diff = diff_adj_attack.nonzero()\n",
    "    print(f\"adj wise : modifications after attack: {non_zero_diff}\")\n",
    "    num_changes = len(non_zero_diff[0]) // 2\n",
    "    print(f\"adj wise: Number of modifications after attack: {num_changes}\")\n",
    "\n",
    "    # evaluation after attack\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    model.fit(features, modified_adj1, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    model.eval()\n",
    "\n",
    "    accuracy_test_attack_2 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_2 = model.test(idx_test_clean)\n",
    "\n",
    "    print(\"Test accuracy on attack set after attack: \", accuracy_test_attack_2)\n",
    "    print(\"Test accuracy on clean set after attack: \", accuracy_test_clean_2)\n",
    "\n",
    "    ################# Crypto'Graph defense ####################3\n",
    "    print(\"*************** Crypto'Graph defense ***************\")\n",
    "\n",
    "    threshold = 2\n",
    "    metric = \"neighbors\"\n",
    "    object = \"links\"\n",
    "    model = TwoPartyCNGCN(dataset=dataset, nfeat=features.shape[1], nhid=16, nclass=labels.max().item() + 1,\n",
    "                          device=device)\n",
    "    defense_duration, defense_duration, training_duration1, training_duration2, CG_defended_adj1, CG_defended_adj2 = model.fit(\n",
    "        modified_adj1.copy(), adj2.copy(), features, features, labels, idx_train, threshold, metric=metric, object=object,\n",
    "        train_iters=200, initialize=True, verbose=False, idx_val=idx_val)\n",
    "    model.eval()\n",
    "    accuracies = model.test(idx_test)\n",
    "    accuracy_test_attack_3 = model.test(idx_test_attack)\n",
    "    accuracy_test_clean_3 = model.test(idx_test_clean)\n",
    "    print(\"Test accuracy on attack set after Crypto'Graph: \", accuracy_test_attack_3)\n",
    "    print(\"Test accuracy on clean set after Crypto'Graph: \", accuracy_test_clean_3)\n",
    "\n",
    "    rows = CG_defended_adj1.shape[0]\n",
    "    print(f\"CG_defended_adj1. Number of rows: {rows}\")\n",
    "\n",
    "    print(\"*************** adj wise compare (before and after defense) ***************\")\n",
    "    differences = np.abs(CG_defended_adj1 - modified_adj1)\n",
    "    total_differences = np.sum(differences)\n",
    "    print(f\"adj check: Total number of differences: {total_differences}\")\n",
    "    rows_with_changes = np.count_nonzero(np.sum(differences, axis=1))\n",
    "    print(f\"Number of rows with changes: {rows_with_changes}\")\n",
    "    changed_rows = np.where(np.sum(differences, axis=1) > 0)[0]\n",
    "    print(f\"Rows with different connectivities: {changed_rows}\")\n",
    "\n",
    "    difference_matrix = CG_defended_adj1 - modified_adj1\n",
    "    rows, cols = np.triu_indices_from(difference_matrix, k=1)\n",
    "    upper_triangle_differences = difference_matrix[rows, cols]\n",
    "    removed_edges = np.argwhere(upper_triangle_differences < 0)\n",
    "    total_removed_edges = len(removed_edges)\n",
    "    print(f\"Total number of removed edges(adj): {total_removed_edges}\")\n",
    "\n",
    "    # Identify the edges added during the attack and check if they are removed by CG defense\n",
    "    added_edges = []\n",
    "    modified_adj1_array = modified_adj1.toarray()\n",
    "    clean_adj1_array = clean_adj1.toarray()\n",
    "\n",
    "    rows, cols = np.triu_indices(modified_adj1_array.shape[0], k=1)\n",
    "    for i, j in zip(rows, cols):\n",
    "        if modified_adj1_array[i, j] == 1 and clean_adj1_array[i, j] == 0:\n",
    "            added_edges.append((i, j))\n",
    "    print(f\"Added edges during attack: {added_edges}\")\n",
    "    print(f\"Total number of added edges during attack: {len(added_edges)}\")\n",
    "\n",
    "    removed_edges_by_CG = []\n",
    "    CG_defended_adj1_array = CG_defended_adj1.toarray()\n",
    "\n",
    "    for edge in added_edges:\n",
    "        i, j = edge\n",
    "        if CG_defended_adj1_array[i, j] == 0:\n",
    "            removed_edges_by_CG.append(edge)\n",
    "    print(f\"Removed edges which have been added during attack by CG defense: {removed_edges_by_CG}\")\n",
    "\n",
    "    accuracy_test_attack_1_values.append(accuracy_test_attack_1)\n",
    "    accuracy_test_clean_1_values.append(accuracy_test_clean_1)\n",
    "    accuracy_test_attack_2_values.append(accuracy_test_attack_2)\n",
    "    accuracy_test_clean_2_values.append(accuracy_test_clean_2)\n",
    "    accuracy_test_attack_3_values.append(accuracy_test_attack_3)\n",
    "    accuracy_test_clean_3_values.append(accuracy_test_clean_3)\n",
    "\n",
    "'''\n",
    "accuracy_test_attack_1_std = np.std(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_std = np.std(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_std = np.std(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_std = np.std(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_std = np.std(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_std = np.std(accuracy_test_clean_3_values)\n",
    "\n",
    "with open('variables_std.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "                 accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "                 accuracy_test_attack_3_std, accuracy_test_clean_3_std], f)\n",
    "\n",
    "accuracy_test_attack_1_avg = np.mean(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_avg = np.mean(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_avg = np.mean(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_avg = np.mean(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_avg = np.mean(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_avg = np.mean(accuracy_test_clean_3_values)\n",
    "\n",
    "with open('variables.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "                 accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "                 accuracy_test_attack_3_avg, accuracy_test_clean_3_avg], f)\n",
    "\n",
    "labels = ['ACCs before attack', 'ACCs before attack', \n",
    "          'ACCs after attack', 'ACCs after attack', \n",
    "          'ACCs after CryptoGraph', 'ACCs after CryptoGraph']\n",
    "values = [accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "          accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "          accuracy_test_attack_3_avg, accuracy_test_clean_3_avg]\n",
    "std_devs = [accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "            accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "            accuracy_test_attack_3_std, accuracy_test_clean_3_std]\n",
    "x = np.arange(len(labels)//2)\n",
    "width = 0.35\n",
    "bars1 = plt.bar(x - width/2, values[::2], width, yerr=std_devs[::2], label='Attack set', color='red', capsize=5)\n",
    "bars2 = plt.bar(x + width/2, values[1::2], width, yerr=std_devs[1::2], label='Clean set', color='blue', capsize=5)\n",
    "plt.title('Average Accuracies')\n",
    "plt.xlabel('Levels of Attack and Defense')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.xticks(x, labels[::2])\n",
    "plt.legend()\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## mahsa-V4.1: using surrogate model for attack --- edit 1 - using loss fonc and gradiant base- edge-score  ################\n",
    "# attack adding/removing edge: (le budget adaptatif pour ajouter/enlever) ###############\n",
    "# surrogat model for each edge to be added or removed, target nodes selected manually\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from deeprobust.graph.defense import GCN\n",
    "from deeprobust.graph.utils import *\n",
    "from deeprobust.graph.data import Dataset\n",
    "from experiments import split_dataset\n",
    "from DistributedDefense import TwoPartyCNGCN\n",
    "import networkx as nx\n",
    "from scipy.sparse import csr_matrix\n",
    "import mahsa_backdoor as backdoor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# Define the number of repeats\n",
    "num_repeats = 1\n",
    "accuracy_test_attack_1_values = []\n",
    "accuracy_test_clean_1_values = []\n",
    "accuracy_test_attack_2_values = []\n",
    "accuracy_test_clean_2_values = []\n",
    "accuracy_test_attack_3_values = []\n",
    "accuracy_test_clean_3_values = []\n",
    "\n",
    "seed = 42  # Seed for reproducibility\n",
    "\n",
    "# Function to set seeds for reproducibility\n",
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Function to train surrogate model\n",
    "def train_surrogate_model(features, adj, labels, idx_train, idx_val):\n",
    "    surrogate_model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                          nhid=16, device=device, dropout=0.5)\n",
    "    surrogate_model = surrogate_model.to(device)\n",
    "    surrogate_model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    return surrogate_model\n",
    "\n",
    "# Function to compute the gradients of the loss function w.r.t. adjacency matrix\n",
    "def compute_gradients(surrogate_model, features, adj, labels, target_node):\n",
    "    surrogate_model.eval()\n",
    "    adj = torch.FloatTensor(adj.toarray()).to(device)\n",
    "    adj.requires_grad = True\n",
    "    features = torch.FloatTensor(features.toarray()).to(device)\n",
    "    labels = torch.LongTensor(labels).to(device)\n",
    "    output = surrogate_model(features, adj)\n",
    "    loss = F.nll_loss(output[[target_node]], labels[[target_node]])\n",
    "    loss.backward()\n",
    "    gradients = adj.grad.cpu().numpy()\n",
    "    return gradients\n",
    "\n",
    "# Function to calculate edge scores based on gradients\n",
    "def calculate_edge_scores(adj, gradients, target_node, add=True):\n",
    "    scores = {}\n",
    "    for i in range(adj.shape[0]):\n",
    "        if add and adj[target_node, i] == 0:\n",
    "            scores[(target_node, i)] = gradients[target_node, i]\n",
    "        elif not add and adj[target_node, i] == 1:\n",
    "            scores[(target_node, i)] = -gradients[target_node, i]\n",
    "    return scores\n",
    "\n",
    "# Function to select the best edge to add or remove based on scores\n",
    "def select_best_edge(adj, gradients, target_node, add=True):\n",
    "    scores = calculate_edge_scores(adj, gradients, target_node, add)\n",
    "    best_edge = max(scores, key=scores.get)\n",
    "    return best_edge\n",
    "\n",
    "################################ Data loading #######################################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "dataset = \"polblogs\"\n",
    "data = Dataset(root='.', name=dataset, setting='gcn', seed=15)\n",
    "\n",
    "for _ in range(num_repeats):\n",
    "    set_seeds(seed)\n",
    "    adj, features, labels = data.adj, data.features, data.labels\n",
    "    idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "    selected_node = 1196\n",
    "    idx_test_attack = np.array([selected_node])\n",
    "    idx_test_clean = np.array([node for node in idx_test if node != selected_node])\n",
    "    print(f\"Selected node for attack: {selected_node}\")\n",
    "    print(f\"Label of the selected node: {labels[selected_node]}\")\n",
    "\n",
    "    proportion_of_common_links = 0.5\n",
    "    adj1, adj2 = split_dataset(adj, proportion_of_common_links) \n",
    "\n",
    "    adj1 = sp.csr_matrix(adj1)\n",
    "    adj2 = sp.csr_matrix(adj2)\n",
    "    clean_adj1 = backdoor.remove_zero_weight_edges(adj1.copy())\n",
    "    clean_adj2 = backdoor.remove_zero_weight_edges(adj2.copy())\n",
    "    \n",
    "    neighbors_vector = adj1[selected_node, :].toarray()\n",
    "    neighbors_indices = np.nonzero(neighbors_vector)[1]\n",
    "    print(f\"num of neighbors of node {selected_node} is: {len(neighbors_indices)}\")\n",
    "    print(\"Neighbors of node\", selected_node, \"are:\", neighbors_indices)\n",
    "\n",
    "    ###### Train GCN model initially for evaluation before attack\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    model.eval()\n",
    "    output = model.test(idx_test)\n",
    "\n",
    "    accuracy_test_attack_1 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_1 = model.test(idx_test_clean)\n",
    "    print(\"Test accuracy on attack set: \", accuracy_test_attack_1)\n",
    "    print(\"Test accuracy on clean set: \", accuracy_test_clean_1)\n",
    "\n",
    "    ######## train surrogate model to find the importance of each edge\n",
    "    surrogate_model = train_surrogate_model(features, adj, labels, idx_train, idx_val)\n",
    "\n",
    "    modified_adj1 =  clean_adj1.copy()\n",
    "    print(f\"Initial number of edges: {modified_adj1.nnz // 2}\")\n",
    "    print(f\"Number of nodes: {modified_adj1.shape[0]}\")\n",
    "\n",
    "    budget = 20\n",
    "\n",
    "    ############### attack adj ################\n",
    "    attacked_adj = modified_adj1.copy()\n",
    "    print(f\"idx_test_attack: {idx_test_attack}\")\n",
    "\n",
    "    for target_node in idx_test_attack:\n",
    "        print(f\"Target node is: {target_node} with label: {labels[target_node]}\")\n",
    "        neighbors_same_label = backdoor.find_same_neighbor_adj(attacked_adj, labels, target_node)\n",
    "        neighbors_opposite_label = backdoor.find_opposite_neighbor_adj(attacked_adj, labels, target_node)\n",
    "        print(f\"Number of target same label neighbors before attack: {len(neighbors_same_label)}\")\n",
    "        print(f\"Number of target opposite label neighbors before attack: {len(neighbors_opposite_label)}\")\n",
    "\n",
    "        gradients = compute_gradients(surrogate_model, features, attacked_adj, labels, target_node)\n",
    "\n",
    "        for _ in range(budget):\n",
    "            edge_add = select_best_edge(attacked_adj, gradients, target_node, add=True)\n",
    "            edge_remove = select_best_edge(attacked_adj, gradients, target_node, add=False)\n",
    "            print(f\"edge_add: {edge_add}, edge_remove: {edge_remove}\")\n",
    "\n",
    "            if edge_add:\n",
    "                attacked_adj[edge_add[0], edge_add[1]] = 1\n",
    "                attacked_adj[edge_add[1], edge_add[0]] = 1\n",
    "                print(f\"Added edge: {edge_add}\")\n",
    "            \n",
    "            if edge_remove:\n",
    "                attacked_adj[edge_remove[0], edge_remove[1]] = 0\n",
    "                attacked_adj[edge_remove[1], edge_remove[0]] = 0\n",
    "                print(f\"Removed edge: {edge_remove}\")\n",
    "\n",
    "    ########## checking the adj wise changes after attack ##########\n",
    "    modified_adj1 = csr_matrix(attacked_adj)\n",
    "    print(modified_adj1)\n",
    "\n",
    "    # check for the differences between the initial graph and the attacked graph\n",
    "    diff_adj_attack = modified_adj1 - clean_adj1\n",
    "    non_zero_diff = diff_adj_attack.nonzero()\n",
    "    print(f\"adj wise : modifications after attack: {non_zero_diff}\")\n",
    "    num_changes = len(non_zero_diff[0]) // 2\n",
    "    print(f\"adj wise: Number of modifications after attack: {num_changes}\")\n",
    "\n",
    "    # evaluation after attack\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    model.fit(features, modified_adj1, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    model.eval()\n",
    "\n",
    "    accuracy_test_attack_2 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_2 = model.test(idx_test_clean)\n",
    "\n",
    "    print(\"Test accuracy on attack set after attack: \", accuracy_test_attack_2)\n",
    "    print(\"Test accuracy on clean set after attack: \", accuracy_test_clean_2)\n",
    "\n",
    "    ################# Crypto'Graph defense ####################3\n",
    "    print(\"*************** Crypto'Graph defense ***************\")\n",
    "\n",
    "    threshold = 2\n",
    "    metric = \"neighbors\"\n",
    "    object = \"links\"\n",
    "    model = TwoPartyCNGCN(dataset=dataset, nfeat=features.shape[1], nhid=16, nclass=labels.max().item() + 1,\n",
    "                          device=device)\n",
    "    defense_duration, defense_duration, training_duration1, training_duration2, CG_defended_adj1, CG_defended_adj2 = model.fit(\n",
    "        modified_adj1.copy(), adj2.copy(), features, features, labels, idx_train, threshold, metric=metric, object=object,\n",
    "        train_iters=200, initialize=True, verbose=False, idx_val=idx_val)\n",
    "    model.eval()\n",
    "    accuracies = model.test(idx_test)\n",
    "    accuracy_test_attack_3 = model.test(idx_test_attack)\n",
    "    accuracy_test_clean_3 = model.test(idx_test_clean)\n",
    "    print(\"Test accuracy on attack set after Crypto'Graph: \", accuracy_test_attack_3)\n",
    "    print(\"Test accuracy on clean set after Crypto'Graph: \", accuracy_test_clean_3)\n",
    "\n",
    "    rows = CG_defended_adj1.shape[0]\n",
    "    print(f\"CG_defended_adj1. Number of rows: {rows}\")\n",
    "\n",
    "    print(\"*************** adj wise compare (before and after defense) ***************\")\n",
    "    differences = np.abs(CG_defended_adj1 - modified_adj1)\n",
    "    total_differences = np.sum(differences)\n",
    "    print(f\"adj check: Total number of differences: {total_differences}\")\n",
    "    rows_with_changes = np.count_nonzero(np.sum(differences, axis=1))\n",
    "    print(f\"Number of rows with changes: {rows_with_changes}\")\n",
    "    changed_rows = np.where(np.sum(differences, axis=1) > 0)[0]\n",
    "    print(f\"Rows with different connectivities: {changed_rows}\")\n",
    "\n",
    "    difference_matrix = CG_defended_adj1 - modified_adj1\n",
    "    rows, cols = np.triu_indices_from(difference_matrix, k=1)\n",
    "    upper_triangle_differences = difference_matrix[rows, cols]\n",
    "    removed_edges = np.argwhere(upper_triangle_differences < 0)\n",
    "    total_removed_edges = len(removed_edges)\n",
    "    print(f\"Total number of removed edges(adj): {total_removed_edges}\")\n",
    "\n",
    "    # Identify the edges added during the attack and check if they are removed by CG defense\n",
    "    added_edges = []\n",
    "    modified_adj1_array = modified_adj1.toarray()\n",
    "    clean_adj1_array = clean_adj1.toarray()\n",
    "\n",
    "    rows, cols = np.triu_indices(modified_adj1_array.shape[0], k=1)\n",
    "    for i, j in zip(rows, cols):\n",
    "        if modified_adj1_array[i, j] == 1 and clean_adj1_array[i, j] == 0:\n",
    "            added_edges.append((i, j))\n",
    "    print(f\"Added edges during attack: {added_edges}\")\n",
    "    print(f\"Total number of added edges during attack: {len(added_edges)}\")\n",
    "\n",
    "    removed_edges_by_CG = []\n",
    "    CG_defended_adj1_array = CG_defended_adj1.toarray()\n",
    "\n",
    "    for edge in added_edges:\n",
    "        i, j = edge\n",
    "        if CG_defended_adj1_array[i, j] == 0:\n",
    "            removed_edges_by_CG.append(edge)\n",
    "    print(f\"Removed edges which have been added during attack by CG defense: {removed_edges_by_CG}\")\n",
    "\n",
    "    accuracy_test_attack_1_values.append(accuracy_test_attack_1)\n",
    "    accuracy_test_clean_1_values.append(accuracy_test_clean_1)\n",
    "    accuracy_test_attack_2_values.append(accuracy_test_attack_2)\n",
    "    accuracy_test_clean_2_values.append(accuracy_test_clean_2)\n",
    "    accuracy_test_attack_3_values.append(accuracy_test_attack_3)\n",
    "    accuracy_test_clean_3_values.append(accuracy_test_clean_3)\n",
    "\n",
    "accuracy_test_attack_1_std = np.std(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_std = np.std(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_std = np.std(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_std = np.std(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_std = np.std(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_std = np.std(accuracy_test_clean_3_values)\n",
    "\n",
    "with open('variables_std.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "                 accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "                 accuracy_test_attack_3_std, accuracy_test_clean_3_std], f)\n",
    "\n",
    "accuracy_test_attack_1_avg = np.mean(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_avg = np.mean(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_avg = np.mean(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_avg = np.mean(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_avg = np.mean(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_avg = np.mean(accuracy_test_clean_3_values)\n",
    "\n",
    "with open('variables.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "                 accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "                 accuracy_test_attack_3_avg, accuracy_test_clean_3_avg], f)\n",
    "\n",
    "labels = ['ACCs before attack', 'ACCs before attack', \n",
    "          'ACCs after attack', 'ACCs after attack', \n",
    "          'ACCs after CryptoGraph', 'ACCs after CryptoGraph']\n",
    "values = [accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "          accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "          accuracy_test_attack_3_avg, accuracy_test_clean_3_avg]\n",
    "std_devs = [accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "            accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "            accuracy_test_attack_3_std, accuracy_test_clean_3_std]\n",
    "x = np.arange(len(labels)//2)\n",
    "width = 0.35\n",
    "bars1 = plt.bar(x - width/2, values[::2], width, yerr=std_devs[::2], label='Attack set', color='red', capsize=5)\n",
    "bars2 = plt.bar(x + width/2, values[1::2], width, yerr=std_devs[1::2], label='Clean set', color='blue', capsize=5)\n",
    "plt.title('Average Accuracies')\n",
    "plt.xlabel('Levels of Attack and Defense')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.xticks(x, labels[::2])\n",
    "plt.legend()\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## mahsa-V4.1: using surrogate model - edit 2 - using loss fonc and gradiant base- edge-score and commun neighbor ################\n",
    "# attack adding/removing edge: (le budget adaptatif pour ajouter/enlever) ###############\n",
    "# surrogat model for each edge to be added or removed, target nodes selected manually\n",
    "#  reports on this one but made changes, now not working  , needs reveiw\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from deeprobust.graph.defense import GCN\n",
    "from deeprobust.graph.utils import *\n",
    "from deeprobust.graph.data import Dataset\n",
    "from experiments import split_dataset\n",
    "from DistributedDefense import TwoPartyCNGCN\n",
    "import networkx as nx\n",
    "from scipy.sparse import csr_matrix\n",
    "import mahsa_backdoor as backdoor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch import nn, optim\n",
    "import scipy.sparse as sp\n",
    "import pickle\n",
    "\n",
    "# Define the number of repeats\n",
    "num_repeats = 1\n",
    "accuracy_test_attack_1_values = []\n",
    "accuracy_test_clean_1_values = []\n",
    "accuracy_test_attack_2_values = []\n",
    "accuracy_test_clean_2_values = []\n",
    "accuracy_test_attack_3_values = []\n",
    "accuracy_test_clean_3_values = []\n",
    "\n",
    "seed = 42  # Seed for reproducibility\n",
    "\n",
    "# Function to set seeds for reproducibility\n",
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Function to train surrogate model\n",
    "def train_surrogate_model(features, adj, labels, idx_train, idx_val):\n",
    "    surrogate_model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                          nhid=16, device=device, dropout=0.5)\n",
    "    surrogate_model = surrogate_model.to(device)\n",
    "    surrogate_model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    return surrogate_model\n",
    "\n",
    "# Function to compute the gradients of the loss function with respect to adjacency matrix\n",
    "def compute_gradients(surrogate_model, features, adj, labels, target_node):\n",
    "    surrogate_model.eval() # sets the surrogate model to evaluation mode. In evaluation mode, certain layers (like dropout and batch normalization) behave differently compared to training mode.\n",
    "    # Convert adjacency matrix to PyTorch tensor and enable gradient computation\n",
    "    adj = torch.FloatTensor(adj.toarray()).to(device)\n",
    "    adj.requires_grad = True\n",
    "     # Convert feature matrix and labels to PyTorch tensors\n",
    "    features = torch.FloatTensor(features.toarray()).to(device)\n",
    "    labels = torch.LongTensor(labels).to(device)\n",
    "    # Forward pass: compute model output (predictions) \n",
    "    output = surrogate_model(features, adj) \n",
    "    # Compute loss for the target node: how well the model's prediction matches the true label for the target_node\n",
    "    loss = F.nll_loss(output[[target_node]], labels[[target_node]]) \n",
    "    #The backward pass computes the gradients of the loss. These gradients indicate how changes in the adjacency matrix would affect the loss.\n",
    "    loss.backward()\n",
    "    gradients = adj.grad.cpu().numpy()  # The gradients are extracted from the adjacency matrix tensor and converted to a NumPy array on the CPU.\n",
    "    \n",
    "    print(f\"Loss for target node {target_node}: {loss.item()}\")\n",
    "    print(f\"Gradients for target node {target_node}: {gradients}\")\n",
    "    # Check for non-zero gradients\n",
    "    if not np.any(gradients):\n",
    "        print(f\"No non-zero gradients found for target node {target_node}.\")\n",
    "    else:\n",
    "        non_zero_gradients = np.nonzero(gradients)\n",
    "        print(f\"Non-zero gradients for target node {target_node}:\")\n",
    "        for index in zip(*non_zero_gradients):\n",
    "            print(f\"Gradient at {index}: {gradients[index]}\")\n",
    "\n",
    "    return gradients\n",
    "\n",
    "\n",
    "# Function to calculate edge scores based on gradients\n",
    "# def calculate_edge_scores(adj, gradients, target_node, add=True):\n",
    "#     scores = {}\n",
    "#     for i in range(adj.shape[0]):\n",
    "#         if add and adj[target_node, i] == 0:\n",
    "#             scores[(target_node, i)] = gradients[target_node, i]  # if gradient is positive, it means that adding the edge would increase the loss\n",
    "#         elif not add and adj[target_node, i] == 1:\n",
    "#             scores[(target_node, i)] = -gradients[target_node, i] # if gradient is negative, it means that removing the edge would increase the loss\n",
    "#     return scores # The scores (gradiants) are returned as a dictionary where the keys are the edges and the values are the gradients.\n",
    "\n",
    "def calculate_common_neighbors(adj, node1, node2):\n",
    "    neighbors1 = set(adj[node1].indices)\n",
    "    neighbors2 = set(adj[node2].indices)\n",
    "    common_neighbors = neighbors1 & neighbors2\n",
    "    return len(common_neighbors) # The number of common neighbors between the two nodes is returned.\n",
    "\n",
    "# Function to calculate edge scores based on gradients and common neighbors ...... it worked at least\n",
    "def calculate_edge_scores_common_neighbors(adj, gradients, target_node, labels, add=True):\n",
    "    scores = {}\n",
    "    for i in range(adj.shape[0]):\n",
    "        if add and adj[target_node, i] == 0 and labels[target_node] != labels[i]:  # Ensure different labels for adding\n",
    "            common_neighbors = calculate_common_neighbors(adj, target_node, i)\n",
    "            scores[(target_node, i)] = gradients[target_node, i] + common_neighbors\n",
    "        elif not add and adj[target_node, i] == 1 and labels[target_node] == labels[i]:  # Ensure same labels for removing\n",
    "            common_neighbors = calculate_common_neighbors(adj, target_node, i)\n",
    "            scores[(target_node, i)] = -gradients[target_node, i] + common_neighbors \n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "#it has problem, nothing is not added or removed\n",
    "# def calculate_edge_scores_common_neighbors(adj, gradients, target_node, labels):\n",
    "#     add_scores = {}\n",
    "#     remove_scores = {}\n",
    "#     for i in range(adj.shape[0]):\n",
    "#         # print(f\"Common neighbors between {target_node} and {i}: number of neighbors:{len(common_neighbors)} and list is {common_neighbors}\")\n",
    "#         if adj[target_node, i] == 0 and labels[target_node] != labels[i]:  # if not neighbor and not same label : adding\n",
    "#             common_neighbors = calculate_common_neighbors(adj, target_node, i)\n",
    "#             add_scores[(target_node, i)] = gradients[target_node, i] + common_neighbors\n",
    "#             # print(f\"Add score for edge ({target_node}, {i}): {add_scores[(target_node, i)]}\")\n",
    "#         elif adj[target_node, i] == 1 and labels[target_node] == labels[i]:  # if neighbor and  same label : removing\n",
    "#             common_neighbors = calculate_common_neighbors(adj, target_node, i)\n",
    "#             remove_scores[(target_node, i)] = -gradients[target_node, i] + common_neighbors  # if gradient is negative, it means that removing the edge would increase the loss, so we put ne - to have a positive score to find the best edge to remove\n",
    "#             # print(f\"Remove score for edge ({target_node}, {i}): {remove_scores[(target_node, i)]}\")\n",
    "#     return add_scores, remove_scores\n",
    "\n",
    "\n",
    "##### last version ----it worked at least but adds and removes.\n",
    "def select_best_edge_common_neighbors(adj, gradients, target_node, labels, add=True):\n",
    "    scores = calculate_edge_scores_common_neighbors(adj, gradients, target_node, labels, add)\n",
    "    if not scores:\n",
    "        return None\n",
    "    if add:\n",
    "        best_edge = max(scores, key=scores.get)\n",
    "    else:\n",
    "        best_edge = min(scores, key=scores.get)\n",
    "    return best_edge\n",
    "\n",
    "#### it has problem, nothing is not added or removed\n",
    "# def select_best_edge_common_neighbors(adj, gradients, target_node, labels):\n",
    "#     add_scores, remove_scores = calculate_edge_scores_common_neighbors(adj, gradients, target_node, labels)\n",
    "#     if not add_scores and not remove_scores:\n",
    "#         return None, None\n",
    "#     best_add_edge = max(add_scores, key=add_scores.get) if add_scores else None\n",
    "#     best_remove_edge = max(remove_scores, key=remove_scores.get) if remove_scores else None\n",
    "    \n",
    "#     best_add_score = add_scores[best_add_edge] if best_add_edge else float('-inf')\n",
    "#     best_remove_score = remove_scores[best_remove_edge] if best_remove_edge else float('-inf')\n",
    "#     if best_add_score > best_remove_score:\n",
    "#         return best_add_edge, 'add'\n",
    "#     else:\n",
    "#         return best_remove_edge, 'remove'\n",
    "\n",
    "\n",
    "################################ Data loading #######################################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "dataset = \"polblogs\"\n",
    "data = Dataset(root='.', name=dataset, setting='gcn', seed=15)\n",
    "\n",
    "for _ in range(num_repeats):\n",
    "    set_seeds(seed)\n",
    "    adj, features, labels = data.adj, data.features, data.labels\n",
    "    idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "    selected_node = 1196\n",
    "    idx_test_attack = np.array([selected_node])\n",
    "    idx_test_clean = np.array([node for node in idx_test if node != selected_node])\n",
    "    print(f\"Selected node for attack: {selected_node}\")\n",
    "    print(f\"Label of the selected node: {labels[selected_node]}\")\n",
    "    \n",
    "    ################### split idx_test into two parts : one node for attack randomley and the rest for clean\n",
    "    # test_size = 1  # 1 node for attack others for test_clean\n",
    "    # idx_test_clean , idx_test_attack = train_test_split(idx_test, test_size=test_size, random_state=42)\n",
    "    # selected_node = idx_test_attack[0]\n",
    "    # print(f\"Selected node for attack: {selected_node}\")\n",
    "    # print(f\"Label of the selected node: {labels[selected_node]}\")\n",
    "    ################ split idx_test into two parts randomly with a specific ratio %\n",
    "    # test_size = 0.10  # 10% for test_attack, 90% for test_clean\n",
    "    # idx_test_clean , idx_test_attack = train_test_split(idx_test, test_size=test_size, random_state=seed)\n",
    "    ######################\n",
    "\n",
    "    proportion_of_common_links = 0.5\n",
    "    adj1, adj2 = split_dataset(adj, proportion_of_common_links) \n",
    "\n",
    "    adj1 = sp.csr_matrix(adj1)\n",
    "    adj2 = sp.csr_matrix(adj2)\n",
    "    clean_adj1 = backdoor.remove_zero_weight_edges(adj1.copy())\n",
    "    clean_adj2 = backdoor.remove_zero_weight_edges(adj2.copy())\n",
    "    \n",
    "    neighbors_vector = adj1[selected_node, :].toarray()\n",
    "    neighbors_indices = np.nonzero(neighbors_vector)[1]\n",
    "    print(f\"num of neighbors of node {selected_node} is: {len(neighbors_indices)}\")\n",
    "    print(\"Neighbors of node\", selected_node, \"are:\", neighbors_indices)\n",
    "\n",
    "    ###### Train GCN model initially for evaluation before attack\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    model.eval()\n",
    "    output = model.test(idx_test)\n",
    "\n",
    "    accuracy_test_attack_1 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_1 = model.test(idx_test_clean)\n",
    "    print(\"Test accuracy on attack set: \", accuracy_test_attack_1)\n",
    "    print(\"Test accuracy on clean set: \", accuracy_test_clean_1)\n",
    "\n",
    "    ######## train surrogate model to find the importance of each edge\n",
    "    surrogate_model = train_surrogate_model(features, adj, labels, idx_train, idx_val)\n",
    "\n",
    "    modified_adj1 =  clean_adj1.copy()\n",
    "    print(f\"Initial number of edges: {modified_adj1.nnz // 2}\")\n",
    "    print(f\"Number of nodes: {modified_adj1.shape[0]}\")\n",
    "\n",
    "    budget = 30\n",
    "    ############### attack adj ################\n",
    "    attacked_adj = modified_adj1.copy()\n",
    "    print(f\"idx_test_attack: {idx_test_attack}\")\n",
    "    edges_added_count = 0\n",
    "    edges_removed_count = 0\n",
    "\n",
    "    for target_node in idx_test_attack:\n",
    "        print(f\"Target node is: {target_node} with label: {labels[target_node]}\")\n",
    "        # neighbors_same_label = backdoor.find_same_neighbor_adj(attacked_adj, labels, target_node)\n",
    "        # neighbors_opposite_label = backdoor.find_opposite_neighbor_adj(attacked_adj, labels, target_node)\n",
    "        # print(f\"Number of target same label neighbors before attack: {len(neighbors_same_label)}\")\n",
    "        # print(f\"Number of target opposite label neighbors before attack: {len(neighbors_opposite_label)}\")\n",
    "\n",
    "        # Compute gradients and their signs\n",
    "        gradients = compute_gradients(surrogate_model, features, attacked_adj, labels, target_node)\n",
    "        print(f\"Gradients for target node {target_node}: {gradients}\")\n",
    "        \n",
    "        ##### it shows that all the gradients are zero, so we can not use them for attack\n",
    "        if not np.any(gradients):\n",
    "            print(f\"No non-zero gradients found for target node {target_node}. Skipping this node.\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        #### it works but it adds and removes\n",
    "        for _ in range(budget):\n",
    "            edge_add = select_best_edge_common_neighbors(attacked_adj, gradients, target_node, labels, add=True)\n",
    "            edge_remove = select_best_edge_common_neighbors(attacked_adj, gradients, target_node, labels, add=False)\n",
    "            print(f\"edge_add: {edge_add}, edge_remove: {edge_remove}\")\n",
    "            if edge_add:\n",
    "                attacked_adj[edge_add[0], edge_add[1]] = 1\n",
    "                attacked_adj[edge_add[1], edge_add[0]] = 1\n",
    "                edges_added_count += 1\n",
    "                print(f\"Added edge: {edge_add}\")\n",
    "            if edge_remove:\n",
    "                attacked_adj[edge_remove[0], edge_remove[1]] = 0\n",
    "                attacked_adj[edge_remove[1], edge_remove[0]] = 0\n",
    "                edges_removed_count += 1\n",
    "                print(f\"Removed edge: {edge_remove}\")\n",
    "                \n",
    "        #### it is not working, nothing is added or removed\n",
    "        # for _ in range(budget):\n",
    "        #         best_edge, action = select_best_edge_common_neighbors(attacked_adj, gradients, target_node, labels)\n",
    "        #         if not best_edge:\n",
    "        #             continue\n",
    "\n",
    "        #         if action == 'add':\n",
    "        #             attacked_adj[best_edge[0], best_edge[1]] = 1\n",
    "        #             attacked_adj[best_edge[1], best_edge[0]] = 1\n",
    "        #             edges_added_count += 1\n",
    "        #             print(f\"Added edge: {best_edge}\")\n",
    "\n",
    "        #         elif action == 'remove':\n",
    "        #             attacked_adj[best_edge[0], best_edge[1]] = 0\n",
    "        #             attacked_adj[best_edge[1], best_edge[0]] = 0\n",
    "        #             edges_removed_count += 1\n",
    "        #             print(f\"Removed edge: {best_edge}\")\n",
    "\n",
    "        print(f\"Total number of added edges during attack: {edges_added_count}\")\n",
    "        print(f\"Total number of removed edges during attack: {edges_removed_count}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ########## checking the adj wise changes after attack ##########\n",
    "    modified_adj1 = csr_matrix(attacked_adj)\n",
    "    print (f\"Number of edges added: {edges_added_count}\")\n",
    "    print (f\"Number of edges removed: {edges_removed_count}\")\n",
    "    # print(modified_adj1)\n",
    "\n",
    "    # check for the differences between the initial graph and the attacked graph\n",
    "    diff_adj_attack = modified_adj1 - clean_adj1\n",
    "    non_zero_diff = diff_adj_attack.nonzero()\n",
    "    print(f\"adj wise : modifications after attack: {non_zero_diff}\")\n",
    "    num_changes = len(non_zero_diff[0]) // 2\n",
    "    print(f\"adj wise: Number of modifications after attack: {num_changes}\")\n",
    "\n",
    "    # evaluation after attack\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    model.fit(features, modified_adj1, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    model.eval()\n",
    "\n",
    "    accuracy_test_attack_2 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_2 = model.test(idx_test_clean)\n",
    "\n",
    "    print(\"Test accuracy on attack set after attack: \", accuracy_test_attack_2)\n",
    "    print(\"Test accuracy on clean set after attack: \", accuracy_test_clean_2)\n",
    "\n",
    "    ################# Crypto'Graph defense ####################3\n",
    "    print(\"*************** Crypto'Graph defense ***************\")\n",
    "\n",
    "    threshold = 2\n",
    "    metric = \"neighbors\"\n",
    "    object = \"links\"\n",
    "    model = TwoPartyCNGCN(dataset=dataset, nfeat=features.shape[1], nhid=16, nclass=labels.max().item() + 1,\n",
    "                          device=device)\n",
    "    defense_duration, defense_duration, training_duration1, training_duration2, CG_defended_adj1, CG_defended_adj2 = model.fit(\n",
    "        modified_adj1.copy(), adj2.copy(), features, features, labels, idx_train, threshold, metric=metric, object=object,\n",
    "        train_iters=200, initialize=True, verbose=False, idx_val=idx_val)\n",
    "    model.eval()\n",
    "    accuracies = model.test(idx_test)\n",
    "    accuracy_test_attack_3 = model.test(idx_test_attack)\n",
    "    accuracy_test_clean_3 = model.test(idx_test_clean)\n",
    "    print(\"Test accuracy on attack set after Crypto'Graph: \", accuracy_test_attack_3)\n",
    "    print(\"Test accuracy on clean set after Crypto'Graph: \", accuracy_test_clean_3)\n",
    "\n",
    "    rows = CG_defended_adj1.shape[0]\n",
    "    print(f\"CG_defended_adj1. Number of rows: {rows}\")\n",
    "\n",
    "    print(\"*************** adj wise compare (before and after defense) ***************\")\n",
    "    differences = np.abs(CG_defended_adj1 - modified_adj1)\n",
    "    total_differences = np.sum(differences)\n",
    "    print(f\"adj check: Total number of differences: {total_differences}\")\n",
    "    rows_with_changes = np.count_nonzero(np.sum(differences, axis=1))\n",
    "    print(f\"Number of rows with changes: {rows_with_changes}\")\n",
    "    # changed_rows = np.where(np.sum(differences, axis=1) > 0)[0]\n",
    "    # print(f\"Rows with different connectivities: {changed_rows}\")\n",
    "\n",
    "    difference_matrix = CG_defended_adj1 - modified_adj1\n",
    "    rows, cols = np.triu_indices_from(difference_matrix, k=1)\n",
    "    upper_triangle_differences = difference_matrix[rows, cols]\n",
    "    removed_edges = np.argwhere(upper_triangle_differences < 0)\n",
    "    total_removed_edges = len(removed_edges)\n",
    "    print(f\"Total number of removed edges(adj) by the CG: {total_removed_edges}\")\n",
    "\n",
    "    # Identify the edges added during the attack and check if they are removed by CG defense\n",
    "    added_edges = []\n",
    "    removed_edges_by_CG = []\n",
    "    modified_adj1_array = modified_adj1.toarray()\n",
    "    clean_adj1_array = clean_adj1.toarray()\n",
    "\n",
    "    rows, cols = np.triu_indices(modified_adj1_array.shape[0], k=1)\n",
    "    for i, j in zip(rows, cols):\n",
    "        if modified_adj1_array[i, j] == 1 and clean_adj1_array[i, j] == 0:\n",
    "            added_edges.append((i, j))\n",
    "    print(f\"Added edges during attack: {added_edges}\")\n",
    "    print(f\"Total number of added edges during attack: {len(added_edges)}\")\n",
    "\n",
    "    removed_edges = []\n",
    "    for i, j in zip(rows, cols):\n",
    "        if modified_adj1_array[i, j] == 0 and clean_adj1_array[i, j] == 1:\n",
    "            removed_edges.append((i, j))\n",
    "    print(f\"Removed edges during attack: {removed_edges}\")\n",
    "    print(f\"Total number of removed edges during attack: {len(removed_edges)}\")\n",
    "\n",
    "\n",
    "    # check if added edges are removed by CG defense\n",
    "    for edge in added_edges:\n",
    "        i, j = edge\n",
    "        if CG_defended_adj1_array[i, j] == 0:\n",
    "            removed_edges_by_CG.append(edge)\n",
    "    print(f\"added edges during attack which are removed by CG defense: {removed_edges_by_CG}\")\n",
    "    print(f\"Total number of added edges during attack which are removed by CG defense: {len(removed_edges_by_CG)}\")\n",
    "\n",
    "    accuracy_test_attack_1_values.append(accuracy_test_attack_1)\n",
    "    accuracy_test_clean_1_values.append(accuracy_test_clean_1)\n",
    "    accuracy_test_attack_2_values.append(accuracy_test_attack_2)\n",
    "    accuracy_test_clean_2_values.append(accuracy_test_clean_2)\n",
    "    accuracy_test_attack_3_values.append(accuracy_test_attack_3)\n",
    "    accuracy_test_clean_3_values.append(accuracy_test_clean_3)\n",
    "\n",
    "accuracy_test_attack_1_std = np.std(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_std = np.std(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_std = np.std(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_std = np.std(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_std = np.std(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_std = np.std(accuracy_test_clean_3_values)\n",
    "\n",
    "with open('variables_std.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "                 accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "                 accuracy_test_attack_3_std, accuracy_test_clean_3_std], f)\n",
    "\n",
    "accuracy_test_attack_1_avg = np.mean(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_avg = np.mean(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_avg = np.mean(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_avg = np.mean(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_avg = np.mean(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_avg = np.mean(accuracy_test_clean_3_values)\n",
    "\n",
    "with open('variables.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "                 accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "                 accuracy_test_attack_3_avg, accuracy_test_clean_3_avg], f)\n",
    "\n",
    "labels = ['ACCs before attack', 'ACCs before attack', \n",
    "          'ACCs after attack', 'ACCs after attack', \n",
    "          'ACCs after CryptoGraph', 'ACCs after CryptoGraph']\n",
    "values = [accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "          accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "          accuracy_test_attack_3_avg, accuracy_test_clean_3_avg]\n",
    "std_devs = [accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "            accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "            accuracy_test_attack_3_std, accuracy_test_clean_3_std]\n",
    "x = np.arange(len(labels)//2)\n",
    "width = 0.35\n",
    "bars1 = plt.bar(x - width/2, values[::2], width, yerr=std_devs[::2], label='Attack set', color='red', capsize=5)\n",
    "bars2 = plt.bar(x + width/2, values[1::2], width, yerr=std_devs[1::2], label='Clean set', color='blue', capsize=5)\n",
    "plt.title('Average Accuracies')\n",
    "plt.xlabel('Levels of Attack and Defense')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.xticks(x, labels[::2])\n",
    "plt.legend()\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### checkings if we have nodes with gradiants non zero losses non zero ... ################\n",
    "####### choosing nodes for attack by selecting the nodes with non zero gradients and non zero losses ########\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from deeprobust.graph.defense import GCN\n",
    "from deeprobust.graph.utils import *\n",
    "from deeprobust.graph.data import Dataset\n",
    "from experiments import split_dataset\n",
    "from DistributedDefense import TwoPartyCNGCN\n",
    "import networkx as nx\n",
    "from scipy.sparse import csr_matrix\n",
    "import mahsa_backdoor as backdoor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch import nn, optim\n",
    "import scipy.sparse as sp\n",
    "import pickle\n",
    "\n",
    "\n",
    "seed = 42  # Seed for reproducibility\n",
    "num_repeats = 1\n",
    "\n",
    "# Function to set seeds for reproducibility\n",
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Function to train surrogate model\n",
    "def train_surrogate_model(features, adj, labels, idx_train, idx_val):\n",
    "    surrogate_model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                          nhid=16, device=device, dropout=0.5)\n",
    "    surrogate_model = surrogate_model.to(device)\n",
    "    surrogate_model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    return surrogate_model\n",
    "\n",
    "# Function to compute the gradients of the loss function with respect to adjacency matrix\n",
    "def compute_gradients(surrogate_model, features, adj, labels, target_node):\n",
    "    surrogate_model.eval() # sets the surrogate model to evaluation mode. In evaluation mode, certain layers (like dropout and batch normalization) behave differently compared to training mode.\n",
    "    adj = torch.FloatTensor(adj.toarray()).to(device)\n",
    "    adj.requires_grad = True\n",
    "    features = torch.FloatTensor(features.toarray()).to(device)\n",
    "    labels = torch.LongTensor(labels).to(device)\n",
    "    # Forward pass: compute model output (predictions) \n",
    "    output = surrogate_model(features, adj) \n",
    "    # Compute loss for the target node: how well the model's prediction matches the true label for the target_node\n",
    "    loss = F.nll_loss(output[[target_node]], labels[[target_node]]) \n",
    "    #The backward pass computes the gradients of the loss. These gradients indicate how changes in the adjacency matrix would affect the loss.\n",
    "    loss.backward()\n",
    "    gradients = adj.grad.cpu().numpy()  # The gradients are extracted from the adjacency matrix tensor and converted to a NumPy array on the CPU.\n",
    "    \n",
    "    # print(f\"Loss for target node {target_node}: {loss.item()}\")\n",
    "    # print(f\"Gradients for target node {target_node}: {gradients}\")\n",
    "    # Check for non-zero gradients\n",
    "    # if not np.any(gradients):\n",
    "    #     print(f\"No non-zero gradients found for target node {target_node}.\")\n",
    "    # else:\n",
    "    #     non_zero_gradients = np.nonzero(gradients)\n",
    "    #     print(f\"Non-zero gradients for target node {target_node}:\")\n",
    "    #     for index in zip(*non_zero_gradients):\n",
    "    #         print(f\"Gradient at {index}: {gradients[index]}\")\n",
    "\n",
    "    return  loss.item(), gradients\n",
    "\n",
    "\n",
    "################################ Data loading #######################################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "dataset = \"polblogs\"\n",
    "data = Dataset(root='.', name=dataset, setting='gcn', seed=15)\n",
    "adj, features, labels = data.adj, data.features, data.labels\n",
    "idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "print(f\"Number of training nodes: {len(idx_train)}\")\n",
    "print(f\"Number of validation nodes: {len(idx_val)}\")\n",
    "print(f\"Number of test nodes: {len(idx_test)}\")\n",
    "\n",
    "#performing the experiment for num_repeats times\n",
    "for _ in range(num_repeats):\n",
    "    set_seeds(seed)\n",
    "    \n",
    "    ###### Train GCN model initially for evaluation before attack\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    model.eval()\n",
    "    output = model.test(idx_test)\n",
    "\n",
    "   \n",
    "    ######## train surrogate model to find the importance of each edge\n",
    "    surrogate_model = train_surrogate_model(features, adj, labels, idx_train, idx_val)\n",
    "\n",
    "    # Calculate gradients and loss for each target node\n",
    "    print(f\"size of idx_test: {len(idx_test)}\")\n",
    "    zero_loss_count = 0\n",
    "    zero_gradients_count = 0\n",
    "    non_zero_loss_and_gradients_nodes = []\n",
    "    zero_loss_non_ziro_gr = 0\n",
    "\n",
    "\n",
    "    for target_node in idx_test:\n",
    "        loss, gradients = compute_gradients(surrogate_model, features, adj, labels, target_node)\n",
    "\n",
    "        if loss == 0:\n",
    "            zero_loss_count += 1\n",
    "        if not np.any(gradients):\n",
    "            zero_gradients_count += 1\n",
    "        \n",
    "        zero_loss = loss == 0\n",
    "        zero_gradients = not np.any(gradients)\n",
    "\n",
    "       # If both loss and gradients are non-zero, store the node\n",
    "        if not zero_loss and not zero_gradients:\n",
    "            impact_score = loss * np.sum(np.abs(gradients))\n",
    "            non_zero_loss_and_gradients_nodes.append((target_node, impact_score))\n",
    "        # Ensure consistency between zero loss and zero gradients\n",
    "        if zero_loss and not zero_gradients:\n",
    "            print(f\"Warning: Target node {target_node} has zero loss but non-zero gradients!\")\n",
    "            zero_loss_non_ziro_gr += 1\n",
    "        \n",
    "\n",
    "        print(f\"Target node is: {target_node} with label: {labels[target_node]}\")\n",
    "        print(f\"Loss for target node {target_node}: {loss}\")\n",
    "        print(f\"Gradients for target node {target_node}: {'Non-zero' if not zero_gradients else 'Zero'}\")\n",
    "      \n",
    "    # Print the counts of nodes with zero loss and zero gradients\n",
    "    print(f\"Final number of nodes with zero loss: {zero_loss_count}\")\n",
    "    print(f\"Final number of nodes with zero gradients: {zero_gradients_count}\")\n",
    "    print(f\"Final number of nodes with zero loss but non-zero gradients: {zero_loss_non_ziro_gr}\")\n",
    "   \n",
    "    print(\"Nodes with non-zero loss and non-zero gradients:\")\n",
    "    for node in non_zero_loss_and_gradients_nodes:\n",
    "        print(node)\n",
    "    print(f\"Number of nodes with non-zero loss and non-zero gradients: {len(non_zero_loss_and_gradients_nodes)}\")\n",
    "\n",
    "    # Sort nodes by impact score in descending order\n",
    "    non_zero_loss_and_gradients_nodes.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Select top k nodes to attack\n",
    "    k = 10  # Number of nodes to attack\n",
    "    nodes_to_attack = [node for node, impact_score in non_zero_loss_and_gradients_nodes[:k]]\n",
    "    print(f\"Nodes to attack (node_id):\")\n",
    "    print(nodes_to_attack)\n",
    "\n",
    "    print(\"Nodes to attack (node_id, impact_score):\")\n",
    "    for node, score in non_zero_loss_and_gradients_nodes[:k]:\n",
    "        print(f\"Node: {node}, Impact Score: {score}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## TEST mahsa-V4.2: using surrogate model - using loss fonc and gradiant base- edge-score for choosing nodes to attack ################\n",
    "# attack adding/removing edge: (le budget adaptatif pour ajouter/enlever) ###############\n",
    "# surrogat model for each edge to be added or removed, target nodes selected manually\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from deeprobust.graph.defense import GCN\n",
    "from deeprobust.graph.utils import *\n",
    "from deeprobust.graph.data import Dataset\n",
    "from experiments import split_dataset\n",
    "from DistributedDefense import TwoPartyCNGCN\n",
    "import networkx as nx\n",
    "from scipy.sparse import csr_matrix\n",
    "import mahsa_backdoor as backdoor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch import nn, optim\n",
    "import scipy.sparse as sp\n",
    "import pickle\n",
    "\n",
    "# Define the number of repeats\n",
    "num_repeats = 1\n",
    "accuracy_test_attack_1_values = []\n",
    "accuracy_test_clean_1_values = []\n",
    "accuracy_test_attack_2_values = []\n",
    "accuracy_test_clean_2_values = []\n",
    "accuracy_test_attack_3_values = []\n",
    "accuracy_test_clean_3_values = []\n",
    "\n",
    "seed = 42  # Seed for reproducibility\n",
    "\n",
    "# Function to set seeds for reproducibility\n",
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Function to train surrogate model\n",
    "def train_surrogate_model(features, adj, labels, idx_train, idx_val):\n",
    "    surrogate_model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                          nhid=16, device=device, dropout=0.5)\n",
    "    surrogate_model = surrogate_model.to(device)\n",
    "    surrogate_model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    return surrogate_model\n",
    "\n",
    "# Function to compute the gradients of the loss function with respect to adjacency matrix\n",
    "def compute_gradients(surrogate_model, features, adj, labels, target_node):\n",
    "    surrogate_model.eval() # sets the surrogate model to evaluation mode. In evaluation mode, certain layers (like dropout and batch normalization) behave differently compared to training mode.\n",
    "    # Convert adjacency matrix to PyTorch tensor and enable gradient computation\n",
    "    adj = torch.FloatTensor(adj.toarray()).to(device)\n",
    "    adj.requires_grad = True\n",
    "     # Convert feature matrix and labels to PyTorch tensors\n",
    "    features = torch.FloatTensor(features.toarray()).to(device)\n",
    "    labels = torch.LongTensor(labels).to(device)\n",
    "    # Forward pass: compute model output (predictions) \n",
    "    output = surrogate_model(features, adj) \n",
    "    # Compute loss for the target node: how well the model's prediction matches the true label for the target_node\n",
    "    loss = F.nll_loss(output[[target_node]], labels[[target_node]]) \n",
    "    #The backward pass computes the gradients of the loss. These gradients indicate how changes in the adjacency matrix would affect the loss.\n",
    "    loss.backward()\n",
    "    gradients = adj.grad.cpu().numpy()  # The gradients are extracted from the adjacency matrix tensor and converted to a NumPy array on the CPU.\n",
    "    \n",
    "    # print(f\"Loss for target node {target_node}: {loss.item()}\")\n",
    "    # print(f\"Gradients for target node {target_node}: {gradients}\")\n",
    "    # # Check for non-zero gradients\n",
    "    # if not np.any(gradients):\n",
    "    #     print(f\"No non-zero gradients found for target node {target_node}.\")\n",
    "    # else:\n",
    "    #     non_zero_gradients = np.nonzero(gradients)\n",
    "    #     print(f\"Non-zero gradients for target node {target_node}:\")\n",
    "    #     for index in zip(*non_zero_gradients):\n",
    "    #         print(f\"Gradient at {index}: {gradients[index]}\")\n",
    "\n",
    "    return  loss.item(), gradients\n",
    "\n",
    "\n",
    "def calculate_common_neighbors(adj, node1, node2):\n",
    "    neighbors1 = set(adj[node1].indices)\n",
    "    neighbors2 = set(adj[node2].indices)\n",
    "    common_neighbors = neighbors1 & neighbors2\n",
    "    return len(common_neighbors) # The number of common neighbors between the two nodes is returned.\n",
    "\n",
    "\n",
    "def calc_nodes_to_attack(surrogate_model, features, adj, labels, idx_test):\n",
    "    zero_loss_count = 0\n",
    "    zero_gradients_count = 0\n",
    "    non_zero_loss_and_gradients_nodes = []\n",
    "    zero_loss_non_ziro_gr = 0\n",
    "\n",
    "    for target_node in idx_test:\n",
    "        loss, gradients = compute_gradients(surrogate_model, features, adj, labels, target_node)\n",
    "\n",
    "        if loss == 0:\n",
    "            zero_loss_count += 1\n",
    "        if not np.any(gradients):\n",
    "            zero_gradients_count += 1\n",
    "        \n",
    "        zero_loss = loss == 0\n",
    "        zero_gradients = not np.any(gradients)\n",
    "\n",
    "    # If both loss and gradients are non-zero, store the node\n",
    "        if not zero_loss and not zero_gradients:\n",
    "            impact_score = loss * np.sum(np.abs(gradients))\n",
    "            non_zero_loss_and_gradients_nodes.append((target_node, impact_score))\n",
    "        # Ensure consistency between zero loss and zero gradients\n",
    "        if zero_loss and not zero_gradients:\n",
    "            print(f\"Warning: Target node {target_node} has zero loss but non-zero gradients!\")\n",
    "            zero_loss_non_ziro_gr += 1\n",
    "        \n",
    "\n",
    "        print(f\"Target node is: {target_node} with label: {labels[target_node]}\")\n",
    "        print(f\"Loss for target node {target_node}: {loss}\")\n",
    "        print(f\"Gradients for target node {target_node}: {'Non-zero' if not zero_gradients else 'Zero'}\")\n",
    "    \n",
    "    # Print the counts of nodes with zero loss and zero gradients\n",
    "    print(f\"Final number of nodes with zero loss: {zero_loss_count}\")\n",
    "    print(f\"Final number of nodes with zero gradients: {zero_gradients_count}\")\n",
    "    print(f\"Final number of nodes with zero loss but non-zero gradients: {zero_loss_non_ziro_gr}\")\n",
    "\n",
    "    print(\"Nodes with non-zero loss and non-zero gradients:\")\n",
    "    for node in non_zero_loss_and_gradients_nodes:\n",
    "        print(node)\n",
    "    print(f\"Number of nodes with non-zero loss and non-zero gradients: {len(non_zero_loss_and_gradients_nodes)}\")\n",
    "\n",
    "    # Sort nodes by impact score in descending order\n",
    "    non_zero_loss_and_gradients_nodes.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Select top k nodes to attack\n",
    "    k = 10  # Number of nodes to attack\n",
    "    nodes_to_attack = [node for node, score in non_zero_loss_and_gradients_nodes[:k]]\n",
    "\n",
    "    print(\"Nodes to attack (node_id, impact_score):\")\n",
    "    for node, score in non_zero_loss_and_gradients_nodes[:k]:\n",
    "        print(f\"Node: {node}, Impact Score: {score}\")\n",
    "\n",
    "    return nodes_to_attack\n",
    "\n",
    "\n",
    "# Function to calculate edge scores based on gradients and common neighbors ...... it worked at least\n",
    "def calculate_edge_scores_common_neighbors(adj, gradients, target_node, labels, add=True):\n",
    "    scores = {}\n",
    "    for i in range(adj.shape[0]):\n",
    "        if add and adj[target_node, i] == 0 and labels[target_node] != labels[i]:  # Ensure different labels for adding\n",
    "            common_neighbors = calculate_common_neighbors(adj, target_node, i)\n",
    "            scores[(target_node, i)] = gradients[target_node, i] + common_neighbors\n",
    "        elif not add and adj[target_node, i] == 1 and labels[target_node] == labels[i]:  # Ensure same labels for removing\n",
    "            common_neighbors = calculate_common_neighbors(adj, target_node, i)\n",
    "            scores[(target_node, i)] = -gradients[target_node, i] + common_neighbors \n",
    "    return scores\n",
    "\n",
    "##### last version ----it worked at least but adds and removes.\n",
    "def select_best_edge_common_neighbors(adj, gradients, target_node, labels, add=True):\n",
    "    scores = calculate_edge_scores_common_neighbors(adj, gradients, target_node, labels, add)\n",
    "    if not scores:\n",
    "        return None\n",
    "    if add:\n",
    "        best_edge = max(scores, key=scores.get)\n",
    "    else:\n",
    "        best_edge = min(scores, key=scores.get)\n",
    "    return best_edge\n",
    "\n",
    "\n",
    "\n",
    "################################ Data loading #######################################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "dataset = \"polblogs\"\n",
    "data = Dataset(root='.', name=dataset, setting='gcn', seed=15)\n",
    "\n",
    "for _ in range(num_repeats):\n",
    "    set_seeds(seed)\n",
    "    adj, features, labels = data.adj, data.features, data.labels\n",
    "    idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "    # selected_node = 1196\n",
    "    # idx_test_attack = np.array([selected_node])\n",
    "    # idx_test_clean = np.array([node for node in idx_test if node != selected_node])\n",
    "    # print(f\"Selected node for attack: {selected_node}\")\n",
    "    # print(f\"Label of the selected node: {labels[selected_node]}\")\n",
    "    \n",
    "    ################### split idx_test into two parts : one node for attack randomley and the rest for clean\n",
    "    # test_size = 1  # 1 node for attack others for test_clean\n",
    "    # idx_test_clean , idx_test_attack = train_test_split(idx_test, test_size=test_size, random_state=42)\n",
    "    # selected_node = idx_test_attack[0]\n",
    "    # print(f\"Selected node for attack: {selected_node}\")\n",
    "    # print(f\"Label of the selected node: {labels[selected_node]}\")\n",
    "    ################ split idx_test into two parts randomly with a specific ratio %\n",
    "    # test_size = 0.10  # 10% for test_attack, 90% for test_clean\n",
    "    # idx_test_clean , idx_test_attack = train_test_split(idx_test, test_size=test_size, random_state=seed)\n",
    "    ######################\n",
    "\n",
    "\n",
    "\n",
    "     ######## train surrogate model to find the importance of each edge\n",
    "    surrogate_model = train_surrogate_model(features, adj, labels, idx_train, idx_val)\n",
    "\n",
    "\n",
    "    ################ split idx_test into two parts for attack: nodes_for_attack and the rest for clean\n",
    "    # Assuming nodes_to_attack is a function that returns the nodes to attack\n",
    "    idx_test_attack = calc_nodes_to_attack(surrogate_model, features, adj, labels, idx_test)\n",
    "    nodes_to_attack_set = set(idx_test_attack)\n",
    "    idx_test_clean = [node for node in idx_test if node not in nodes_to_attack_set]\n",
    "    print(f\"Nodes to attack: {idx_test_attack}, len= {len(idx_test_attack)}\")\n",
    "    print(f\"Nodes for clean: {idx_test_clean}, len= {len(idx_test_clean)}\")\n",
    "\n",
    "    ######################\n",
    "\n",
    "    proportion_of_common_links = 0.5\n",
    "    adj1, adj2 = split_dataset(adj, proportion_of_common_links) \n",
    "\n",
    "    # adj1 = sp.csr_matrix(adj1)\n",
    "    # adj2 = sp.csr_matrix(adj2)\n",
    "    # clean_adj1 = backdoor.remove_zero_weight_edges(adj1.copy())\n",
    "    # clean_adj2 = backdoor.remove_zero_weight_edges(adj2.copy())\n",
    "    \n",
    "    # neighbors_vector = adj1[selected_node, :].toarray()\n",
    "    # neighbors_indices = np.nonzero(neighbors_vector)[1]\n",
    "    # print(f\"num of neighbors of node {selected_node} is: {len(neighbors_indices)}\")\n",
    "    # print(\"Neighbors of node\", selected_node, \"are:\", neighbors_indices)\n",
    "\n",
    "    ###### Train GCN model initially for evaluation before attack\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    model.eval()\n",
    "    output = model.test(idx_test)\n",
    "\n",
    "    accuracy_test_attack_1 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_1 = model.test(idx_test_clean)\n",
    "    print(\"Test accuracy on attack set: \", accuracy_test_attack_1)\n",
    "    print(\"Test accuracy on clean set: \", accuracy_test_clean_1)\n",
    "\n",
    "   \n",
    "   \n",
    "    # modified_adj1 =  clean_adj1.copy()\n",
    "    # print(f\"Initial number of edges: {modified_adj1.nnz // 2}\")\n",
    "    # print(f\"Number of nodes: {modified_adj1.shape[0]}\")\n",
    "\n",
    "    budget = 5\n",
    "    ############### attack adj ################\n",
    "    attacked_adj = adj1.copy()\n",
    "    print(f\"idx_test_attack: {idx_test_attack}\")\n",
    "    edges_added_count = 0\n",
    "    edges_removed_count = 0\n",
    "\n",
    "    for target_node in idx_test_attack:\n",
    "        print(f\"Target node is: {target_node} with label: {labels[target_node]}\")\n",
    "        # neighbors_same_label = backdoor.find_same_neighbor_adj(attacked_adj, labels, target_node)\n",
    "        # neighbors_opposite_label = backdoor.find_opposite_neighbor_adj(attacked_adj, labels, target_node)\n",
    "        # print(f\"Number of target same label neighbors before attack: {len(neighbors_same_label)}\")\n",
    "        # print(f\"Number of target opposite label neighbors before attack: {len(neighbors_opposite_label)}\")\n",
    "\n",
    "        # Compute gradients and their signs\n",
    "        gradients = compute_gradients(surrogate_model, features, attacked_adj, labels, target_node)\n",
    "        print(f\"Gradients for target node {target_node}: {gradients}\")\n",
    "        \n",
    "        ##### it shows that all the gradients are zero, so we can not use them for attack\n",
    "        if not np.any(gradients):\n",
    "            print(f\"No non-zero gradients found for target node {target_node}. Skipping this node.\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        #### it works but it adds and removes\n",
    "        for _ in range(budget):\n",
    "            edge_add = select_best_edge_common_neighbors(attacked_adj, gradients, target_node, labels, add=True)\n",
    "            edge_remove = select_best_edge_common_neighbors(attacked_adj, gradients, target_node, labels, add=False)\n",
    "            print(f\"edge_add: {edge_add}, edge_remove: {edge_remove}\")\n",
    "            if edge_add:\n",
    "                attacked_adj[edge_add[0], edge_add[1]] = 1\n",
    "                attacked_adj[edge_add[1], edge_add[0]] = 1\n",
    "                edges_added_count += 1\n",
    "                print(f\"Added edge: {edge_add}\")\n",
    "            if edge_remove:\n",
    "                attacked_adj[edge_remove[0], edge_remove[1]] = 0\n",
    "                attacked_adj[edge_remove[1], edge_remove[0]] = 0\n",
    "                edges_removed_count += 1\n",
    "                print(f\"Removed edge: {edge_remove}\")\n",
    "                \n",
    "        #### it is not working, nothing is added or removed\n",
    "        # for _ in range(budget):\n",
    "        #         best_edge, action = select_best_edge_common_neighbors(attacked_adj, gradients, target_node, labels)\n",
    "        #         if not best_edge:\n",
    "        #             continue\n",
    "\n",
    "        #         if action == 'add':\n",
    "        #             attacked_adj[best_edge[0], best_edge[1]] = 1\n",
    "        #             attacked_adj[best_edge[1], best_edge[0]] = 1\n",
    "        #             edges_added_count += 1\n",
    "        #             print(f\"Added edge: {best_edge}\")\n",
    "\n",
    "        #         elif action == 'remove':\n",
    "        #             attacked_adj[best_edge[0], best_edge[1]] = 0\n",
    "        #             attacked_adj[best_edge[1], best_edge[0]] = 0\n",
    "        #             edges_removed_count += 1\n",
    "        #             print(f\"Removed edge: {best_edge}\")\n",
    "\n",
    "        print(f\"Total number of added edges during attack: {edges_added_count}\")\n",
    "        print(f\"Total number of removed edges during attack: {edges_removed_count}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ########## checking the adj wise changes after attack ##########\n",
    "    modified_adj1 = csr_matrix(attacked_adj)\n",
    "    print (f\"Number of edges added: {edges_added_count}\")\n",
    "    print (f\"Number of edges removed: {edges_removed_count}\")\n",
    "    # print(modified_adj1)\n",
    "\n",
    "    # check for the differences between the initial graph and the attacked graph\n",
    "    diff_adj_attack = modified_adj1 - clean_adj1\n",
    "    non_zero_diff = diff_adj_attack.nonzero()\n",
    "    print(f\"adj wise : modifications after attack: {non_zero_diff}\")\n",
    "    num_changes = len(non_zero_diff[0]) // 2\n",
    "    print(f\"adj wise: Number of modifications after attack: {num_changes}\")\n",
    "\n",
    "    # evaluation after attack\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    model.fit(features, modified_adj1, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    model.eval()\n",
    "\n",
    "    accuracy_test_attack_2 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_2 = model.test(idx_test_clean)\n",
    "\n",
    "    print(\"Test accuracy on attack set after attack: \", accuracy_test_attack_2)\n",
    "    print(\"Test accuracy on clean set after attack: \", accuracy_test_clean_2)\n",
    "\n",
    "    ################# Crypto'Graph defense ####################3\n",
    "    print(\"*************** Crypto'Graph defense ***************\")\n",
    "\n",
    "    threshold = 2\n",
    "    metric = \"neighbors\"\n",
    "    object = \"links\"\n",
    "    model = TwoPartyCNGCN(dataset=dataset, nfeat=features.shape[1], nhid=16, nclass=labels.max().item() + 1,\n",
    "                          device=device)\n",
    "    defense_duration, defense_duration, training_duration1, training_duration2, CG_defended_adj1, CG_defended_adj2 = model.fit(\n",
    "        modified_adj1.copy(), adj2.copy(), features, features, labels, idx_train, threshold, metric=metric, object=object,\n",
    "        train_iters=200, initialize=True, verbose=False, idx_val=idx_val)\n",
    "    model.eval()\n",
    "    accuracies = model.test(idx_test)\n",
    "    accuracy_test_attack_3 = model.test(idx_test_attack)\n",
    "    accuracy_test_clean_3 = model.test(idx_test_clean)\n",
    "    print(\"Test accuracy on attack set after Crypto'Graph: \", accuracy_test_attack_3)\n",
    "    print(\"Test accuracy on clean set after Crypto'Graph: \", accuracy_test_clean_3)\n",
    "\n",
    "    rows = CG_defended_adj1.shape[0]\n",
    "    print(f\"CG_defended_adj1. Number of rows: {rows}\")\n",
    "\n",
    "    print(\"*************** adj wise compare (before and after defense) ***************\")\n",
    "    differences = np.abs(CG_defended_adj1 - modified_adj1)\n",
    "    total_differences = np.sum(differences)\n",
    "    print(f\"adj check: Total number of differences: {total_differences}\")\n",
    "    rows_with_changes = np.count_nonzero(np.sum(differences, axis=1))\n",
    "    print(f\"Number of rows with changes: {rows_with_changes}\")\n",
    "    # changed_rows = np.where(np.sum(differences, axis=1) > 0)[0]\n",
    "    # print(f\"Rows with different connectivities: {changed_rows}\")\n",
    "\n",
    "    difference_matrix = CG_defended_adj1 - modified_adj1\n",
    "    rows, cols = np.triu_indices_from(difference_matrix, k=1)\n",
    "    upper_triangle_differences = difference_matrix[rows, cols]\n",
    "    removed_edges = np.argwhere(upper_triangle_differences < 0)\n",
    "    total_removed_edges = len(removed_edges)\n",
    "    print(f\"Total number of removed edges(adj) by the CG: {total_removed_edges}\")\n",
    "\n",
    "    # Identify the edges added during the attack and check if they are removed by CG defense\n",
    "    added_edges = []\n",
    "    removed_edges_by_CG = []\n",
    "    modified_adj1_array = modified_adj1.toarray()\n",
    "    clean_adj1_array = clean_adj1.toarray()\n",
    "\n",
    "    rows, cols = np.triu_indices(modified_adj1_array.shape[0], k=1)\n",
    "    for i, j in zip(rows, cols):\n",
    "        if modified_adj1_array[i, j] == 1 and clean_adj1_array[i, j] == 0:\n",
    "            added_edges.append((i, j))\n",
    "    print(f\"Added edges during attack: {added_edges}\")\n",
    "    print(f\"Total number of added edges during attack: {len(added_edges)}\")\n",
    "\n",
    "    removed_edges = []\n",
    "    for i, j in zip(rows, cols):\n",
    "        if modified_adj1_array[i, j] == 0 and clean_adj1_array[i, j] == 1:\n",
    "            removed_edges.append((i, j))\n",
    "    print(f\"Removed edges during attack: {removed_edges}\")\n",
    "    print(f\"Total number of removed edges during attack: {len(removed_edges)}\")\n",
    "\n",
    "\n",
    "    # check if added edges are removed by CG defense\n",
    "    for edge in added_edges:\n",
    "        i, j = edge\n",
    "        if CG_defended_adj1_array[i, j] == 0:\n",
    "            removed_edges_by_CG.append(edge)\n",
    "    print(f\"added edges during attack which are removed by CG defense: {removed_edges_by_CG}\")\n",
    "    print(f\"Total number of added edges during attack which are removed by CG defense: {len(removed_edges_by_CG)}\")\n",
    "\n",
    "    accuracy_test_attack_1_values.append(accuracy_test_attack_1)\n",
    "    accuracy_test_clean_1_values.append(accuracy_test_clean_1)\n",
    "    accuracy_test_attack_2_values.append(accuracy_test_attack_2)\n",
    "    accuracy_test_clean_2_values.append(accuracy_test_clean_2)\n",
    "    accuracy_test_attack_3_values.append(accuracy_test_attack_3)\n",
    "    accuracy_test_clean_3_values.append(accuracy_test_clean_3)\n",
    "\n",
    "accuracy_test_attack_1_std = np.std(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_std = np.std(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_std = np.std(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_std = np.std(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_std = np.std(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_std = np.std(accuracy_test_clean_3_values)\n",
    "\n",
    "with open('variables_std.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "                 accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "                 accuracy_test_attack_3_std, accuracy_test_clean_3_std], f)\n",
    "\n",
    "accuracy_test_attack_1_avg = np.mean(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_avg = np.mean(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_avg = np.mean(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_avg = np.mean(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_avg = np.mean(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_avg = np.mean(accuracy_test_clean_3_values)\n",
    "\n",
    "with open('variables.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "                 accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "                 accuracy_test_attack_3_avg, accuracy_test_clean_3_avg], f)\n",
    "\n",
    "labels = ['ACCs before attack', 'ACCs before attack', \n",
    "          'ACCs after attack', 'ACCs after attack', \n",
    "          'ACCs after CryptoGraph', 'ACCs after CryptoGraph']\n",
    "values = [accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "          accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "          accuracy_test_attack_3_avg, accuracy_test_clean_3_avg]\n",
    "std_devs = [accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "            accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "            accuracy_test_attack_3_std, accuracy_test_clean_3_std]\n",
    "x = np.arange(len(labels)//2)\n",
    "width = 0.35\n",
    "bars1 = plt.bar(x - width/2, values[::2], width, yerr=std_devs[::2], label='Attack set', color='red', capsize=5)\n",
    "bars2 = plt.bar(x + width/2, values[1::2], width, yerr=std_devs[1::2], label='Clean set', color='blue', capsize=5)\n",
    "plt.title('Average Accuracies')\n",
    "plt.xlabel('Levels of Attack and Defense')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.xticks(x, labels[::2])\n",
    "plt.legend()\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test V4.2\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from deeprobust.graph.defense import GCN\n",
    "from deeprobust.graph.utils import *\n",
    "from deeprobust.graph.data import Dataset\n",
    "from DistributedDefense import TwoPartyCNGCN\n",
    "from experiments import split_dataset\n",
    "from scipy.sparse import csr_matrix\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "dataset = \"polblogs\"\n",
    "data = Dataset(root='.', name=dataset, setting='gcn', seed=15)\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Train surrogate model\n",
    "def train_surrogate_model(features, adj, labels, idx_train, idx_val):\n",
    "    surrogate_model = GCN(nfeat=features.shape[1], nclass=labels.max().item() + 1, nhid=16, device=device, dropout=0.5)\n",
    "    surrogate_model = surrogate_model.to(device)\n",
    "    surrogate_model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    return surrogate_model\n",
    "\n",
    "# Compute gradients of loss w.r.t adjacency matrix\n",
    "def compute_gradients(surrogate_model, features, adj, labels, target_node):\n",
    "    surrogate_model.eval()\n",
    "    adj = torch.FloatTensor(adj.toarray()).to(device)\n",
    "    adj.requires_grad = True\n",
    "    features = torch.FloatTensor(features.toarray()).to(device)\n",
    "    labels = torch.LongTensor(labels).to(device)\n",
    "    output = surrogate_model(features, adj)\n",
    "    loss = F.nll_loss(output[[target_node]], labels[[target_node]])\n",
    "    loss.backward()\n",
    "    gradients = adj.grad.cpu().numpy()\n",
    "    return loss.item(), gradients\n",
    "\n",
    "def calc_nodes_to_attack(surrogate_model, features, adj, labels, idx_test):\n",
    "    zero_loss_count = 0\n",
    "    zero_gradients_count = 0\n",
    "    non_zero_loss_and_gradients_nodes = []\n",
    "    zero_loss_non_ziro_gr = 0\n",
    "\n",
    "    for target_node in idx_test:\n",
    "        loss, gradients = compute_gradients(surrogate_model, features, adj, labels, target_node)\n",
    "        if loss == 0:\n",
    "            zero_loss_count += 1\n",
    "        if not np.any(gradients):\n",
    "            zero_gradients_count += 1\n",
    "        \n",
    "        zero_loss = loss == 0\n",
    "        zero_gradients = not np.any(gradients)\n",
    "    # If both loss and gradients are non-zero, store the node\n",
    "        if not zero_loss and not zero_gradients:\n",
    "            impact_score = loss * np.sum(np.abs(gradients))\n",
    "            non_zero_loss_and_gradients_nodes.append((target_node, impact_score))\n",
    "        # Ensure consistency between zero loss and zero gradients\n",
    "        if zero_loss and not zero_gradients:\n",
    "            print(f\"Warning: Target node {target_node} has zero loss but non-zero gradients!\")\n",
    "            zero_loss_non_ziro_gr += 1\n",
    "    \n",
    "        print(f\"Target node is: {target_node} with label: {labels[target_node]}\")\n",
    "        print(f\"Loss for target node {target_node}: {loss}\")\n",
    "        print(f\"Gradients for target node {target_node}: {'Non-zero' if not zero_gradients else 'Zero'}\")\n",
    "    \n",
    "    # Print the counts of nodes with zero loss and zero gradients\n",
    "    print(f\"Final number of nodes with zero loss: {zero_loss_count}\")\n",
    "    print(f\"Final number of nodes with zero gradients: {zero_gradients_count}\")\n",
    "    print(f\"Final number of nodes with zero loss but non-zero gradients: {zero_loss_non_ziro_gr}\")\n",
    "\n",
    "    print(\"Nodes with non-zero loss and non-zero gradients:\")\n",
    "    for node in non_zero_loss_and_gradients_nodes:\n",
    "        print(node)\n",
    "    print(f\"Number of nodes with non-zero loss and non-zero gradients: {len(non_zero_loss_and_gradients_nodes)}\")\n",
    "\n",
    "    # Sort nodes by impact score in descending order\n",
    "    non_zero_loss_and_gradients_nodes.sort(key=lambda x: x[1], reverse=True)\n",
    "    nodes_to_attack = [node for node, score in non_zero_loss_and_gradients_nodes]\n",
    "\n",
    "    # Select top k nodes to attack\n",
    "    # k = 10  # Number of nodes to attack\n",
    "    # nodes_to_attack = [node for node, score in non_zero_loss_and_gradients_nodes[:k]]\n",
    "    # print(\"Nodes to attack (node_id, impact_score):\")\n",
    "    # for node, score in non_zero_loss_and_gradients_nodes[:k]:\n",
    "    #     print(f\"Node: {node}, Impact Score: {score}\")\n",
    "    return nodes_to_attack\n",
    "\n",
    "# Calculate common neighbors between two nodes\n",
    "def calculate_common_neighbors(adj, node1, node2):\n",
    "    neighbors1 = set(adj[node1].indices)\n",
    "    neighbors2 = set(adj[node2].indices)\n",
    "    common_neighbors = neighbors1 & neighbors2\n",
    "    return len(common_neighbors)\n",
    "\n",
    "# Calculate edge scores based on gradients and common neighbors\n",
    "def calculate_edge_scores(adj, gradients, target_node, labels, add=True):\n",
    "    scores = {}\n",
    "    for i in range(adj.shape[0]):\n",
    "        if add and adj[target_node, i] == 0 and labels[target_node] != labels[i]:\n",
    "            common_neighbors = calculate_common_neighbors(adj, target_node, i)\n",
    "            scores[(target_node, i)] = gradients[target_node, i] + common_neighbors\n",
    "        elif not add and adj[target_node, i] == 1 and labels[target_node] == labels[i]:\n",
    "            common_neighbors = calculate_common_neighbors(adj, target_node, i)\n",
    "            scores[(target_node, i)] = -gradients[target_node, i] + common_neighbors\n",
    "    return scores\n",
    "\n",
    "# Select best edge based on edge scores\n",
    "def select_best_edge(adj, gradients, target_node, labels, add=True):\n",
    "    scores = calculate_edge_scores(adj, gradients, target_node, labels, add)\n",
    "    if not scores:\n",
    "        return None\n",
    "    if add:\n",
    "        best_edge = max(scores, key=scores.get)\n",
    "    else:\n",
    "        best_edge = min(scores, key=scores.get)\n",
    "    return best_edge\n",
    "\n",
    "# Perturb edges between target nodes\n",
    "def perturb_edges_between_targets(adj, surrogate_model, features, labels, idx_test_attack, budget):\n",
    "    attacked_adj = adj.copy()\n",
    "    for target_node in idx_test_attack:\n",
    "        loss, gradients = compute_gradients(surrogate_model, features, attacked_adj, labels, target_node)\n",
    "        if not np.any(gradients):\n",
    "            continue\n",
    "        for _ in range(budget):\n",
    "            edge_add = select_best_edge(attacked_adj, gradients, target_node, labels, add=True)\n",
    "            edge_remove = select_best_edge(attacked_adj, gradients, target_node, labels, add=False)\n",
    "            if edge_add:\n",
    "                attacked_adj[edge_add[0], edge_add[1]] = 1\n",
    "                attacked_adj[edge_add[1], edge_add[0]] = 1\n",
    "            if edge_remove:\n",
    "                attacked_adj[edge_remove[0], edge_remove[1]] = 0\n",
    "                attacked_adj[edge_remove[1], edge_remove[0]] = 0\n",
    "    return attacked_adj\n",
    "\n",
    "# Main execution\n",
    "set_seeds(42)\n",
    "adj, features, labels = data.adj, data.features, data.labels\n",
    "idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "surrogate_model = train_surrogate_model(features, adj, labels, idx_train, idx_val)\n",
    "\n",
    "# Determine nodes to attack\n",
    "k = 10\n",
    "nodes_to_attack = calc_nodes_to_attack(surrogate_model, features, adj, labels, idx_test)\n",
    "idx_test_attack = nodes_to_attack[:k]\n",
    "idx_test_clean = [node for node in idx_test if node not in idx_test_attack]\n",
    "\n",
    "# Initial model evaluation\n",
    "model = GCN(nfeat=features.shape[1], nclass=labels.max().item() + 1, nhid=16, device=device, dropout=0.5)\n",
    "model = model.to(device)\n",
    "model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "model.eval()\n",
    "\n",
    "# Initial accuracy\n",
    "accuracy_test_attack_1 = model.test(idx_test_attack)\n",
    "accuracy_test_clean_1 = model.test(idx_test_clean)\n",
    "print(\"Initial test accuracy on attack set: \", accuracy_test_attack_1)\n",
    "print(\"Initial test accuracy on clean set: \", accuracy_test_clean_1)\n",
    "print(\"start attacking\")\n",
    "\n",
    "# Perturb edges\n",
    "budget = 5\n",
    "attacked_adj = perturb_edges_between_targets(adj, surrogate_model, features, labels, idx_test_attack, budget)\n",
    "\n",
    "# Model evaluation after attack\n",
    "model.fit(features, attacked_adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "model.eval()\n",
    "\n",
    "accuracy_test_attack_2 = model.test(idx_test_attack)\n",
    "accuracy_test_clean_2 = model.test(idx_test_clean)\n",
    "print(\"Test accuracy on attack set after attack: \", accuracy_test_attack_2)\n",
    "print(\"Test accuracy on clean set after attack: \", accuracy_test_clean_2)\n",
    "\n",
    "# Crypto'Graph defense\n",
    "print(\"*************** Crypto'Graph defense ***************\")\n",
    "proportion_of_common_links = 0.5\n",
    "adj1, adj2 = split_dataset(attacked_adj, proportion_of_common_links)\n",
    "model = TwoPartyCNGCN(dataset=dataset, nfeat=features.shape[1], nhid=16, nclass=labels.max().item() + 1, device=device)\n",
    "model.fit(adj1, adj2, features, features, labels, idx_train, threshold=2, metric=\"neighbors\", object=\"links\", train_iters=200, initialize=True, verbose=False, idx_val=idx_val)\n",
    "model.eval()\n",
    "\n",
    "accuracy_test_attack_3 = model.test(idx_test_attack)\n",
    "accuracy_test_clean_3 = model.test(idx_test_clean)\n",
    "print(\"Test accuracy on attack set after Crypto'Graph: \", accuracy_test_attack_3)\n",
    "print(\"Test accuracy on clean set after Crypto'Graph: \", accuracy_test_clean_3)\n",
    "\n",
    "# Save and plot results\n",
    "with open('variables.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1, accuracy_test_clean_1, accuracy_test_attack_2, accuracy_test_clean_2, accuracy_test_attack_3, accuracy_test_clean_3], f)\n",
    "\n",
    "# Ensure values and std_devs are properly formatted as floats\n",
    "values = [float(accuracy_test_attack_1), float(accuracy_test_clean_1),\n",
    "          float(accuracy_test_attack_2), float(accuracy_test_clean_2),\n",
    "          float(accuracy_test_attack_3), float(accuracy_test_clean_3)]\n",
    "\n",
    "# Assuming std_devs were previously calculated and are available in the same format\n",
    "std_devs = [np.std([accuracy_test_attack_1]), np.std([accuracy_test_clean_1]),\n",
    "            np.std([accuracy_test_attack_2]), np.std([accuracy_test_clean_2]),\n",
    "            np.std([accuracy_test_attack_3]), np.std([accuracy_test_clean_3])]\n",
    "\n",
    "labels = ['Initial Attack', 'Initial Clean', 'After Attack', 'After Clean', 'After CryptoGraph', 'After CryptoGraph']\n",
    "\n",
    "x = np.arange(len(labels) // 2)\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bars1 = ax.bar(x - width / 2, values[::2], width, label='Attack Set', color='red', capsize=5)\n",
    "bars2 = ax.bar(x + width / 2, values[1::2], width, label='Clean Set', color='blue', capsize=5)\n",
    "\n",
    "ax.set_xlabel('Stages')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy at Different Stages')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels[::2])\n",
    "ax.legend()\n",
    "\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test V4.2\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from deeprobust.graph.defense import GCN\n",
    "from deeprobust.graph.utils import *\n",
    "from deeprobust.graph.data import Dataset\n",
    "from DistributedDefense import TwoPartyCNGCN\n",
    "from experiments import split_dataset\n",
    "from scipy.sparse import csr_matrix\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Train surrogate model\n",
    "def train_surrogate_model(features, adj, labels, idx_train, idx_val):\n",
    "    surrogate_model = GCN(nfeat=features.shape[1], nclass=labels.max().item() + 1, nhid=16, device=device, dropout=0.5)\n",
    "    surrogate_model = surrogate_model.to(device)\n",
    "    surrogate_model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    return surrogate_model\n",
    "\n",
    "# Compute gradients of loss w.r.t adjacency matrix\n",
    "def compute_gradients(surrogate_model, features, adj, labels, target_node):\n",
    "    surrogate_model.eval()\n",
    "    adj = torch.FloatTensor(adj.toarray()).to(device)\n",
    "    adj.requires_grad = True\n",
    "    features = torch.FloatTensor(features.toarray()).to(device)\n",
    "    labels = torch.LongTensor(labels).to(device)\n",
    "    output = surrogate_model(features, adj)\n",
    "    loss = F.nll_loss(output[[target_node]], labels[[target_node]])\n",
    "    loss.backward()\n",
    "    gradients = adj.grad.cpu().numpy()\n",
    "    return loss.item(), gradients\n",
    "\n",
    "def calc_nodes_to_attack(surrogate_model, features, adj, labels, idx_test):\n",
    "    zero_loss_count = 0\n",
    "    zero_gradients_count = 0\n",
    "    non_zero_loss_and_gradients_nodes = []\n",
    "    zero_loss_non_ziro_gr = 0\n",
    "\n",
    "    for target_node in idx_test:\n",
    "        loss, gradients = compute_gradients(surrogate_model, features, adj, labels, target_node)\n",
    "        if loss == 0:\n",
    "            zero_loss_count += 1\n",
    "        if not np.any(gradients):\n",
    "            zero_gradients_count += 1\n",
    "        \n",
    "        zero_loss = loss == 0\n",
    "        zero_gradients = not np.any(gradients)\n",
    "    # If both loss and gradients are non-zero, store the node\n",
    "        if not zero_loss and not zero_gradients:\n",
    "            impact_score = loss * np.sum(np.abs(gradients))\n",
    "            non_zero_loss_and_gradients_nodes.append((target_node, impact_score))\n",
    "        # Ensure consistency between zero loss and zero gradients\n",
    "        if zero_loss and not zero_gradients:\n",
    "            # print(f\"Warning: Target node {target_node} has zero loss but non-zero gradients!\")\n",
    "            zero_loss_non_ziro_gr += 1\n",
    "    \n",
    "        # print(f\"Target node is: {target_node} with label: {labels[target_node]}\")\n",
    "        # print(f\"Loss for target node {target_node}: {loss}\")\n",
    "        # print(f\"Gradients for target node {target_node}: {'Non-zero' if not zero_gradients else 'Zero'}\")\n",
    "    \n",
    "    # Print the counts of nodes with zero loss and zero gradients\n",
    "    print(f\"Final number of nodes with zero loss: {zero_loss_count}\")\n",
    "    print(f\"Final number of nodes with zero gradients: {zero_gradients_count}\")\n",
    "    print(f\"Final number of nodes with zero loss but non-zero gradients: {zero_loss_non_ziro_gr}\")\n",
    "\n",
    "    # print(\"Nodes with non-zero loss and non-zero gradients:\")\n",
    "    # for node in non_zero_loss_and_gradients_nodes:\n",
    "    #     print(node)\n",
    "    print(f\"Number of nodes with non-zero loss and non-zero gradients: {len(non_zero_loss_and_gradients_nodes)}\")\n",
    "\n",
    "    # Sort nodes by impact score in descending order\n",
    "    non_zero_loss_and_gradients_nodes.sort(key=lambda x: x[1], reverse=True)\n",
    "    nodes_to_attack = [node for node, score in non_zero_loss_and_gradients_nodes]\n",
    "\n",
    "    # Select top k nodes to attack\n",
    "    # k = 10  # Number of nodes to attack\n",
    "    # nodes_to_attack = [node for node, score in non_zero_loss_and_gradients_nodes[:k]]\n",
    "    # print(\"Nodes to attack (node_id, impact_score):\")\n",
    "    # for node, score in non_zero_loss_and_gradients_nodes[:k]:\n",
    "    #     print(f\"Node: {node}, Impact Score: {score}\")\n",
    "    return nodes_to_attack\n",
    "\n",
    "# Calculate common neighbors between two nodes\n",
    "def calculate_common_neighbors(adj, node1, node2):\n",
    "    neighbors1 = set(adj[node1].indices)\n",
    "    neighbors2 = set(adj[node2].indices)\n",
    "    common_neighbors = neighbors1 & neighbors2\n",
    "    return len(common_neighbors)\n",
    "\n",
    "# Calculate edge scores based on gradients and common neighbors\n",
    "def calculate_edge_scores(adj, gradients, target_node, labels, add=True):\n",
    "    scores = {}\n",
    "    for i in range(adj.shape[0]):\n",
    "        if add and adj[target_node, i] == 0 and labels[target_node] != labels[i]:\n",
    "            common_neighbors = calculate_common_neighbors(adj, target_node, i)\n",
    "            scores[(target_node, i)] = gradients[target_node, i] + common_neighbors\n",
    "        elif not add and adj[target_node, i] == 1 and labels[target_node] == labels[i]:\n",
    "            common_neighbors = calculate_common_neighbors(adj, target_node, i)\n",
    "            scores[(target_node, i)] = -gradients[target_node, i] + common_neighbors\n",
    "    return scores\n",
    "\n",
    "# Select best edge based on edge scores\n",
    "def select_best_edge(adj, gradients, target_node, labels, add=True):\n",
    "    scores = calculate_edge_scores(adj, gradients, target_node, labels, add)\n",
    "    if not scores:\n",
    "        return None\n",
    "    if add:\n",
    "        best_edge = max(scores, key=scores.get)\n",
    "    else:\n",
    "        best_edge = min(scores, key=scores.get)\n",
    "    return best_edge\n",
    "\n",
    "# Perturb edges between target nodes\n",
    "def perturb_edges_between_targets(adj, surrogate_model, features, labels, idx_test_attack, budget):\n",
    "    attacked_adj = adj.copy()\n",
    "    edge_added_count = 0\n",
    "    edge_removed_count = 0\n",
    "    for target_node in idx_test_attack:\n",
    "        print(f\"Target node is: {target_node} with label: {labels[target_node]}\")\n",
    "        loss, gradients = compute_gradients(surrogate_model, features, attacked_adj, labels, target_node)\n",
    "        if not np.any(gradients):\n",
    "            continue\n",
    "        for _ in range(budget):\n",
    "            edge_add = select_best_edge(attacked_adj, gradients, target_node, labels, add=True)\n",
    "            edge_remove = select_best_edge(attacked_adj, gradients, target_node, labels, add=False)\n",
    "            # print(f\"edge_add: {edge_add}, edge_remove: {edge_remove}\")\n",
    "            if edge_add:\n",
    "                attacked_adj[edge_add[0], edge_add[1]] = 1\n",
    "                attacked_adj[edge_add[1], edge_add[0]] = 1\n",
    "                edge_added_count += 1\n",
    "                print(f\"Added edge: {edge_add}\")\n",
    "            if edge_remove:\n",
    "                attacked_adj[edge_remove[0], edge_remove[1]] = 0\n",
    "                attacked_adj[edge_remove[1], edge_remove[0]] = 0\n",
    "                edge_removed_count += 1\n",
    "                print(f\"Removed edge: {edge_remove}\")\n",
    "    return attacked_adj\n",
    "\n",
    "# Main execution\n",
    "################################ Data loading #######################################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "dataset = \"polblogs\"\n",
    "data = Dataset(root='.', name=dataset, setting='gcn', seed=15)\n",
    "seed = 42\n",
    " \n",
    "set_seeds(seed)\n",
    "adj, features, labels = data.adj, data.features, data.labels\n",
    "idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "\n",
    "############  Train surrogate model and determine nodes to attack\n",
    "surrogate_model = train_surrogate_model(features, adj, labels, idx_train, idx_val)\n",
    "\n",
    "k = 10  # budget in the meaning of Number of nodes to attack\n",
    "nodes_to_attack = calc_nodes_to_attack(surrogate_model, features, adj, labels, idx_test)\n",
    "idx_test_attack = nodes_to_attack[:k]\n",
    "idx_test_clean = [node for node in idx_test if node not in idx_test_attack]\n",
    "\n",
    "########### Train GCN model initially for evaluation before attack\n",
    "model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "            nhid=16, device=device, dropout=0.5)\n",
    "model = model.to(device)\n",
    "model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "model.eval()\n",
    "output = model.test(idx_test)\n",
    "\n",
    "accuracy_test_attack_1 = model.test(idx_test_attack) \n",
    "accuracy_test_clean_1 = model.test(idx_test_clean)\n",
    "print(\"Test accuracy on attack set: \", accuracy_test_attack_1)\n",
    "print(\"Test accuracy on clean set: \", accuracy_test_clean_1)\n",
    "\n",
    "############# perform attack Perturb edges\n",
    "budget = 1  # Number of edges to add or remove for each target node\n",
    "attacked_adj = perturb_edges_between_targets(adj, surrogate_model, features, labels, idx_test_attack, budget)\n",
    "\n",
    "# Model evaluation after attack\n",
    "model.fit(features, attacked_adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "model.eval()\n",
    "\n",
    "accuracy_test_attack_2 = model.test(idx_test_attack)\n",
    "accuracy_test_clean_2 = model.test(idx_test_clean)\n",
    "print(\"Test accuracy on attack set after attack: \", accuracy_test_attack_2)\n",
    "print(\"Test accuracy on clean set after attack: \", accuracy_test_clean_2)\n",
    "\n",
    "##################   Crypto'Graph defense\n",
    "print(\"*************** Crypto'Graph defense ***************\")\n",
    "roportion_of_common_links = 0.5\n",
    "adj1, adj2 = split_dataset(attacked_adj, proportion_of_common_links) \n",
    "threshold = 2\n",
    "metric = \"neighbors\"\n",
    "object = \"links\"\n",
    "\n",
    "model = TwoPartyCNGCN(dataset=dataset, nfeat=features.shape[1], nhid=16, nclass=labels.max().item() + 1, device=device)\n",
    "defense_duration, defense_duration, training_duration1, training_duration2, CG_defended_adj1, CG_defended_adj2 = model.fit(\n",
    "        adj1.copy(), adj2.copy(), features, features, labels, idx_train, threshold, metric=metric, object=object,\n",
    "        train_iters=200, initialize=True, verbose=False, idx_val=idx_val)\n",
    "model.eval()\n",
    "\n",
    "accuracy_test_attack_3 = model.test(idx_test_attack)\n",
    "accuracy_test_clean_3 = model.test(idx_test_clean)\n",
    "print(\"Test accuracy on attack set after Crypto'Graph: \", accuracy_test_attack_3)\n",
    "print(\"Test accuracy on clean set after Crypto'Graph: \", accuracy_test_clean_3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################ Save and plot results\n",
    "accuracy_test_attack_1_std = np.std(accuracy_test_attack_1)\n",
    "accuracy_test_clean_1_std = np.std(accuracy_test_clean_1)\n",
    "accuracy_test_attack_2_std = np.std(accuracy_test_attack_2)\n",
    "accuracy_test_clean_2_std = np.std(accuracy_test_clean_2)\n",
    "accuracy_test_attack_3_std = np.std(accuracy_test_attack_3)\n",
    "accuracy_test_clean_3_std = np.std(accuracy_test_clean_3)\n",
    "\n",
    "with open('variables_std.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "                 accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "                 accuracy_test_attack_3_std, accuracy_test_clean_3_std], f)\n",
    "\n",
    "accuracy_test_attack_1_avg = np.mean(accuracy_test_attack_1)\n",
    "accuracy_test_clean_1_avg = np.mean(accuracy_test_clean_1)\n",
    "accuracy_test_attack_2_avg = np.mean(accuracy_test_attack_2)\n",
    "accuracy_test_clean_2_avg = np.mean(accuracy_test_clean_2)\n",
    "accuracy_test_attack_3_avg = np.mean(accuracy_test_attack_3)\n",
    "accuracy_test_clean_3_avg = np.mean(accuracy_test_clean_3)\n",
    "\n",
    "with open('variables.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "                 accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "                 accuracy_test_attack_3_avg, accuracy_test_clean_3_avg], f)\n",
    "\n",
    "labels = ['ACCs before attack', 'ACCs before attack', \n",
    "          'ACCs after attack', 'ACCs after attack', \n",
    "          'ACCs after CryptoGraph', 'ACCs after CryptoGraph']\n",
    "values = [accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "          accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "          accuracy_test_attack_3_avg, accuracy_test_clean_3_avg]\n",
    "std_devs = [accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "            accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "            accuracy_test_attack_3_std, accuracy_test_clean_3_std]\n",
    "x = np.arange(len(labels)//2)\n",
    "width = 0.35\n",
    "bars1 = plt.bar(x - width/2, values[::2], width, yerr=std_devs[::2], label='Attack set', color='red', capsize=5)\n",
    "bars2 = plt.bar(x + width/2, values[1::2], width, yerr=std_devs[1::2], label='Clean set', color='blue', capsize=5)\n",
    "plt.title('Average Accuracies')\n",
    "plt.xlabel('Levels of Attack and Defense')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.xticks(x, labels[::2])\n",
    "plt.legend()\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading polblogs dataset...\n",
      "Final number of nodes with zero loss: 737\n",
      "Final number of nodes with zero gradients: 690\n",
      "Final number of nodes with zero loss but non-zero gradients: 47\n",
      "Number of nodes with non-zero loss and non-zero gradients: 213\n",
      "Nodes chosen for attack: [1130, 275, 118]\n",
      "Test set results: loss= 0.3643 accuracy= 0.8547\n",
      "Test set results: loss= 2.3023 accuracy= 0.0000\n",
      "Test set results: loss= 0.3581 accuracy= 0.8574\n",
      "Test accuracy on attack set:  0.0\n",
      "Test accuracy on clean set:  0.8574445617740233\n",
      "Target node is: 1130 with label: 1\n",
      "Added edge: (1130, 362)\n",
      "Removed edge: (1130, 1228)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahsa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\scipy\\sparse\\_index.py:102: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added edge: (1130, 728)\n",
      "Added edge: (1130, 179)\n",
      "Added edge: (1130, 492)\n",
      "Added edge: (1130, 143)\n",
      "Target node is: 275 with label: 0\n",
      "Added edge: (275, 1100)\n",
      "Removed edge: (275, 695)\n",
      "Added edge: (275, 999)\n",
      "Removed edge: (275, 159)\n",
      "Added edge: (275, 1152)\n",
      "Removed edge: (275, 742)\n",
      "Added edge: (275, 1478)\n",
      "Removed edge: (275, 240)\n",
      "Added edge: (275, 1111)\n",
      "Removed edge: (275, 258)\n",
      "Target node is: 118 with label: 0\n",
      "Added edge: (118, 854)\n",
      "Removed edge: (118, 311)\n",
      "Added edge: (118, 1100)\n",
      "Removed edge: (118, 600)\n",
      "Added edge: (118, 1152)\n",
      "Removed edge: (118, 748)\n",
      "Added edge: (118, 999)\n",
      "Removed edge: (118, 498)\n",
      "Added edge: (118, 879)\n",
      "Removed edge: (118, 327)\n",
      "Total number of edges added: 15\n",
      "Total number of edges removed: 11\n",
      "Test set results: loss= 2.3334 accuracy= 0.0000\n",
      "Test set results: loss= 0.3809 accuracy= 0.8511\n",
      "Test accuracy on attack set after attack:  0.0\n",
      "Test accuracy on clean set after attack:  0.8511087645195353\n",
      "*************** Crypto'Graph defense ***************\n",
      "Dropping dissimilar edges using metric :  neighbors  on links\n",
      "removed 1668 edges in polblogs 1\n",
      "removed 1630 edges in polblogs 2\n",
      "*** polblogs 1 ***\n",
      "Test set results: loss= 2.3569 accuracy= 0.0000\n",
      "*** polblogs 2 ***\n",
      "Test set results: loss= 2.3983 accuracy= 0.0000\n",
      "*** polblogs 1 ***\n",
      "Test set results: loss= 0.4463 accuracy= 0.7307\n",
      "*** polblogs 2 ***\n",
      "Test set results: loss= 0.4517 accuracy= 0.7307\n",
      "Test accuracy on attack set after Crypto'Graph:  (0.0, 0.0)\n",
      "Test accuracy on clean set after Crypto'Graph:  (0.7307286166842661, 0.7307286166842661)\n",
      "Total number of removed edges by CG: 2203\n",
      "Inserted edges removed by CG: []\n",
      "Number of inserted edges removed by CG: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######## mahsa-V4.2: using surrogate model - using loss fonc and gradiant base- edge-score for choosing nodes to attack ################\n",
    "# attack adding/removing edge: (NOT YET implemented le budget adaptatif pour ajouter/enlever) ###############\n",
    "# surrogat model for each edge to be added or removed via gradient and loss of edges and common neighbors\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from deeprobust.graph.defense import GCN\n",
    "from deeprobust.graph.utils import *\n",
    "from deeprobust.graph.data import Dataset\n",
    "from DistributedDefense import TwoPartyCNGCN\n",
    "from experiments import split_dataset\n",
    "from scipy.sparse import csr_matrix\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Train surrogate model\n",
    "def train_surrogate_model(features, adj, labels, idx_train, idx_val):\n",
    "    surrogate_model = GCN(nfeat=features.shape[1], nclass=labels.max().item() + 1, nhid=16, device=device, dropout=0.5)\n",
    "    surrogate_model = surrogate_model.to(device)\n",
    "    surrogate_model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    return surrogate_model\n",
    "\n",
    "# Compute gradients of loss w.r.t adjacency matrix\n",
    "def compute_gradients(surrogate_model, features, adj, labels, target_node):\n",
    "    surrogate_model.eval()\n",
    "    adj = torch.FloatTensor(adj.toarray()).to(device)\n",
    "    adj.requires_grad = True\n",
    "    features = torch.FloatTensor(features.toarray()).to(device)\n",
    "    labels = torch.LongTensor(labels).to(device)\n",
    "    output = surrogate_model(features, adj)\n",
    "    loss = F.nll_loss(output[[target_node]], labels[[target_node]])\n",
    "    loss.backward()\n",
    "    gradients = adj.grad.cpu().numpy()\n",
    "    return loss.item(), gradients\n",
    "\n",
    "# choose nodes to attack based on loss and gradients not common neighbors\n",
    "def calc_nodes_to_attack(surrogate_model, features, adj, labels, idx_test):\n",
    "    zero_loss_count = 0\n",
    "    zero_gradients_count = 0\n",
    "    non_zero_loss_and_gradients_nodes = []\n",
    "    zero_loss_non_ziro_gr = 0\n",
    "\n",
    "    for target_node in idx_test:\n",
    "        loss, gradients = compute_gradients(surrogate_model, features, adj, labels, target_node)\n",
    "        if loss == 0:\n",
    "            zero_loss_count += 1\n",
    "        if not np.any(gradients):\n",
    "            zero_gradients_count += 1\n",
    "        \n",
    "        zero_loss = loss == 0\n",
    "        zero_gradients = not np.any(gradients)\n",
    "    # If both loss and gradients are non-zero, store the node\n",
    "        if not zero_loss and not zero_gradients:\n",
    "            impact_score = loss * np.sum(np.abs(gradients))\n",
    "            non_zero_loss_and_gradients_nodes.append((target_node, impact_score))\n",
    "        # Ensure consistency between zero loss and zero gradients\n",
    "        if zero_loss and not zero_gradients:\n",
    "            # print(f\"Warning: Target node {target_node} has zero loss but non-zero gradients!\")\n",
    "            zero_loss_non_ziro_gr += 1\n",
    "    \n",
    "    print(f\"Final number of nodes with zero loss: {zero_loss_count}\")\n",
    "    print(f\"Final number of nodes with zero gradients: {zero_gradients_count}\")\n",
    "    print(f\"Final number of nodes with zero loss but non-zero gradients: {zero_loss_non_ziro_gr}\")\n",
    "    # print(\"Nodes with non-zero loss and non-zero gradients:\")\n",
    "    # for node in non_zero_loss_and_gradients_nodes:\n",
    "    #     print(node)\n",
    "    print(f\"Number of nodes with non-zero loss and non-zero gradients: {len(non_zero_loss_and_gradients_nodes)}\")\n",
    "    # Sort nodes by impact score in descending order\n",
    "    non_zero_loss_and_gradients_nodes.sort(key=lambda x: x[1], reverse=True)\n",
    "    nodes_to_attack = [node for node, score in non_zero_loss_and_gradients_nodes]\n",
    "    return nodes_to_attack\n",
    "\n",
    "\n",
    "####### new strategy of adding alpha beta to the impact score to consider the common neighbors while selecting nodes to attack\n",
    "####### not have good results all 0.1 accuracies.\n",
    "# def calc_nodes_to_attack(surrogate_model, features, adj, labels, idx_test, alpha=1.0, beta=1.0):\n",
    "#     zero_loss_count = 0\n",
    "#     zero_gradients_count = 0\n",
    "#     non_zero_loss_and_gradients_nodes = []\n",
    "#     zero_loss_non_ziro_gr = 0\n",
    "\n",
    "#     for target_node in idx_test:\n",
    "#         loss, gradients = compute_gradients(surrogate_model, features, adj, labels, target_node)\n",
    "#         if loss == 0:\n",
    "#             zero_loss_count += 1\n",
    "#         if not np.any(gradients):\n",
    "#             zero_gradients_count += 1\n",
    "        \n",
    "#         zero_loss = loss == 0\n",
    "#         zero_gradients = not np.any(gradients)\n",
    "#         if not zero_loss and not zero_gradients:\n",
    "#             impact_score = loss * np.sum(np.abs(gradients))\n",
    "#             common_neighbors = sum(calculate_common_neighbors(adj, target_node, i) for i in range(adj.shape[0]) if i != target_node)\n",
    "#             final_score = alpha * impact_score + beta * common_neighbors\n",
    "#             non_zero_loss_and_gradients_nodes.append((target_node, final_score))\n",
    "        \n",
    "#         if zero_loss and not zero_gradients:\n",
    "#             zero_loss_non_ziro_gr += 1\n",
    "    \n",
    "#     print(f\"Final number of nodes with zero loss: {zero_loss_count}\")\n",
    "#     print(f\"Final number of nodes with zero gradients: {zero_gradients_count}\")\n",
    "#     print(f\"Final number of nodes with zero loss but non-zero gradients: {zero_loss_non_ziro_gr}\")\n",
    "#     print(f\"Number of nodes with non-zero loss and non-zero gradients: {len(non_zero_loss_and_gradients_nodes)}\")\n",
    "\n",
    "#     # Sort nodes by the final score in descending order\n",
    "#     non_zero_loss_and_gradients_nodes.sort(key=lambda x: x[1], reverse=True)\n",
    "#     nodes_to_attack = [node for node, score in non_zero_loss_and_gradients_nodes]\n",
    "#     return nodes_to_attack\n",
    "\n",
    "\n",
    "\n",
    "# Calculate common neighbors between two nodes\n",
    "def calculate_common_neighbors(adj, node1, node2):\n",
    "    neighbors1 = set(adj[node1].indices)\n",
    "    neighbors2 = set(adj[node2].indices)\n",
    "    common_neighbors = neighbors1 & neighbors2\n",
    "    return len(common_neighbors)\n",
    "\n",
    "# Calculate edge scores based on gradients and common neighbors\n",
    "def calculate_edge_scores(adj, gradients, target_node, labels, add=True):\n",
    "    scores = {}\n",
    "    for i in range(adj.shape[0]):\n",
    "        if add and adj[target_node, i] == 0 and labels[target_node] != labels[i]:\n",
    "            common_neighbors = calculate_common_neighbors(adj, target_node, i)\n",
    "            scores[(target_node, i)] = gradients[target_node, i] + common_neighbors #* 10  # 10 is a hyperparameter, can be tuned\n",
    "        elif not add and adj[target_node, i] == 1 and labels[target_node] == labels[i]:\n",
    "            common_neighbors = calculate_common_neighbors(adj, target_node, i)\n",
    "            scores[(target_node, i)] = -gradients[target_node, i] + common_neighbors #* 10 # 10 is a hyperparameter\n",
    "    return scores\n",
    "\n",
    "# Select best edge based on edge scores\n",
    "def select_best_edge(adj, gradients, target_node, labels, add=True):\n",
    "    scores = calculate_edge_scores(adj, gradients, target_node, labels, add) ########################################just add?\n",
    "    if not scores:\n",
    "        return None\n",
    "    if add:\n",
    "        best_edge = max(scores, key=scores.get)\n",
    "    else:\n",
    "        best_edge = min(scores, key=scores.get)\n",
    "    return best_edge\n",
    "\n",
    "# Perturb edges between target nodes\n",
    "def perturb_edges_between_targets(adj, surrogate_model, features, labels, idx_test_attack, budget):\n",
    "    attacked_adj = adj.copy()\n",
    "    added_edges = []  # Track added edges\n",
    "    edge_added_count = 0\n",
    "    edge_removed_count = 0\n",
    "    for target_node in idx_test_attack:\n",
    "        print(f\"Target node is: {target_node} with label: {labels[target_node]}\")\n",
    "        loss, gradients = compute_gradients(surrogate_model, features, attacked_adj, labels, target_node)\n",
    "        if not np.any(gradients):\n",
    "            continue\n",
    "        for _ in range(budget):\n",
    "            edge_add = select_best_edge(attacked_adj, gradients, target_node, labels, add=True)\n",
    "            edge_remove = select_best_edge(attacked_adj, gradients, target_node, labels, add=False)\n",
    "            # print(f\"edge_add: {edge_add}, edge_remove: {edge_remove}\")\n",
    "            if edge_add:\n",
    "                attacked_adj[edge_add[0], edge_add[1]] = 1\n",
    "                attacked_adj[edge_add[1], edge_add[0]] = 1\n",
    "                added_edges.append(edge_add)  # Track added edge\n",
    "                edge_added_count += 1\n",
    "                print(f\"Added edge: {edge_add}\")\n",
    "            if edge_remove:\n",
    "                attacked_adj[edge_remove[0], edge_remove[1]] = 0\n",
    "                attacked_adj[edge_remove[1], edge_remove[0]] = 0\n",
    "                edge_removed_count += 1\n",
    "                print(f\"Removed edge: {edge_remove}\")\n",
    "    print(f\"Total number of edges added: {edge_added_count}\") \n",
    "    print(f\"Total number of edges removed: {edge_removed_count}\")      \n",
    "    return attacked_adj, added_edges  # Return added edges for tracking\n",
    "\n",
    "# Main execution\n",
    "################################ Data loading #######################################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "dataset = \"polblogs\"\n",
    "data = Dataset(root='.', name=dataset, setting='gcn', seed=15)\n",
    "seed = 42\n",
    " \n",
    "set_seeds(seed)\n",
    "adj, features, labels = data.adj, data.features, data.labels\n",
    "idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "\n",
    "############  Train surrogate model and determine nodes to attack\n",
    "surrogate_model = train_surrogate_model(features, adj, labels, idx_train, idx_val)\n",
    "\n",
    "k = 10 # budget in the meaning of Number of nodes to attack\n",
    "nodes_to_attack = calc_nodes_to_attack(surrogate_model, features, adj, labels, idx_test)\n",
    "idx_test_attack = nodes_to_attack[:k]\n",
    "idx_test_clean = [node for node in idx_test if node not in idx_test_attack]\n",
    "print(\"Nodes chosen for attack:\", idx_test_attack)\n",
    "\n",
    "\n",
    "########### Train GCN model initially for evaluation before attack\n",
    "model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "            nhid=16, device=device, dropout=0.5)\n",
    "model = model.to(device)\n",
    "model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "model.eval()\n",
    "output = model.test(idx_test)\n",
    "\n",
    "accuracy_test_attack_1 = model.test(idx_test_attack) \n",
    "accuracy_test_clean_1 = model.test(idx_test_clean)\n",
    "print(\"Test accuracy on attack set: \", accuracy_test_attack_1)\n",
    "print(\"Test accuracy on clean set: \", accuracy_test_clean_1)\n",
    "\n",
    "############# perform attack Perturb edges\n",
    "budget = 5 # Number of edges to add or remove for each target node\n",
    "attacked_adj, added_edges = perturb_edges_between_targets(adj, surrogate_model, features, labels, idx_test_attack, budget)\n",
    "\n",
    "# Model evaluation after attack\n",
    "model.fit(features, attacked_adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "model.eval()\n",
    "\n",
    "accuracy_test_attack_2 = model.test(idx_test_attack)\n",
    "accuracy_test_clean_2 = model.test(idx_test_clean)\n",
    "print(\"Test accuracy on attack set after attack: \", accuracy_test_attack_2)\n",
    "print(\"Test accuracy on clean set after attack: \", accuracy_test_clean_2)\n",
    "\n",
    "##################   Crypto'Graph defense\n",
    "print(\"*************** Crypto'Graph defense ***************\")\n",
    "proportion_of_common_links = 0.5\n",
    "adj1, adj2 = split_dataset(attacked_adj, proportion_of_common_links) \n",
    "threshold = 2\n",
    "metric = \"neighbors\"\n",
    "object = \"links\"\n",
    "\n",
    "model = TwoPartyCNGCN(dataset=dataset, nfeat=features.shape[1], nhid=16, nclass=labels.max().item() + 1, device=device)\n",
    "defense_duration, defense_duration, training_duration1, training_duration2, CG_defended_adj1, CG_defended_adj2 = model.fit(\n",
    "        adj1.copy(), adj2.copy(), features, features, labels, idx_train, threshold, metric=metric, object=object,\n",
    "        train_iters=200, initialize=True, verbose=False, idx_val=idx_val)\n",
    "model.eval()\n",
    "\n",
    "accuracy_test_attack_3 = model.test(idx_test_attack)\n",
    "accuracy_test_clean_3 = model.test(idx_test_clean)\n",
    "print(\"Test accuracy on attack set after Crypto'Graph: \", accuracy_test_attack_3)\n",
    "print(\"Test accuracy on clean set after Crypto'Graph: \", accuracy_test_clean_3)\n",
    "\n",
    "# Function to find removed edges\n",
    "def find_removed_edges(original_adj, defended_adj1, defended_adj2):\n",
    "    removed_edges = []\n",
    "    original_adj = original_adj.toarray()\n",
    "    defended_adj1 = defended_adj1.toarray()\n",
    "    defended_adj2 = defended_adj2.toarray()\n",
    "    combined_defended_adj = np.maximum(defended_adj1, defended_adj2)\n",
    "    for i in range(original_adj.shape[0]):\n",
    "        for j in range(i + 1, original_adj.shape[1]):\n",
    "            if original_adj[i, j] == 1 and combined_defended_adj[i, j] == 0:\n",
    "                removed_edges.append((i, j))\n",
    "    return removed_edges\n",
    "\n",
    "# Find all removed edges\n",
    "removed_edges = find_removed_edges(attacked_adj, CG_defended_adj1, CG_defended_adj2)\n",
    "print(f\"Total number of removed edges by CG: {len(removed_edges)}\")\n",
    "\n",
    "# Check if any of the inserted edges during the attack were removed by CG\n",
    "removed_inserted_edges = [edge for edge in added_edges if edge in removed_edges]\n",
    "print(f\"Inserted edges removed by CG: {removed_inserted_edges}\")\n",
    "print(f\"Number of inserted edges removed by CG: {len(removed_inserted_edges)}\")\n",
    "\n",
    "################ Save and plot results\n",
    "accuracy_test_attack_1_std = np.std(accuracy_test_attack_1)\n",
    "accuracy_test_clean_1_std = np.std(accuracy_test_clean_1)\n",
    "accuracy_test_attack_2_std = np.std(accuracy_test_attack_2)\n",
    "accuracy_test_clean_2_std = np.std(accuracy_test_clean_2)\n",
    "accuracy_test_attack_3_std = np.std(accuracy_test_attack_3)\n",
    "accuracy_test_clean_3_std = np.std(accuracy_test_clean_3)\n",
    "\n",
    "with open('variables_std.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "                 accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "                 accuracy_test_attack_3_std, accuracy_test_clean_3_std], f)\n",
    "\n",
    "accuracy_test_attack_1_avg = np.mean(accuracy_test_attack_1)\n",
    "accuracy_test_clean_1_avg = np.mean(accuracy_test_clean_1)\n",
    "accuracy_test_attack_2_avg = np.mean(accuracy_test_attack_2)\n",
    "accuracy_test_clean_2_avg = np.mean(accuracy_test_clean_2)\n",
    "accuracy_test_attack_3_avg = np.mean(accuracy_test_attack_3)\n",
    "accuracy_test_clean_3_avg = np.mean(accuracy_test_clean_3)\n",
    "\n",
    "with open('variables.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "                 accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "                 accuracy_test_attack_3_avg, accuracy_test_clean_3_avg], f)\n",
    "\n",
    "labels = ['ACCs before attack', 'ACCs before attack', \n",
    "          'ACCs after attack', 'ACCs after attack', \n",
    "          'ACCs after CryptoGraph', 'ACCs after CryptoGraph']\n",
    "values = [accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "          accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "          accuracy_test_attack_3_avg, accuracy_test_clean_3_avg]\n",
    "std_devs = [accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "            accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "            accuracy_test_attack_3_std, accuracy_test_clean_3_std]\n",
    "x = np.arange(len(labels)//2)\n",
    "width = 0.35\n",
    "bars1 = plt.bar(x - width/2, values[::2], width, yerr=std_devs[::2], label='Attack set', color='red', capsize=5)\n",
    "bars2 = plt.bar(x + width/2, values[1::2], width, yerr=std_devs[1::2], label='Clean set', color='blue', capsize=5)\n",
    "plt.title('Average Accuracies')\n",
    "plt.xlabel('Levels of Attack and Defense')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.xticks(x, labels[::2])\n",
    "plt.legend()\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading polblogs dataset...\n",
      "Final number of nodes with zero loss: 737\n",
      "Final number of nodes with zero gradients: 690\n",
      "Final number of nodes with zero loss but non-zero gradients: 47\n",
      "Number of nodes with non-zero loss and non-zero gradients: 213\n",
      "Nodes chosen for attack: [716, 1182, 207, 379, 681, 820, 1288, 585, 333, 125]\n",
      "Test set results: loss= 0.3643 accuracy= 0.8547\n",
      "Test set results: loss= 0.6746 accuracy= 0.6000\n",
      "Test set results: loss= 0.3610 accuracy= 0.8574\n",
      "Test accuracy on attack set:  0.6\n",
      "Test accuracy on clean set:  0.8574468085106383\n",
      "Target node is: 716 with label: 0\n",
      "Added edge: (716, 854)\n",
      "Gradient: 0.00043980134068988264\n",
      "Number of common neighbors: 0\n",
      "Score: 0.00043980134068988264\n",
      "Removed edge: (716, 44)\n",
      "Gradient: -1.2366248483886011e-05\n",
      "Number of common neighbors: 0\n",
      "Score: 1.2366248483886011e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahsa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\scipy\\sparse\\_index.py:102: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added edge: (716, 1100)\n",
      "Gradient: 0.00024832223425619304\n",
      "Number of common neighbors: 1\n",
      "Score: 1.0002483222342562\n",
      "Added edge: (716, 879)\n",
      "Gradient: 0.00021674732852261513\n",
      "Number of common neighbors: 2\n",
      "Score: 2.0002167473285226\n",
      "Target node is: 1182 with label: 1\n",
      "Added edge: (1182, 322)\n",
      "Gradient: 0.0017908562440425158\n",
      "Number of common neighbors: 1\n",
      "Score: 1.0017908562440425\n",
      "Removed edge: (1182, 820)\n",
      "Gradient: -9.539907296129968e-06\n",
      "Number of common neighbors: 1\n",
      "Score: 1.0000095399072961\n",
      "Added edge: (1182, 511)\n",
      "Gradient: 0.00178462453186512\n",
      "Number of common neighbors: 2\n",
      "Score: 2.001784624531865\n",
      "Removed edge: (1182, 819)\n",
      "Gradient: -9.540784958517179e-06\n",
      "Number of common neighbors: 1\n",
      "Score: 1.0000095407849585\n",
      "Added edge: (1182, 12)\n",
      "Gradient: 0.0007567263673990965\n",
      "Number of common neighbors: 3\n",
      "Score: 3.000756726367399\n",
      "Target node is: 207 with label: 0\n",
      "Added edge: (207, 1477)\n",
      "Gradient: 0.012218998745083809\n",
      "Number of common neighbors: 1\n",
      "Score: 1.0122189987450838\n",
      "Removed edge: (207, 80)\n",
      "Gradient: -0.0017452691681683064\n",
      "Number of common neighbors: 1\n",
      "Score: 1.0017452691681683\n",
      "Added edge: (207, 879)\n",
      "Gradient: 0.05280204862356186\n",
      "Number of common neighbors: 1\n",
      "Score: 1.0528020486235619\n",
      "Added edge: (207, 1111)\n",
      "Gradient: 0.04813838005065918\n",
      "Number of common neighbors: 2\n",
      "Score: 2.048138380050659\n",
      "Target node is: 379 with label: 0\n",
      "Added edge: (379, 854)\n",
      "Gradient: 3.5294883251190186\n",
      "Number of common neighbors: 0\n",
      "Score: 3.5294883251190186\n",
      "Removed edge: (379, 621)\n",
      "Gradient: -0.030927827581763268\n",
      "Number of common neighbors: 0\n",
      "Score: 0.030927827581763268\n",
      "Added edge: (379, 1100)\n",
      "Gradient: 1.9928522109985352\n",
      "Number of common neighbors: 1\n",
      "Score: 2.992852210998535\n",
      "Added edge: (379, 879)\n",
      "Gradient: 1.7394015789031982\n",
      "Number of common neighbors: 2\n",
      "Score: 3.7394015789031982\n",
      "Target node is: 681 with label: 0\n",
      "Added edge: (681, 854)\n",
      "Gradient: 47.339935302734375\n",
      "Number of common neighbors: 0\n",
      "Score: 47.339935302734375\n",
      "Removed edge: (681, 75)\n",
      "Gradient: -0.1405458301305771\n",
      "Number of common neighbors: 0\n",
      "Score: 0.1405458301305771\n",
      "Added edge: (681, 1100)\n",
      "Gradient: 26.729511260986328\n",
      "Number of common neighbors: 1\n",
      "Score: 27.729511260986328\n",
      "Added edge: (681, 999)\n",
      "Gradient: 25.644760131835938\n",
      "Number of common neighbors: 1\n",
      "Score: 26.644760131835938\n",
      "Target node is: 820 with label: 1\n",
      "Added edge: (820, 154)\n",
      "Gradient: 163.40097045898438\n",
      "Number of common neighbors: 0\n",
      "Score: 163.40097045898438\n",
      "Removed edge: (820, 819)\n",
      "Gradient: -0.4950060546398163\n",
      "Number of common neighbors: 1\n",
      "Score: 1.4950060546398163\n",
      "Added edge: (820, 54)\n",
      "Gradient: 159.57485961914062\n",
      "Number of common neighbors: 1\n",
      "Score: 160.57485961914062\n",
      "Added edge: (820, 640)\n",
      "Gradient: 143.86569213867188\n",
      "Number of common neighbors: 2\n",
      "Score: 145.86569213867188\n",
      "Target node is: 1288 with label: 1\n",
      "Added edge: (1288, 154)\n",
      "Gradient: 101.69084930419922\n",
      "Number of common neighbors: 1\n",
      "Score: 102.69084930419922\n",
      "Added edge: (1288, 54)\n",
      "Gradient: 99.3096923828125\n",
      "Number of common neighbors: 2\n",
      "Score: 101.3096923828125\n",
      "Added edge: (1288, 640)\n",
      "Gradient: 89.53327941894531\n",
      "Number of common neighbors: 3\n",
      "Score: 92.53327941894531\n",
      "Target node is: 585 with label: 0\n",
      "Added edge: (585, 854)\n",
      "Gradient: 144.59231567382812\n",
      "Number of common neighbors: 0\n",
      "Score: 144.59231567382812\n",
      "Added edge: (585, 1100)\n",
      "Gradient: 81.64106750488281\n",
      "Number of common neighbors: 1\n",
      "Score: 82.64106750488281\n",
      "Added edge: (585, 999)\n",
      "Gradient: 78.32786560058594\n",
      "Number of common neighbors: 1\n",
      "Score: 79.32786560058594\n",
      "Target node is: 333 with label: 0\n",
      "Added edge: (333, 854)\n",
      "Gradient: 144.59234619140625\n",
      "Number of common neighbors: 0\n",
      "Score: 144.59234619140625\n",
      "Added edge: (333, 1100)\n",
      "Gradient: 81.6410903930664\n",
      "Number of common neighbors: 1\n",
      "Score: 82.6410903930664\n",
      "Added edge: (333, 999)\n",
      "Gradient: 78.32788848876953\n",
      "Number of common neighbors: 1\n",
      "Score: 79.32788848876953\n",
      "Target node is: 125 with label: 0\n",
      "Added edge: (125, 854)\n",
      "Gradient: 144.59230041503906\n",
      "Number of common neighbors: 0\n",
      "Score: 144.59230041503906\n",
      "Added edge: (125, 1100)\n",
      "Gradient: 81.64105224609375\n",
      "Number of common neighbors: 1\n",
      "Score: 82.64105224609375\n",
      "Added edge: (125, 999)\n",
      "Gradient: 78.32785034179688\n",
      "Number of common neighbors: 1\n",
      "Score: 79.32785034179688\n",
      "Total number of edges added: 30\n",
      "Total number of edges removed: 7\n",
      "k = number of nodes to attack: 10\n",
      "budget: 3\n",
      "Test set results: loss= 1.1397 accuracy= 0.0000\n",
      "Test set results: loss= 0.3827 accuracy= 0.8532\n",
      "Test accuracy on attack set after attack:  0.0\n",
      "Test accuracy on clean set after attack:  0.8531914893617021\n",
      "*************** Crypto'Graph defense ***************\n",
      "Dropping dissimilar edges using metric :  neighbors  on links\n",
      "removed 1669 edges in polblogs 1\n",
      "removed 1647 edges in polblogs 2\n",
      "*** polblogs 1 ***\n",
      "Test set results: loss= 0.8244 accuracy= 0.1000\n",
      "*** polblogs 2 ***\n",
      "Test set results: loss= 0.8138 accuracy= 0.1000\n",
      "*** polblogs 1 ***\n",
      "Test set results: loss= 0.4464 accuracy= 0.7383\n",
      "*** polblogs 2 ***\n",
      "Test set results: loss= 0.4484 accuracy= 0.7372\n",
      "Test accuracy on attack set after Crypto'Graph:  (0.1, 0.1)\n",
      "Test accuracy on clean set after Crypto'Graph:  (0.7382978723404255, 0.7372340425531915)\n",
      "Total number of removed edges by CG: 2227\n",
      "Inserted edges removed by CG: [(716, 854), (716, 1100), (716, 879), (207, 1477), (207, 879), (207, 1111), (379, 854), (379, 1100), (379, 879), (681, 854), (681, 1100), (681, 999), (585, 854), (585, 1100), (585, 999), (333, 854), (333, 1100), (333, 999), (125, 854), (125, 1100), (125, 999)]\n",
      "Number of inserted edges removed by CG: 21\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######## mahsa-V4.3: using surrogate model - using loss fonc and gradiant to edge-score for choosing nodes to attack ################\n",
    "# 10 nodes who have most loss and gradients --- 10 nodes who have less loss and gradients\n",
    "#  attack adding/removing edge: (NOT YET implemented le budget adaptatif pour ajouter/enlever) ###############\n",
    "# surrogat model for each edge to be added or removed via gradient and loss of edges and common neighbors\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from deeprobust.graph.defense import GCN\n",
    "from deeprobust.graph.utils import *\n",
    "from deeprobust.graph.data import Dataset\n",
    "from DistributedDefense import TwoPartyCNGCN\n",
    "from experiments import split_dataset\n",
    "from scipy.sparse import csr_matrix\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Train surrogate model\n",
    "def train_surrogate_model(features, adj, labels, idx_train, idx_val):\n",
    "    surrogate_model = GCN(nfeat=features.shape[1], nclass=labels.max().item() + 1, nhid=16, device=device, dropout=0.5)\n",
    "    surrogate_model = surrogate_model.to(device)\n",
    "    surrogate_model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    return surrogate_model\n",
    "\n",
    "# Compute gradients of loss w.r.t adjacency matrix\n",
    "def compute_gradients(surrogate_model, features, adj, labels, target_node):\n",
    "    surrogate_model.eval()\n",
    "    adj = torch.FloatTensor(adj.toarray()).to(device)\n",
    "    adj.requires_grad = True\n",
    "    features = torch.FloatTensor(features.toarray()).to(device)\n",
    "    labels = torch.LongTensor(labels).to(device)\n",
    "    output = surrogate_model(features, adj)\n",
    "    loss = F.nll_loss(output[[target_node]], labels[[target_node]])\n",
    "    loss.backward()\n",
    "    gradients = adj.grad.cpu().numpy()\n",
    "    return loss.item(), gradients\n",
    "\n",
    "# choose nodes to attack based on loss and gradients not common neighbors\n",
    "def calc_nodes_to_attack(surrogate_model, features, adj, labels, idx_test):\n",
    "    zero_loss_count = 0\n",
    "    zero_gradients_count = 0\n",
    "    non_zero_loss_and_gradients_nodes = []\n",
    "    zero_loss_non_ziro_gr = 0\n",
    "\n",
    "    for target_node in idx_test:\n",
    "        loss, gradients = compute_gradients(surrogate_model, features, adj, labels, target_node)\n",
    "        if loss == 0:\n",
    "            zero_loss_count += 1\n",
    "        if not np.any(gradients):\n",
    "            zero_gradients_count += 1\n",
    "        \n",
    "        zero_loss = loss == 0\n",
    "        zero_gradients = not np.any(gradients)\n",
    "    # If both loss and gradients are non-zero, store the node\n",
    "        if not zero_loss and not zero_gradients:\n",
    "            impact_score = loss * np.sum(np.abs(gradients))\n",
    "            non_zero_loss_and_gradients_nodes.append((target_node, impact_score))\n",
    "        # Ensure consistency between zero loss and zero gradients\n",
    "        if zero_loss and not zero_gradients:\n",
    "            # print(f\"Warning: Target node {target_node} has zero loss but non-zero gradients!\")\n",
    "            zero_loss_non_ziro_gr += 1\n",
    "    \n",
    "    print(f\"Final number of nodes with zero loss: {zero_loss_count}\")\n",
    "    print(f\"Final number of nodes with zero gradients: {zero_gradients_count}\")\n",
    "    print(f\"Final number of nodes with zero loss but non-zero gradients: {zero_loss_non_ziro_gr}\")\n",
    "    # print(\"Nodes with non-zero loss and non-zero gradients:\")\n",
    "    # for node in non_zero_loss_and_gradients_nodes:\n",
    "    #     print(node)\n",
    "    print(f\"Number of nodes with non-zero loss and non-zero gradients: {len(non_zero_loss_and_gradients_nodes)}\")\n",
    "    # Sort nodes by impact score in descending order\n",
    "    # non_zero_loss_and_gradients_nodes.sort(key=lambda x: x[1], reverse=True)\n",
    "    # nodes_to_attack = [node for node, score in non_zero_loss_and_gradients_nodes]\n",
    "\n",
    "    # sort nodes by less loss and gradients\n",
    "    sorted_nodes = sorted(non_zero_loss_and_gradients_nodes, key=lambda x: x[1])\n",
    "    nodes_to_attack = [node for node, score in sorted_nodes[:k]]\n",
    "\n",
    "    return nodes_to_attack\n",
    "\n",
    "\n",
    "####### new strategy of adding alpha beta to the impact score to consider the common neighbors while selecting nodes to attack\n",
    "####### not have good results all 0.1 accuracies.\n",
    "# def calc_nodes_to_attack(surrogate_model, features, adj, labels, idx_test, alpha=1.0, beta=1.0):\n",
    "#     zero_loss_count = 0\n",
    "#     zero_gradients_count = 0\n",
    "#     non_zero_loss_and_gradients_nodes = []\n",
    "#     zero_loss_non_ziro_gr = 0\n",
    "\n",
    "#     for target_node in idx_test:\n",
    "#         loss, gradients = compute_gradients(surrogate_model, features, adj, labels, target_node)\n",
    "#         if loss == 0:\n",
    "#             zero_loss_count += 1\n",
    "#         if not np.any(gradients):\n",
    "#             zero_gradients_count += 1\n",
    "        \n",
    "#         zero_loss = loss == 0\n",
    "#         zero_gradients = not np.any(gradients)\n",
    "#         if not zero_loss and not zero_gradients:\n",
    "#             impact_score = loss * np.sum(np.abs(gradients))\n",
    "#             common_neighbors = sum(calculate_common_neighbors(adj, target_node, i) for i in range(adj.shape[0]) if i != target_node)\n",
    "#             final_score = alpha * impact_score + beta * common_neighbors\n",
    "#             non_zero_loss_and_gradients_nodes.append((target_node, final_score))\n",
    "        \n",
    "#         if zero_loss and not zero_gradients:\n",
    "#             zero_loss_non_ziro_gr += 1\n",
    "    \n",
    "#     print(f\"Final number of nodes with zero loss: {zero_loss_count}\")\n",
    "#     print(f\"Final number of nodes with zero gradients: {zero_gradients_count}\")\n",
    "#     print(f\"Final number of nodes with zero loss but non-zero gradients: {zero_loss_non_ziro_gr}\")\n",
    "#     print(f\"Number of nodes with non-zero loss and non-zero gradients: {len(non_zero_loss_and_gradients_nodes)}\")\n",
    "\n",
    "#     # Sort nodes by the final score in descending order\n",
    "#     non_zero_loss_and_gradients_nodes.sort(key=lambda x: x[1], reverse=True)\n",
    "#     nodes_to_attack = [node for node, score in non_zero_loss_and_gradients_nodes]\n",
    "#     return nodes_to_attack\n",
    "\n",
    "\n",
    "\n",
    "# Calculate common neighbors between two nodes\n",
    "def calculate_common_neighbors(adj, node1, node2):\n",
    "    neighbors1 = set(adj[node1].indices)\n",
    "    neighbors2 = set(adj[node2].indices)\n",
    "    common_neighbors = neighbors1 & neighbors2\n",
    "    return len(common_neighbors)\n",
    "\n",
    "# Calculate edge scores based on gradients and common neighbors\n",
    "def calculate_edge_scores(adj, gradients, target_node, labels, add=True):\n",
    "    scores = {}\n",
    "    for i in range(adj.shape[0]):\n",
    "        if add and adj[target_node, i] == 0   and labels[target_node] != labels[i]:\n",
    "            common_neighbors = calculate_common_neighbors(adj, target_node, i)\n",
    "            scores[(target_node, i)] = gradients[target_node, i]  + common_neighbors   # 10 is a hyperparameter, can be tuned\n",
    "        elif not add and adj[target_node, i] == 1  and labels[target_node] == labels[i]:\n",
    "            common_neighbors = calculate_common_neighbors(adj, target_node, i)\n",
    "            scores[(target_node, i)] = -gradients[target_node, i]  + common_neighbors  # 10 is a hyperparameter\n",
    "    return scores\n",
    "\n",
    "# Select best edge based on edge scores\n",
    "def select_best_edge(adj, gradients, target_node, labels, add=True):\n",
    "    scores = calculate_edge_scores(adj, gradients, target_node, labels, add) ########################################just add?\n",
    "    if not scores:\n",
    "        return None\n",
    "    if add:\n",
    "        best_edge = max(scores, key=scores.get)\n",
    "    else:\n",
    "        best_edge = min(scores, key=scores.get)\n",
    "    return best_edge\n",
    "\n",
    "# Perturb edges between target nodes\n",
    "def perturb_edges_between_targets(adj, surrogate_model, features, labels, idx_test_attack, budget):\n",
    "    attacked_adj = adj.copy()\n",
    "    added_edges = []  # Track added edges\n",
    "    edge_added_count = 0\n",
    "    edge_removed_count = 0\n",
    "    for target_node in idx_test_attack:\n",
    "        print(f\"Target node is: {target_node} with label: {labels[target_node]}\")\n",
    "        loss, gradients = compute_gradients(surrogate_model, features, attacked_adj, labels, target_node)\n",
    "        if not np.any(gradients):\n",
    "            continue\n",
    "        for _ in range(budget):\n",
    "            edge_add = select_best_edge(attacked_adj, gradients, target_node, labels, add=True)\n",
    "            edge_remove = select_best_edge(attacked_adj, gradients, target_node, labels, add=False)\n",
    "            # print(f\"edge_add: {edge_add}, edge_remove: {edge_remove}\")\n",
    "            if edge_add:\n",
    "                common_neighbors_add = calculate_common_neighbors(attacked_adj, edge_add[0], edge_add[1])\n",
    "                score_add = gradients[edge_add[0], edge_add[1]] + common_neighbors_add  #* 200\n",
    "                attacked_adj[edge_add[0], edge_add[1]] = 1\n",
    "                attacked_adj[edge_add[1], edge_add[0]] = 1\n",
    "                added_edges.append(edge_add)  # Track added edge\n",
    "                edge_added_count += 1\n",
    "                print(f\"Added edge: {edge_add}\")\n",
    "                print(f\"Gradient: {gradients[edge_add[0], edge_add[1]]}\")\n",
    "                print(f\"Number of common neighbors: {common_neighbors_add}\")\n",
    "                print(f\"Score: {score_add}\")\n",
    "\n",
    "            if edge_remove:\n",
    "                common_neighbors_remove = calculate_common_neighbors(attacked_adj, edge_remove[0], edge_remove[1])\n",
    "                score_remove = -gradients[edge_remove[0], edge_remove[1]] + common_neighbors_remove #* 200\n",
    "                attacked_adj[edge_remove[0], edge_remove[1]] = 0\n",
    "                attacked_adj[edge_remove[1], edge_remove[0]] = 0\n",
    "                edge_removed_count += 1\n",
    "                print(f\"Removed edge: {edge_remove}\")\n",
    "                print(f\"Gradient: {gradients[edge_remove[0], edge_remove[1]]}\")\n",
    "                print(f\"Number of common neighbors: {common_neighbors_remove}\")\n",
    "                print(f\"Score: {score_remove}\")\n",
    "\n",
    "    print(f\"Total number of edges added: {edge_added_count}\") \n",
    "    print(f\"Total number of edges removed: {edge_removed_count}\")      \n",
    "    return attacked_adj, added_edges  # Return added edges for tracking\n",
    "\n",
    "# Main execution\n",
    "################################ Data loading #######################################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "dataset = \"polblogs\"\n",
    "data = Dataset(root='.', name=dataset, setting='gcn', seed=15)\n",
    "seed = 42\n",
    " \n",
    "set_seeds(seed)\n",
    "adj, features, labels = data.adj, data.features, data.labels\n",
    "idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "\n",
    "############  Train surrogate model and determine nodes to attack\n",
    "surrogate_model = train_surrogate_model(features, adj, labels, idx_train, idx_val)\n",
    "\n",
    "k = 10 # budget in the meaning of Number of nodes to attack\n",
    "nodes_to_attack = calc_nodes_to_attack(surrogate_model, features, adj, labels, idx_test)\n",
    "idx_test_attack = nodes_to_attack[:k]\n",
    "idx_test_clean = [node for node in idx_test if node not in idx_test_attack]\n",
    "print(\"Nodes chosen for attack:\", idx_test_attack)\n",
    "\n",
    "\n",
    "########### Train GCN model initially for evaluation before attack\n",
    "model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "            nhid=16, device=device, dropout=0.5)\n",
    "model = model.to(device)\n",
    "model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "model.eval()\n",
    "output = model.test(idx_test)\n",
    "\n",
    "accuracy_test_attack_1 = model.test(idx_test_attack) \n",
    "accuracy_test_clean_1 = model.test(idx_test_clean)\n",
    "print(\"Test accuracy on attack set: \", accuracy_test_attack_1)\n",
    "print(\"Test accuracy on clean set: \", accuracy_test_clean_1)\n",
    "\n",
    "############# perform attack Perturb edges\n",
    "budget = 3 # Number of edges to add or remove for each target node\n",
    "attacked_adj, added_edges = perturb_edges_between_targets(adj, surrogate_model, features, labels, idx_test_attack, budget)\n",
    "print(f\"k = number of nodes to attack: {len(idx_test_attack)}\")\n",
    "print(f\"budget: {budget}\")\n",
    "\n",
    "# Model evaluation after attack\n",
    "model.fit(features, attacked_adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "model.eval()\n",
    "\n",
    "accuracy_test_attack_2 = model.test(idx_test_attack)\n",
    "accuracy_test_clean_2 = model.test(idx_test_clean)\n",
    "print(\"Test accuracy on attack set after attack: \", accuracy_test_attack_2)\n",
    "print(\"Test accuracy on clean set after attack: \", accuracy_test_clean_2)\n",
    "\n",
    "##################   Crypto'Graph defense\n",
    "print(\"*************** Crypto'Graph defense ***************\")\n",
    "proportion_of_common_links = 0.5\n",
    "adj1, adj2 = split_dataset(attacked_adj, proportion_of_common_links) \n",
    "threshold = 2\n",
    "metric = \"neighbors\"\n",
    "object = \"links\"\n",
    "\n",
    "model = TwoPartyCNGCN(dataset=dataset, nfeat=features.shape[1], nhid=16, nclass=labels.max().item() + 1, device=device)\n",
    "defense_duration, defense_duration, training_duration1, training_duration2, CG_defended_adj1, CG_defended_adj2 = model.fit(\n",
    "        adj1.copy(), adj2.copy(), features, features, labels, idx_train, threshold, metric=metric, object=object,\n",
    "        train_iters=200, initialize=True, verbose=False, idx_val=idx_val)\n",
    "model.eval()\n",
    "\n",
    "accuracy_test_attack_3 = model.test(idx_test_attack)\n",
    "accuracy_test_clean_3 = model.test(idx_test_clean)\n",
    "print(\"Test accuracy on attack set after Crypto'Graph: \", accuracy_test_attack_3)\n",
    "print(\"Test accuracy on clean set after Crypto'Graph: \", accuracy_test_clean_3)\n",
    "\n",
    "# Function to find removed edges\n",
    "def find_removed_edges(original_adj, defended_adj1, defended_adj2):\n",
    "    removed_edges = []\n",
    "    original_adj = original_adj.toarray()\n",
    "    defended_adj1 = defended_adj1.toarray()\n",
    "    defended_adj2 = defended_adj2.toarray()\n",
    "    combined_defended_adj = np.maximum(defended_adj1, defended_adj2)\n",
    "    for i in range(original_adj.shape[0]):\n",
    "        for j in range(i + 1, original_adj.shape[1]):\n",
    "            if original_adj[i, j] == 1 and combined_defended_adj[i, j] == 0:\n",
    "                removed_edges.append((i, j))\n",
    "    return removed_edges\n",
    "\n",
    "# Find all removed edges\n",
    "removed_edges = find_removed_edges(attacked_adj, CG_defended_adj1, CG_defended_adj2)\n",
    "print(f\"Total number of removed edges by CG: {len(removed_edges)}\")\n",
    "\n",
    "# Check if any of the inserted edges during the attack were removed by CG\n",
    "removed_inserted_edges = [edge for edge in added_edges if edge in removed_edges]\n",
    "print(f\"Inserted edges removed by CG: {removed_inserted_edges}\")\n",
    "print(f\"Number of inserted edges removed by CG: {len(removed_inserted_edges)}\")\n",
    "\n",
    "################ Save and plot results\n",
    "accuracy_test_attack_1_std = np.std(accuracy_test_attack_1)\n",
    "accuracy_test_clean_1_std = np.std(accuracy_test_clean_1)\n",
    "accuracy_test_attack_2_std = np.std(accuracy_test_attack_2)\n",
    "accuracy_test_clean_2_std = np.std(accuracy_test_clean_2)\n",
    "accuracy_test_attack_3_std = np.std(accuracy_test_attack_3)\n",
    "accuracy_test_clean_3_std = np.std(accuracy_test_clean_3)\n",
    "\n",
    "with open('variables_std.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "                 accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "                 accuracy_test_attack_3_std, accuracy_test_clean_3_std], f)\n",
    "\n",
    "accuracy_test_attack_1_avg = np.mean(accuracy_test_attack_1)\n",
    "accuracy_test_clean_1_avg = np.mean(accuracy_test_clean_1)\n",
    "accuracy_test_attack_2_avg = np.mean(accuracy_test_attack_2)\n",
    "accuracy_test_clean_2_avg = np.mean(accuracy_test_clean_2)\n",
    "accuracy_test_attack_3_avg = np.mean(accuracy_test_attack_3)\n",
    "accuracy_test_clean_3_avg = np.mean(accuracy_test_clean_3)\n",
    "\n",
    "with open('variables.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "                 accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "                 accuracy_test_attack_3_avg, accuracy_test_clean_3_avg], f)\n",
    "\n",
    "labels = ['ACCs before attack', 'ACCs before attack', \n",
    "          'ACCs after attack', 'ACCs after attack', \n",
    "          'ACCs after CryptoGraph', 'ACCs after CryptoGraph']\n",
    "values = [accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "          accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "          accuracy_test_attack_3_avg, accuracy_test_clean_3_avg]\n",
    "std_devs = [accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "            accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "            accuracy_test_attack_3_std, accuracy_test_clean_3_std]\n",
    "x = np.arange(len(labels)//2)\n",
    "width = 0.35\n",
    "bars1 = plt.bar(x - width/2, values[::2], width, yerr=std_devs[::2], label='Attack set', color='red', capsize=5)\n",
    "bars2 = plt.bar(x + width/2, values[1::2], width, yerr=std_devs[1::2], label='Clean set', color='blue', capsize=5)\n",
    "plt.title('Average Accuracies')\n",
    "plt.xlabel('Levels of Attack and Defense')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.xticks(x, labels[::2])\n",
    "plt.legend()\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## mahsa-V4.3.1 :alpha beta- impact of common neighbors\n",
    "#  using surrogate model - using loss fonc and gradiant to edge-score for choosing nodes to attack ################\n",
    "# 10 nodes who have most loss and gradients --- 10 nodes who have less loss and gradients\n",
    "#  attack adding/removing edge: (NOT YET implemented le budget adaptatif pour ajouter/enlever) ###############\n",
    "# surrogat model for each edge to be added or removed via gradient and loss of edges and common neighbors\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from deeprobust.graph.defense import GCN\n",
    "from deeprobust.graph.utils import *\n",
    "from deeprobust.graph.data import Dataset\n",
    "from DistributedDefense import TwoPartyCNGCN\n",
    "from experiments import split_dataset\n",
    "from scipy.sparse import csr_matrix\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Train surrogate model\n",
    "def train_surrogate_model(features, adj, labels, idx_train, idx_val):\n",
    "    surrogate_model = GCN(nfeat=features.shape[1], nclass=labels.max().item() + 1, nhid=16, device=device, dropout=0.5)\n",
    "    surrogate_model = surrogate_model.to(device)\n",
    "    surrogate_model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    return surrogate_model\n",
    "\n",
    "# Compute gradients of loss w.r.t adjacency matrix\n",
    "def compute_gradients(surrogate_model, features, adj, labels, target_node):\n",
    "    surrogate_model.eval()\n",
    "    adj = torch.FloatTensor(adj.toarray()).to(device)\n",
    "    adj.requires_grad = True\n",
    "    features = torch.FloatTensor(features.toarray()).to(device)\n",
    "    labels = torch.LongTensor(labels).to(device)\n",
    "    output = surrogate_model(features, adj)\n",
    "    loss = F.nll_loss(output[[target_node]], labels[[target_node]])\n",
    "    loss.backward()\n",
    "    gradients = adj.grad.cpu().numpy()\n",
    "    return loss.item(), gradients\n",
    "\n",
    "# choose nodes to attack based on loss and gradients not common neighbors\n",
    "def calc_nodes_to_attack(surrogate_model, features, adj, labels, idx_test):\n",
    "    zero_loss_count = 0\n",
    "    zero_gradients_count = 0\n",
    "    non_zero_loss_and_gradients_nodes = []\n",
    "    zero_loss_non_ziro_gr = 0\n",
    "\n",
    "    for target_node in idx_test:\n",
    "        loss, gradients = compute_gradients(surrogate_model, features, adj, labels, target_node)\n",
    "        if loss == 0:\n",
    "            zero_loss_count += 1\n",
    "        if not np.any(gradients):\n",
    "            zero_gradients_count += 1\n",
    "        \n",
    "        zero_loss = loss == 0\n",
    "        zero_gradients = not np.any(gradients)\n",
    "    # If both loss and gradients are non-zero, store the node\n",
    "        if not zero_loss and not zero_gradients:\n",
    "            impact_score = loss * np.sum(np.abs(gradients))\n",
    "            non_zero_loss_and_gradients_nodes.append((target_node, impact_score))\n",
    "        # Ensure consistency between zero loss and zero gradients\n",
    "        if zero_loss and not zero_gradients:\n",
    "            # print(f\"Warning: Target node {target_node} has zero loss but non-zero gradients!\")\n",
    "            zero_loss_non_ziro_gr += 1\n",
    "    \n",
    "    print(f\"Final number of nodes with zero loss: {zero_loss_count}\")\n",
    "    print(f\"Final number of nodes with zero gradients: {zero_gradients_count}\")\n",
    "    print(f\"Final number of nodes with zero loss but non-zero gradients: {zero_loss_non_ziro_gr}\")\n",
    "    # print(\"Nodes with non-zero loss and non-zero gradients:\")\n",
    "    # for node in non_zero_loss_and_gradients_nodes:\n",
    "    #     print(node)\n",
    "    print(f\"Number of nodes with non-zero loss and non-zero gradients: {len(non_zero_loss_and_gradients_nodes)}\")\n",
    "    # Sort nodes by impact score in descending order\n",
    "    # non_zero_loss_and_gradients_nodes.sort(key=lambda x: x[1], reverse=True)\n",
    "    # nodes_to_attack = [node for node, score in non_zero_loss_and_gradients_nodes]\n",
    "\n",
    "    # sort nodes by less loss and gradients\n",
    "    sorted_nodes = sorted(non_zero_loss_and_gradients_nodes, key=lambda x: x[1])\n",
    "    nodes_to_attack = [node for node, score in sorted_nodes[:k]]\n",
    "\n",
    "    return nodes_to_attack\n",
    "\n",
    "\n",
    "####### new strategy of adding alpha beta to the impact score to consider the common neighbors while selecting nodes to attack\n",
    "####### not have good results all 0.1 accuracies.\n",
    "# def calc_nodes_to_attack(surrogate_model, features, adj, labels, idx_test, alpha=1.0, beta=1.0):\n",
    "#     zero_loss_count = 0\n",
    "#     zero_gradients_count = 0\n",
    "#     non_zero_loss_and_gradients_nodes = []\n",
    "#     zero_loss_non_ziro_gr = 0\n",
    "\n",
    "#     for target_node in idx_test:\n",
    "#         loss, gradients = compute_gradients(surrogate_model, features, adj, labels, target_node)\n",
    "#         if loss == 0:\n",
    "#             zero_loss_count += 1\n",
    "#         if not np.any(gradients):\n",
    "#             zero_gradients_count += 1\n",
    "        \n",
    "#         zero_loss = loss == 0\n",
    "#         zero_gradients = not np.any(gradients)\n",
    "#         if not zero_loss and not zero_gradients:\n",
    "#             impact_score = loss * np.sum(np.abs(gradients))\n",
    "#             common_neighbors = sum(calculate_common_neighbors(adj, target_node, i) for i in range(adj.shape[0]) if i != target_node)\n",
    "#             final_score = alpha * impact_score + beta * common_neighbors\n",
    "#             non_zero_loss_and_gradients_nodes.append((target_node, final_score))\n",
    "        \n",
    "#         if zero_loss and not zero_gradients:\n",
    "#             zero_loss_non_ziro_gr += 1\n",
    "    \n",
    "#     print(f\"Final number of nodes with zero loss: {zero_loss_count}\")\n",
    "#     print(f\"Final number of nodes with zero gradients: {zero_gradients_count}\")\n",
    "#     print(f\"Final number of nodes with zero loss but non-zero gradients: {zero_loss_non_ziro_gr}\")\n",
    "#     print(f\"Number of nodes with non-zero loss and non-zero gradients: {len(non_zero_loss_and_gradients_nodes)}\")\n",
    "\n",
    "#     # Sort nodes by the final score in descending order\n",
    "#     non_zero_loss_and_gradients_nodes.sort(key=lambda x: x[1], reverse=True)\n",
    "#     nodes_to_attack = [node for node, score in non_zero_loss_and_gradients_nodes]\n",
    "#     return nodes_to_attack\n",
    "\n",
    "\n",
    "\n",
    "# Calculate common neighbors between two nodes\n",
    "def calculate_common_neighbors(adj, node1, node2):\n",
    "    neighbors1 = set(adj[node1].indices)\n",
    "    neighbors2 = set(adj[node2].indices)\n",
    "    common_neighbors = neighbors1 & neighbors2\n",
    "    return len(common_neighbors)\n",
    "\n",
    "# Calculate edge scores based on gradients and common neighbors\n",
    "def calculate_edge_scores(adj, gradients, target_node, labels, add=True, alpha, beta):\n",
    "    scores = {}\n",
    "    for i in range(adj.shape[0]):\n",
    "        if add and adj[target_node, i] == 0   and labels[target_node] != labels[i]:\n",
    "            common_neighbors = calculate_common_neighbors(adj, target_node, i)\n",
    "            scores[(target_node, i)] = gradients[target_node, i] * alpha + common_neighbors * beta  # 10 is a hyperparameter, can be tuned\n",
    "        elif not add and adj[target_node, i] == 1  and labels[target_node] == labels[i]:\n",
    "            common_neighbors = calculate_common_neighbors(adj, target_node, i)\n",
    "            scores[(target_node, i)] = -gradients[target_node, i] * alpha + common_neighbors * beta # 10 is a hyperparameter\n",
    "    return scores\n",
    "\n",
    "# Select best edge based on edge scores\n",
    "def select_best_edge(adj, gradients, target_node, labels, add=True):\n",
    "    scores = calculate_edge_scores(adj, gradients, target_node, labels, add, alpha= alpha, beta= beta) ########################################just add?\n",
    "    if not scores:\n",
    "        return None\n",
    "    if add:\n",
    "        best_edge = max(scores, key=scores.get)\n",
    "    else:\n",
    "        best_edge = min(scores, key=scores.get)\n",
    "    return best_edge\n",
    "\n",
    "# Perturb edges between target nodes\n",
    "def perturb_edges_between_targets(adj, surrogate_model, features, labels, idx_test_attack, budget, alpha, beta):\n",
    "    attacked_adj = adj.copy()\n",
    "    added_edges = []  # Track added edges\n",
    "    edge_added_count = 0\n",
    "    edge_removed_count = 0\n",
    "    for target_node in idx_test_attack:\n",
    "        print(f\"Target node is: {target_node} with label: {labels[target_node]}\")\n",
    "        loss, gradients = compute_gradients(surrogate_model, features, attacked_adj, labels, target_node)\n",
    "        if not np.any(gradients):\n",
    "            continue\n",
    "        for _ in range(budget):\n",
    "            edge_add = select_best_edge(attacked_adj, gradients, target_node, labels, add=True, alpha=alpha, beta=beta)\n",
    "            edge_remove = select_best_edge(attacked_adj, gradients, target_node, labels, add=False, alpha=alpha, beta=beta)\n",
    "            # print(f\"edge_add: {edge_add}, edge_remove: {edge_remove}\")\n",
    "            if edge_add:\n",
    "                common_neighbors_add = calculate_common_neighbors(attacked_adj, edge_add[0], edge_add[1])\n",
    "                score_add = gradients[edge_add[0], edge_add[1]] * alpha + common_neighbors_add * beta  \n",
    "                attacked_adj[edge_add[0], edge_add[1]] = 1\n",
    "                attacked_adj[edge_add[1], edge_add[0]] = 1\n",
    "                added_edges.append(edge_add)  # Track added edge\n",
    "                edge_added_count += 1\n",
    "                print(f\"Added edge: {edge_add}\")\n",
    "                print(f\"Gradient: {gradients[edge_add[0], edge_add[1]]}\")\n",
    "                print(f\"Number of common neighbors: {common_neighbors_add}\")\n",
    "                print(f\"Score: {score_add}\")\n",
    "\n",
    "            if edge_remove:\n",
    "                common_neighbors_remove = calculate_common_neighbors(attacked_adj, edge_remove[0], edge_remove[1])\n",
    "                score_remove = -gradients[edge_remove[0], edge_remove[1]] *alpha + common_neighbors_remove * beta\n",
    "                attacked_adj[edge_remove[0], edge_remove[1]] = 0\n",
    "                attacked_adj[edge_remove[1], edge_remove[0]] = 0\n",
    "                edge_removed_count += 1\n",
    "                print(f\"Removed edge: {edge_remove}\")\n",
    "                print(f\"Gradient: {gradients[edge_remove[0], edge_remove[1]]}\")\n",
    "                print(f\"Number of common neighbors: {common_neighbors_remove}\")\n",
    "                print(f\"Score: {score_remove}\")\n",
    "\n",
    "    print(f\"Total number of edges added: {edge_added_count}\") \n",
    "    print(f\"Total number of edges removed: {edge_removed_count}\")      \n",
    "    return attacked_adj, added_edges  # Return added edges for tracking\n",
    "\n",
    "# Main execution\n",
    "################################ Data loading #######################################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "dataset = \"polblogs\"\n",
    "data = Dataset(root='.', name=dataset, setting='gcn', seed=15)\n",
    "seed = 42\n",
    " \n",
    "set_seeds(seed)\n",
    "adj, features, labels = data.adj, data.features, data.labels\n",
    "idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "\n",
    "############  Train surrogate model and determine nodes to attack\n",
    "surrogate_model = train_surrogate_model(features, adj, labels, idx_train, idx_val)\n",
    "\n",
    "k = 10 # budget in the meaning of Number of nodes to attack\n",
    "nodes_to_attack = calc_nodes_to_attack(surrogate_model, features, adj, labels, idx_test)\n",
    "idx_test_attack = nodes_to_attack[:k]\n",
    "idx_test_clean = [node for node in idx_test if node not in idx_test_attack]\n",
    "print(\"Nodes chosen for attack:\", idx_test_attack)\n",
    "\n",
    "\n",
    "########### Train GCN model initially for evaluation before attack\n",
    "model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "            nhid=16, device=device, dropout=0.5)\n",
    "model = model.to(device)\n",
    "model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "model.eval()\n",
    "output = model.test(idx_test)\n",
    "\n",
    "accuracy_test_attack_1 = model.test(idx_test_attack) \n",
    "accuracy_test_clean_1 = model.test(idx_test_clean)\n",
    "print(\"Test accuracy on attack set: \", accuracy_test_attack_1)\n",
    "print(\"Test accuracy on clean set: \", accuracy_test_clean_1)\n",
    "\n",
    "############# perform attack Perturb edges\n",
    "budget = 3 # Number of edges to add or remove for each target node\n",
    "alpha = 1.0\n",
    "beta = 1.0\n",
    "print(f\"k = number of nodes to attack: {len(idx_test_attack)}\")\n",
    "print(f\"budget: {budget}\", f\"alpha(gradient's importance): {alpha}\", F\"beta( commun neighbor's importance): {beta}\")\n",
    "\n",
    "attacked_adj, added_edges = perturb_edges_between_targets(adj, surrogate_model, features, labels, idx_test_attack, budget, alpha, beta)\n",
    "\n",
    "# Model evaluation after attack\n",
    "model.fit(features, attacked_adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "model.eval()\n",
    "\n",
    "accuracy_test_attack_2 = model.test(idx_test_attack)\n",
    "accuracy_test_clean_2 = model.test(idx_test_clean)\n",
    "print(\"Test accuracy on attack set after attack: \", accuracy_test_attack_2)\n",
    "print(\"Test accuracy on clean set after attack: \", accuracy_test_clean_2)\n",
    "\n",
    "##################   Crypto'Graph defense\n",
    "print(\"*************** Crypto'Graph defense ***************\")\n",
    "proportion_of_common_links = 0.5\n",
    "adj1, adj2 = split_dataset(attacked_adj, proportion_of_common_links) \n",
    "threshold = 2\n",
    "metric = \"neighbors\"\n",
    "object = \"links\"\n",
    "\n",
    "model = TwoPartyCNGCN(dataset=dataset, nfeat=features.shape[1], nhid=16, nclass=labels.max().item() + 1, device=device)\n",
    "defense_duration, defense_duration, training_duration1, training_duration2, CG_defended_adj1, CG_defended_adj2 = model.fit(\n",
    "        adj1.copy(), adj2.copy(), features, features, labels, idx_train, threshold, metric=metric, object=object,\n",
    "        train_iters=200, initialize=True, verbose=False, idx_val=idx_val)\n",
    "model.eval()\n",
    "\n",
    "accuracy_test_attack_3 = model.test(idx_test_attack)\n",
    "accuracy_test_clean_3 = model.test(idx_test_clean)\n",
    "print(\"Test accuracy on attack set after Crypto'Graph: \", accuracy_test_attack_3)\n",
    "print(\"Test accuracy on clean set after Crypto'Graph: \", accuracy_test_clean_3)\n",
    "\n",
    "# Function to find removed edges\n",
    "def find_removed_edges(original_adj, defended_adj1, defended_adj2):\n",
    "    removed_edges = []\n",
    "    original_adj = original_adj.toarray()\n",
    "    defended_adj1 = defended_adj1.toarray()\n",
    "    defended_adj2 = defended_adj2.toarray()\n",
    "    combined_defended_adj = np.maximum(defended_adj1, defended_adj2)\n",
    "    for i in range(original_adj.shape[0]):\n",
    "        for j in range(i + 1, original_adj.shape[1]):\n",
    "            if original_adj[i, j] == 1 and combined_defended_adj[i, j] == 0:\n",
    "                removed_edges.append((i, j))\n",
    "    return removed_edges\n",
    "\n",
    "# Find all removed edges\n",
    "removed_edges = find_removed_edges(attacked_adj, CG_defended_adj1, CG_defended_adj2)\n",
    "print(f\"Total number of removed edges by CG: {len(removed_edges)}\")\n",
    "\n",
    "# Check if any of the inserted edges during the attack were removed by CG\n",
    "removed_inserted_edges = [edge for edge in added_edges if edge in removed_edges]\n",
    "print(f\"Inserted edges removed by CG: {removed_inserted_edges}\")\n",
    "print(f\"Number of inserted edges removed by CG: {len(removed_inserted_edges)}\")\n",
    "\n",
    "################ Save and plot results\n",
    "accuracy_test_attack_1_std = np.std(accuracy_test_attack_1)\n",
    "accuracy_test_clean_1_std = np.std(accuracy_test_clean_1)\n",
    "accuracy_test_attack_2_std = np.std(accuracy_test_attack_2)\n",
    "accuracy_test_clean_2_std = np.std(accuracy_test_clean_2)\n",
    "accuracy_test_attack_3_std = np.std(accuracy_test_attack_3)\n",
    "accuracy_test_clean_3_std = np.std(accuracy_test_clean_3)\n",
    "\n",
    "with open('variables_std.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "                 accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "                 accuracy_test_attack_3_std, accuracy_test_clean_3_std], f)\n",
    "\n",
    "accuracy_test_attack_1_avg = np.mean(accuracy_test_attack_1)\n",
    "accuracy_test_clean_1_avg = np.mean(accuracy_test_clean_1)\n",
    "accuracy_test_attack_2_avg = np.mean(accuracy_test_attack_2)\n",
    "accuracy_test_clean_2_avg = np.mean(accuracy_test_clean_2)\n",
    "accuracy_test_attack_3_avg = np.mean(accuracy_test_attack_3)\n",
    "accuracy_test_clean_3_avg = np.mean(accuracy_test_clean_3)\n",
    "\n",
    "with open('variables.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "                 accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "                 accuracy_test_attack_3_avg, accuracy_test_clean_3_avg], f)\n",
    "\n",
    "labels = ['ACCs before attack', 'ACCs before attack', \n",
    "          'ACCs after attack', 'ACCs after attack', \n",
    "          'ACCs after CryptoGraph', 'ACCs after CryptoGraph']\n",
    "values = [accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "          accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "          accuracy_test_attack_3_avg, accuracy_test_clean_3_avg]\n",
    "std_devs = [accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "            accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "            accuracy_test_attack_3_std, accuracy_test_clean_3_std]\n",
    "x = np.arange(len(labels)//2)\n",
    "width = 0.35\n",
    "bars1 = plt.bar(x - width/2, values[::2], width, yerr=std_devs[::2], label='Attack set', color='red', capsize=5)\n",
    "bars2 = plt.bar(x + width/2, values[1::2], width, yerr=std_devs[1::2], label='Clean set', color='blue', capsize=5)\n",
    "plt.title('Average Accuracies')\n",
    "plt.xlabel('Levels of Attack and Defense')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.xticks(x, labels[::2])\n",
    "plt.legend()\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## mahsa-V4.4: using surrogate model - using loss fonc and gradiant base- edge-score for choosing nodes to attack ################\n",
    "# attack adding/removing edge: (make le budget adaptatif just for ajouter or  enlever) ####### change of 4.4 ########\n",
    "# surrogat model for each edge to be added or removed via gradient and loss of edges and common neighbors\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from deeprobust.graph.defense import GCN\n",
    "from deeprobust.graph.utils import *\n",
    "from deeprobust.graph.data import Dataset\n",
    "from DistributedDefense import TwoPartyCNGCN\n",
    "from experiments import split_dataset\n",
    "from scipy.sparse import csr_matrix\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Train surrogate model\n",
    "def train_surrogate_model(features, adj, labels, idx_train, idx_val):\n",
    "    surrogate_model = GCN(nfeat=features.shape[1], nclass=labels.max().item() + 1, nhid=16, device=device, dropout=0.5)\n",
    "    surrogate_model = surrogate_model.to(device)\n",
    "    surrogate_model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    return surrogate_model\n",
    "\n",
    "# Compute gradients of loss w.r.t adjacency matrix\n",
    "def compute_gradients(surrogate_model, features, adj, labels, target_node):\n",
    "    surrogate_model.eval()\n",
    "    adj = torch.FloatTensor(adj.toarray()).to(device)\n",
    "    adj.requires_grad = True\n",
    "    features = torch.FloatTensor(features.toarray()).to(device)\n",
    "    labels = torch.LongTensor(labels).to(device)\n",
    "    output = surrogate_model(features, adj)\n",
    "    loss = F.nll_loss(output[[target_node]], labels[[target_node]])\n",
    "    loss.backward()\n",
    "    gradients = adj.grad.cpu().numpy()\n",
    "    return loss.item(), gradients\n",
    "\n",
    "# choose nodes to attack based on loss and gradients not common neighbors\n",
    "def calc_nodes_to_attack(surrogate_model, features, adj, labels, idx_test):\n",
    "    zero_loss_count = 0\n",
    "    zero_gradients_count = 0\n",
    "    non_zero_loss_and_gradients_nodes = []\n",
    "    zero_loss_non_ziro_gr = 0\n",
    "\n",
    "    for target_node in idx_test:\n",
    "        loss, gradients = compute_gradients(surrogate_model, features, adj, labels, target_node)\n",
    "        if loss == 0:\n",
    "            zero_loss_count += 1\n",
    "        if not np.any(gradients):\n",
    "            zero_gradients_count += 1\n",
    "        \n",
    "        zero_loss = loss == 0\n",
    "        zero_gradients = not np.any(gradients)\n",
    "    # If both loss and gradients are non-zero, store the node\n",
    "        if not zero_loss and not zero_gradients:\n",
    "            impact_score = loss * np.sum(np.abs(gradients))\n",
    "            non_zero_loss_and_gradients_nodes.append((target_node, impact_score))\n",
    "        # Ensure consistency between zero loss and zero gradients\n",
    "        if zero_loss and not zero_gradients:\n",
    "            # print(f\"Warning: Target node {target_node} has zero loss but non-zero gradients!\")\n",
    "            zero_loss_non_ziro_gr += 1\n",
    "    \n",
    "    print(f\"Final number of nodes with zero loss: {zero_loss_count}\")\n",
    "    print(f\"Final number of nodes with zero gradients: {zero_gradients_count}\")\n",
    "    print(f\"Final number of nodes with zero loss but non-zero gradients: {zero_loss_non_ziro_gr}\")\n",
    "    # print(\"Nodes with non-zero loss and non-zero gradients:\")\n",
    "    # for node in non_zero_loss_and_gradients_nodes:\n",
    "    #     print(node)\n",
    "    print(f\"Number of nodes with non-zero loss and non-zero gradients: {len(non_zero_loss_and_gradients_nodes)}\")\n",
    "    # Sort nodes by impact score in descending order\n",
    "    non_zero_loss_and_gradients_nodes.sort(key=lambda x: x[1], reverse=True)\n",
    "    nodes_to_attack = [node for node, score in non_zero_loss_and_gradients_nodes]\n",
    "    return nodes_to_attack\n",
    "\n",
    "\n",
    "####### new strategy of adding alpha beta to the impact score to consider the common neighbors while selecting nodes to attack\n",
    "####### not have good results all 0.1 accuracies.\n",
    "# def calc_nodes_to_attack(surrogate_model, features, adj, labels, idx_test, alpha=1.0, beta=1.0):\n",
    "#     zero_loss_count = 0\n",
    "#     zero_gradients_count = 0\n",
    "#     non_zero_loss_and_gradients_nodes = []\n",
    "#     zero_loss_non_ziro_gr = 0\n",
    "\n",
    "#     for target_node in idx_test:\n",
    "#         loss, gradients = compute_gradients(surrogate_model, features, adj, labels, target_node)\n",
    "#         if loss == 0:\n",
    "#             zero_loss_count += 1\n",
    "#         if not np.any(gradients):\n",
    "#             zero_gradients_count += 1\n",
    "        \n",
    "#         zero_loss = loss == 0\n",
    "#         zero_gradients = not np.any(gradients)\n",
    "#         if not zero_loss and not zero_gradients:\n",
    "#             impact_score = loss * np.sum(np.abs(gradients))\n",
    "#             common_neighbors = sum(calculate_common_neighbors(adj, target_node, i) for i in range(adj.shape[0]) if i != target_node)\n",
    "#             final_score = alpha * impact_score + beta * common_neighbors\n",
    "#             non_zero_loss_and_gradients_nodes.append((target_node, final_score))\n",
    "        \n",
    "#         if zero_loss and not zero_gradients:\n",
    "#             zero_loss_non_ziro_gr += 1\n",
    "    \n",
    "#     print(f\"Final number of nodes with zero loss: {zero_loss_count}\")\n",
    "#     print(f\"Final number of nodes with zero gradients: {zero_gradients_count}\")\n",
    "#     print(f\"Final number of nodes with zero loss but non-zero gradients: {zero_loss_non_ziro_gr}\")\n",
    "#     print(f\"Number of nodes with non-zero loss and non-zero gradients: {len(non_zero_loss_and_gradients_nodes)}\")\n",
    "\n",
    "#     # Sort nodes by the final score in descending order\n",
    "#     non_zero_loss_and_gradients_nodes.sort(key=lambda x: x[1], reverse=True)\n",
    "#     nodes_to_attack = [node for node, score in non_zero_loss_and_gradients_nodes]\n",
    "#     return nodes_to_attack\n",
    "\n",
    "\n",
    "\n",
    "# Calculate common neighbors between two nodes\n",
    "def calculate_common_neighbors(adj, node1, node2):\n",
    "    neighbors1 = set(adj[node1].indices)\n",
    "    neighbors2 = set(adj[node2].indices)\n",
    "    common_neighbors = neighbors1 & neighbors2\n",
    "    return len(common_neighbors)\n",
    "\n",
    "# Calculate edge scores based on gradients and common neighbors\n",
    "def calculate_edge_scores(adj, gradients, target_node, labels, add=True):\n",
    "    scores = {}\n",
    "    for i in range(adj.shape[0]):\n",
    "        if add and adj[target_node, i] == 0 and labels[target_node] != labels[i]:\n",
    "            common_neighbors = calculate_common_neighbors(adj, target_node, i)\n",
    "            scores[(target_node, i)] = gradients[target_node, i] + common_neighbors #* 10  # 10 is a hyperparameter, can be tuned\n",
    "        elif not add and adj[target_node, i] == 1 and labels[target_node] == labels[i]:\n",
    "            common_neighbors = calculate_common_neighbors(adj, target_node, i)\n",
    "            scores[(target_node, i)] = -gradients[target_node, i] + common_neighbors #* 10 # 10 is a hyperparameter\n",
    "    return scores\n",
    "\n",
    "# Select best edge based on edge scores\n",
    "def select_best_edge(adj, gradients, target_node, labels, add=True):\n",
    "    scores = calculate_edge_scores(adj, gradients, target_node, labels, add) ########################################just add?\n",
    "    if not scores:\n",
    "        return None\n",
    "    if add:\n",
    "        best_edge = max(scores, key=scores.get)\n",
    "    else:\n",
    "        best_edge = min(scores, key=scores.get)\n",
    "    return best_edge\n",
    "\n",
    "# Perturb edges between target nodes\n",
    "def perturb_edges_between_targets(adj, surrogate_model, features, labels, idx_test_attack, budget):\n",
    "    attacked_adj = adj.copy()\n",
    "    added_edges = []  # Track added edges\n",
    "    edge_added_count = 0\n",
    "    edge_removed_count = 0\n",
    "    for target_node in idx_test_attack:\n",
    "        print(f\"Target node is: {target_node} with label: {labels[target_node]}\")\n",
    "        loss, gradients = compute_gradients(surrogate_model, features, attacked_adj, labels, target_node)\n",
    "        if not np.any(gradients):\n",
    "            continue\n",
    "        for _ in range(budget):\n",
    "            edge_add = select_best_edge(attacked_adj, gradients, target_node, labels, add=True)\n",
    "            edge_remove = select_best_edge(attacked_adj, gradients, target_node, labels, add=False)\n",
    "            # print(f\"edge_add: {edge_add}, edge_remove: {edge_remove}\")\n",
    "            if edge_add:\n",
    "                attacked_adj[edge_add[0], edge_add[1]] = 1\n",
    "                attacked_adj[edge_add[1], edge_add[0]] = 1\n",
    "                added_edges.append(edge_add)  # Track added edge\n",
    "                edge_added_count += 1\n",
    "                print(f\"Added edge: {edge_add}\")\n",
    "            if edge_remove:\n",
    "                attacked_adj[edge_remove[0], edge_remove[1]] = 0\n",
    "                attacked_adj[edge_remove[1], edge_remove[0]] = 0\n",
    "                edge_removed_count += 1\n",
    "                print(f\"Removed edge: {edge_remove}\")\n",
    "    print(f\"Total number of edges added: {edge_added_count}\") \n",
    "    print(f\"Total number of edges removed: {edge_removed_count}\")      \n",
    "    return attacked_adj, added_edges  # Return added edges for tracking\n",
    "\n",
    "# Main execution\n",
    "################################ Data loading #######################################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "dataset = \"polblogs\"\n",
    "data = Dataset(root='.', name=dataset, setting='gcn', seed=15)\n",
    "seed = 42\n",
    " \n",
    "set_seeds(seed)\n",
    "adj, features, labels = data.adj, data.features, data.labels\n",
    "idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "\n",
    "############  Train surrogate model and determine nodes to attack\n",
    "surrogate_model = train_surrogate_model(features, adj, labels, idx_train, idx_val)\n",
    "\n",
    "k = 3 # budget in the meaning of Number of nodes to attack\n",
    "nodes_to_attack = calc_nodes_to_attack(surrogate_model, features, adj, labels, idx_test)\n",
    "idx_test_attack = nodes_to_attack[:k]\n",
    "idx_test_clean = [node for node in idx_test if node not in idx_test_attack]\n",
    "print(\"Nodes chosen for attack:\", idx_test_attack)\n",
    "\n",
    "\n",
    "########### Train GCN model initially for evaluation before attack\n",
    "model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "            nhid=16, device=device, dropout=0.5)\n",
    "model = model.to(device)\n",
    "model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "model.eval()\n",
    "output = model.test(idx_test)\n",
    "\n",
    "accuracy_test_attack_1 = model.test(idx_test_attack) \n",
    "accuracy_test_clean_1 = model.test(idx_test_clean)\n",
    "print(\"Test accuracy on attack set: \", accuracy_test_attack_1)\n",
    "print(\"Test accuracy on clean set: \", accuracy_test_clean_1)\n",
    "\n",
    "############# perform attack Perturb edges\n",
    "budget = 5 # Number of edges to add or remove for each target node\n",
    "attacked_adj, added_edges = perturb_edges_between_targets(adj, surrogate_model, features, labels, idx_test_attack, budget)\n",
    "\n",
    "# Model evaluation after attack\n",
    "model.fit(features, attacked_adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "model.eval()\n",
    "\n",
    "accuracy_test_attack_2 = model.test(idx_test_attack)\n",
    "accuracy_test_clean_2 = model.test(idx_test_clean)\n",
    "print(\"Test accuracy on attack set after attack: \", accuracy_test_attack_2)\n",
    "print(\"Test accuracy on clean set after attack: \", accuracy_test_clean_2)\n",
    "\n",
    "##################   Crypto'Graph defense\n",
    "print(\"*************** Crypto'Graph defense ***************\")\n",
    "proportion_of_common_links = 0.5\n",
    "adj1, adj2 = split_dataset(attacked_adj, proportion_of_common_links) \n",
    "threshold = 2\n",
    "metric = \"neighbors\"\n",
    "object = \"links\"\n",
    "\n",
    "model = TwoPartyCNGCN(dataset=dataset, nfeat=features.shape[1], nhid=16, nclass=labels.max().item() + 1, device=device)\n",
    "defense_duration, defense_duration, training_duration1, training_duration2, CG_defended_adj1, CG_defended_adj2 = model.fit(\n",
    "        adj1.copy(), adj2.copy(), features, features, labels, idx_train, threshold, metric=metric, object=object,\n",
    "        train_iters=200, initialize=True, verbose=False, idx_val=idx_val)\n",
    "model.eval()\n",
    "\n",
    "accuracy_test_attack_3 = model.test(idx_test_attack)\n",
    "accuracy_test_clean_3 = model.test(idx_test_clean)\n",
    "print(\"Test accuracy on attack set after Crypto'Graph: \", accuracy_test_attack_3)\n",
    "print(\"Test accuracy on clean set after Crypto'Graph: \", accuracy_test_clean_3)\n",
    "\n",
    "# Function to find removed edges\n",
    "def find_removed_edges(original_adj, defended_adj1, defended_adj2):\n",
    "    removed_edges = []\n",
    "    original_adj = original_adj.toarray()\n",
    "    defended_adj1 = defended_adj1.toarray()\n",
    "    defended_adj2 = defended_adj2.toarray()\n",
    "    combined_defended_adj = np.maximum(defended_adj1, defended_adj2)\n",
    "    for i in range(original_adj.shape[0]):\n",
    "        for j in range(i + 1, original_adj.shape[1]):\n",
    "            if original_adj[i, j] == 1 and combined_defended_adj[i, j] == 0:\n",
    "                removed_edges.append((i, j))\n",
    "    return removed_edges\n",
    "\n",
    "# Find all removed edges\n",
    "removed_edges = find_removed_edges(attacked_adj, CG_defended_adj1, CG_defended_adj2)\n",
    "print(f\"Total number of removed edges by CG: {len(removed_edges)}\")\n",
    "\n",
    "# Check if any of the inserted edges during the attack were removed by CG\n",
    "removed_inserted_edges = [edge for edge in added_edges if edge in removed_edges]\n",
    "print(f\"Inserted edges removed by CG: {removed_inserted_edges}\")\n",
    "print(f\"Number of inserted edges removed by CG: {len(removed_inserted_edges)}\")\n",
    "\n",
    "################ Save and plot results\n",
    "accuracy_test_attack_1_std = np.std(accuracy_test_attack_1)\n",
    "accuracy_test_clean_1_std = np.std(accuracy_test_clean_1)\n",
    "accuracy_test_attack_2_std = np.std(accuracy_test_attack_2)\n",
    "accuracy_test_clean_2_std = np.std(accuracy_test_clean_2)\n",
    "accuracy_test_attack_3_std = np.std(accuracy_test_attack_3)\n",
    "accuracy_test_clean_3_std = np.std(accuracy_test_clean_3)\n",
    "\n",
    "with open('variables_std.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "                 accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "                 accuracy_test_attack_3_std, accuracy_test_clean_3_std], f)\n",
    "\n",
    "accuracy_test_attack_1_avg = np.mean(accuracy_test_attack_1)\n",
    "accuracy_test_clean_1_avg = np.mean(accuracy_test_clean_1)\n",
    "accuracy_test_attack_2_avg = np.mean(accuracy_test_attack_2)\n",
    "accuracy_test_clean_2_avg = np.mean(accuracy_test_clean_2)\n",
    "accuracy_test_attack_3_avg = np.mean(accuracy_test_attack_3)\n",
    "accuracy_test_clean_3_avg = np.mean(accuracy_test_clean_3)\n",
    "\n",
    "with open('variables.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "                 accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "                 accuracy_test_attack_3_avg, accuracy_test_clean_3_avg], f)\n",
    "\n",
    "labels = ['ACCs before attack', 'ACCs before attack', \n",
    "          'ACCs after attack', 'ACCs after attack', \n",
    "          'ACCs after CryptoGraph', 'ACCs after CryptoGraph']\n",
    "values = [accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "          accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "          accuracy_test_attack_3_avg, accuracy_test_clean_3_avg]\n",
    "std_devs = [accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "            accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "            accuracy_test_attack_3_std, accuracy_test_clean_3_std]\n",
    "x = np.arange(len(labels)//2)\n",
    "width = 0.35\n",
    "bars1 = plt.bar(x - width/2, values[::2], width, yerr=std_devs[::2], label='Attack set', color='red', capsize=5)\n",
    "bars2 = plt.bar(x + width/2, values[1::2], width, yerr=std_devs[1::2], label='Clean set', color='blue', capsize=5)\n",
    "plt.title('Average Accuracies')\n",
    "plt.xlabel('Levels of Attack and Defense')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.xticks(x, labels[::2])\n",
    "plt.legend()\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. inke az argmax estefade kone dorost baraye probability inke che tasiri mizare bego boro maghalehaye nettack o ... ro bekhon tebghe ona\n",
    "\n",
    "3. when model fooled, even if budget is still remaining, stop the process\n",
    "in a defined budget if att successful ok. if needed more bud, tell prompt\n",
    "\n",
    "\n",
    "8. version v4.1 ham alan dorost kar nemikone, chon ke hichi na add mikone na remove, fek konam moshkel ine ke vaghti mikhad entekhab kone add kone ya remove hichi mishe. to noskhe ghabli ke ham add mikard ham remove joda joda ok bod anjam mishod \n",
    "hala switch konim roye v4.2 behtare vaght bezarim\n",
    "\n",
    "9. faghat add???????????? be shomare 8 bargard bebin chi mishe. alan ba ye budget ham add ham remove mikone\n",
    "\n",
    "10. ba formule jadid common neighbor dar entekhab node ha ham barresi kon chera az 0.1 abla pain nemire, tedad o budgethaye mokhtalef\n",
    "11. maybe change alpha beta in new impact score for node selection\n",
    "maybe change node selection \n",
    "\n",
    "11. for this week: work on alpha beta to see if it changes anything\n",
    "12. fir next week maybe see the selected nodes conditions to see if they have how many edges and labales and .... \n",
    "12. for next week : work on V4.4  to use each bud for add or remove\n",
    "13. in version 4.3 mitoni zero lost o zero gradient ro hata emtehan koni\n",
    "14. try the model`s overall performance. i just work on accuracy for 2 parts attacked and clean. how about overal\n",
    "15. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
