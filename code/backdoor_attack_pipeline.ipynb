{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from deeprobust.graph.defense import GCN\n",
    "from deeprobust.graph.targeted_attack import FGA\n",
    "from deeprobust.graph.utils import *\n",
    "from deeprobust.graph.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from experiments import split_dataset\n",
    "from DistributedDefense import TwoPartyCNGCN\n",
    "import networkx as nx\n",
    "from scipy.sparse import csr_matrix\n",
    "import Mahsa_backdoor_V0 as backdoor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "#import random # for random choice of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# V0: adding edges - Attack repeatedly - consider crypto'Graph ###############################\n",
    "# Define the number of repeats\n",
    "num_repeats = 1\n",
    "accuracy_test_attack_1_values = []\n",
    "accuracy_test_clean_1_values = []\n",
    "accuracy_test_attack_2_values = []\n",
    "accuracy_test_clean_2_values = []\n",
    "accuracy_test_attack_3_values = []\n",
    "accuracy_test_clean_3_values = []\n",
    "\n",
    "################################ Data loading #######################################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "dataset = \"polblogs\"\n",
    "# Use the current directory for windows\n",
    "data = Dataset(root='.', name=dataset)\n",
    "#data = Dataset(root='/tmp/', name=dataset): this is for unix-based systems\n",
    "\n",
    "for _ in range(num_repeats):\n",
    "    \n",
    "    #############################  preprocessing ############################\n",
    "    adj, features, labels = data.adj, data.features, data.labels\n",
    "    idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "    #split idx_test into two parts randomly\n",
    "    test_size = 0.10  # 10% for test_attack, 90% for test_clean\n",
    "    # test_size = 1- 1 / len(idx_test)  # 1 node for test_attack, the rest for test_clean\n",
    "\n",
    "    idx_test_clean , idx_test_attack = train_test_split(idx_test, test_size=test_size, random_state=42)\n",
    "\n",
    "\n",
    "    # Split graph into two graphs \n",
    "    proportion_of_common_links = 0.5\n",
    "    adj1, adj2 = split_dataset(adj, proportion_of_common_links) \n",
    "\n",
    "\n",
    "# print (\"idx_test_clean\",len (idx_test_clean))\n",
    "# print (\"idx_test_attack\",len (idx_test_attack))\n",
    "# print (\"idx_test\",len (idx_test))\n",
    "# print (\"train\",len (idx_train))\n",
    "# print (\"val\",len (idx_val))\n",
    "\n",
    "\n",
    "    ############################ tarin model initially and test accuracy ###########################\n",
    "    # Perform evaluation before attack to find the baseline accuracy\n",
    "\n",
    "    # Train GCN model \n",
    "    # 1. Model definition\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    # 2. Train model - patience= number of epochs to wait before early stopping , train_iters= number of iterations\n",
    "    model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    #model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200,metric=metric,\n",
    "               #object=object, initialize=True, verbose=False )\n",
    "    # 3. Evaluate model\n",
    "    model.eval()\n",
    "    output = model.test(idx_test)\n",
    "    #acc_test = accuracy(output, labels, idx_test)\n",
    "\n",
    "    # accuracies = model.test(idx_test) \n",
    "    # print(\"Test accuracy: \", accuracies)\n",
    "\n",
    "    # output_1 = model.test(idx_test_attack)\n",
    "    # output_2 = model.test(idx_test_clean)\n",
    "\n",
    "    accuracy_test_attack_1 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_1 = model.test(idx_test_clean)\n",
    "\n",
    "    print(\"Test accuracy on attack set: \", accuracy_test_attack_1)\n",
    "    print(\"Test accuracy on clean set: \", accuracy_test_clean_1)\n",
    "\n",
    "    \n",
    "    ################################ Mahsa attack ##############################\n",
    "    # Perform the attack\n",
    "    # version 0: attack on the whole graph - on idx_test_attack nodes\n",
    "\n",
    "    modified_adj1 =  adj1.copy()\n",
    "\n",
    "    # Create a NetworkX graph from the adjacency matrix\n",
    "    graph = nx.from_scipy_sparse_array(modified_adj1)\n",
    "\n",
    "    # Add labels to the graph\n",
    "    for node_id, label in enumerate(labels):\n",
    "        graph.nodes[node_id]['label'] = label\n",
    "    # print(f\"lenght of the labels : {len(labels)}\") \n",
    "    print(f\"graph edges : {graph.number_of_edges()}\")\n",
    "    print(f\"graph nodes : {graph.number_of_nodes()}\")\n",
    "    # Set the budget for the attack\n",
    "    budget = 5\n",
    "\n",
    "    #attacked_graph is initially set to graph, and then updated after each attack\n",
    "    # This means that each attack is performed on the graph resulting from the previous attacks.\n",
    "    attacked_graph = graph\n",
    "    for target_node in idx_test_attack:\n",
    "        non_neighbor_opposit = backdoor.find_non_neighbor_opposit_label(attacked_graph, target_node)\n",
    "        max_same_min_opposit_label_neighbors = backdoor.find_max_same_min_opposit_label_neighbors(attacked_graph, non_neighbor_opposit)\n",
    "        nodes_for_attack = backdoor.nodes_for_attack(attacked_graph, target_node, max_same_min_opposit_label_neighbors, budget)\n",
    "        attacked_graph = backdoor.insert_edge(attacked_graph, target_node, nodes_for_attack)\n",
    "        backdoor.evaluate_graph(attacked_graph, nodes_for_attack, target_node, budget)\n",
    "        \n",
    "    # Convert the graph to a CSR matrix\n",
    "    modified_adj1 =backdoor.convert(attacked_graph)\n",
    "    print(attacked_graph)\n",
    "    print(f\"total inserted edges : {attacked_graph.number_of_edges() - graph.number_of_edges()}\")\n",
    "\n",
    "    ################################ evaluation after attack ##############################\n",
    "    # accuracy after attack\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    #data = data.to(device)\n",
    "    model.fit(features, modified_adj1, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    model.eval()\n",
    "\n",
    "    # output = model.test(idx_test)\n",
    "\n",
    "    #acc_test = accuracy(output, labels, idx_test)\n",
    "\n",
    "    # output_1 = model.test(idx_test_attack)\n",
    "    # output_2 = model.test(idx_test_clean)\n",
    "\n",
    "    accuracy_test_attack_2 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_2 = model.test(idx_test_clean)\n",
    "\n",
    "    print(\"Test accuracy on attack set: \", accuracy_test_attack_2)\n",
    "    print(\"Test accuracy on clean set: \", accuracy_test_clean_2)\n",
    "\n",
    "    ############################ Crypto'Graph defense ###########################\n",
    "    # Perform Crypto'Graph distributed defense\n",
    "\n",
    "    threshold = 2               # threshold for dropping dissimilar edges\n",
    "    metric = \"neighbors\"        # metric for dropping dissimilar edges (neighbors, jaccard, cosine)\n",
    "    object = \"links\"            # object for defense (links, features)\n",
    "\n",
    "    model = TwoPartyCNGCN(dataset=dataset, nfeat=features.shape[1], nhid=16, nclass=labels.max().item() + 1,\n",
    "                            device=device)\n",
    "    model.fit(modified_adj1.copy(), adj2.copy(), features, features, labels, idx_train, threshold, metric=metric, object=object,\n",
    "                train_iters=200, initialize=True, verbose=False, idx_val=idx_val)\n",
    "    model.eval()\n",
    "    accuracies = model.test(idx_test)  #accuracy of the model after the defense on all the test data - (all the nodes)\n",
    "    accuracy_test_attack_3 = model.test(idx_test_attack)\n",
    "    accuracy_test_clean_3 = model.test(idx_test_clean)\n",
    "    print(\"Test accuracy on attack set: \", accuracy_test_attack_3)\n",
    "    print(\"Test accuracy on clean set: \", accuracy_test_clean_3)\n",
    "\n",
    "    # At the end of each repeat, append the accuracy values to the lists:\n",
    "    accuracy_test_attack_1_values.append(accuracy_test_attack_1)\n",
    "    accuracy_test_clean_1_values.append(accuracy_test_clean_1)\n",
    "    accuracy_test_attack_2_values.append(accuracy_test_attack_2)\n",
    "    accuracy_test_clean_2_values.append(accuracy_test_clean_2)\n",
    "    accuracy_test_attack_3_values.append(accuracy_test_attack_3)\n",
    "    accuracy_test_clean_3_values.append(accuracy_test_clean_3)\n",
    "\n",
    "\n",
    "\n",
    "####################### Standard deviation values ############################\n",
    "# Calculate the standard deviation of the accuracy values:\n",
    "accuracy_test_attack_1_std = np.std(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_std = np.std(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_std = np.std(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_std = np.std(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_std = np.std(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_std = np.std(accuracy_test_clean_3_values)\n",
    "\n",
    "# print(\"Standard deviation of test accuracy on attack set 1: \", accuracy_test_attack_1_std)\n",
    "# print(\"Standard deviation of test accuracy on clean set 1: \", accuracy_test_clean_1_std)\n",
    "# print(\"Standard deviation of test accuracy on attack set 2: \", accuracy_test_attack_2_std)\n",
    "# print(\"Standard deviation of test accuracy on clean set 2: \", accuracy_test_clean_2_std)\n",
    "# print(\"Standard deviation of test accuracy on attack set 3: \", accuracy_test_attack_3_std)\n",
    "# print(\"Standard deviation of test accuracy on clean set 3: \", accuracy_test_clean_3_std)\n",
    "\n",
    "# Save the standard deviation values to a file\n",
    "with open('variables_std.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "                 accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "                 accuracy_test_attack_3_std, accuracy_test_clean_3_std], f)\n",
    "\n",
    "\n",
    "####################### Average accuracy values ############################\n",
    "# Calculate the average accuracy values:\n",
    "accuracy_test_attack_1_avg = np.mean(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_avg = np.mean(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_avg = np.mean(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_avg = np.mean(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_avg = np.mean(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_avg = np.mean(accuracy_test_clean_3_values)\n",
    "\n",
    "# print(\"Average test accuracy on attack set 1: \", accuracy_test_attack_1_avg)\n",
    "# print(\"Average test accuracy on clean set 1: \", accuracy_test_clean_1_avg)\n",
    "# print(\"Average test accuracy on attack set 2: \", accuracy_test_attack_2_avg)\n",
    "# print(\"Average test accuracy on clean set 2: \", accuracy_test_clean_2_avg)\n",
    "# print(\"Average test accuracy on attack set 3: \", accuracy_test_attack_3_avg)\n",
    "# print(\"Average test accuracy on clean set 3: \", accuracy_test_clean_3_avg)\n",
    "\n",
    "with open('variables.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "                 accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "                 accuracy_test_attack_3_avg, accuracy_test_clean_3_avg], f)\n",
    "    \n",
    "##################################\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# V0 - Plotting ACcuracies #######################################\n",
    "labels = ['ACCs before attack', 'ACCs before attack', \n",
    "          'ACCs after attack', 'ACCs after attack', \n",
    "          'ACCs after CryptoGraph', 'ACCs after CryptoGraph']\n",
    "values = [accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "          accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "          accuracy_test_attack_3_avg, accuracy_test_clean_3_avg]\n",
    "std_devs = [accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "            accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "            accuracy_test_attack_3_std, accuracy_test_clean_3_std]\n",
    "\n",
    "# Define the x-coordinates of the bars and the width of the bars\n",
    "x = np.arange(len(labels)//2)\n",
    "width = 0.35\n",
    "\n",
    "# # Create the bar chart\n",
    "# bars1 = plt.bar(x - width/2, values[::2], width, label='Attack set', color='red')\n",
    "# bars2 = plt.bar(x + width/2, values[1::2], width, label='Clean set', color='blue')\n",
    "\n",
    "# Create the bar chart with error bars\n",
    "bars1 = plt.bar(x - width/2, values[::2], width, yerr=std_devs[::2], label='Attack set', color='red', capsize=5)\n",
    "bars2 = plt.bar(x + width/2, values[1::2], width, yerr=std_devs[1::2], label='Clean set', color='blue', capsize=5)\n",
    "\n",
    "# Add a title and labels to the axes\n",
    "plt.title('Average Accuracies')\n",
    "plt.xlabel('Levels of Attack and Defense')\n",
    "plt.ylabel('Average Accuracy')\n",
    "\n",
    "# Make the x-labels vertical\n",
    "plt.xticks(x, labels[::2])\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Add exact values on each bar\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "\n",
    "# Adjust the layout to prevent the labels from being cut off\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Attack one node (adding label) each time to discover node conditions ###############################\n",
    "# Define the number of repeats\n",
    "num_repeats = 1\n",
    "accuracy_test_attack_1_values = []\n",
    "accuracy_test_clean_1_values = []\n",
    "accuracy_test_attack_2_values = []\n",
    "accuracy_test_clean_2_values = []\n",
    "accuracy_test_attack_3_values = []\n",
    "accuracy_test_clean_3_values = []\n",
    "\n",
    "################################ Data loading #######################################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "dataset = \"polblogs\"\n",
    "# Use the current directory for windows\n",
    "data = Dataset(root='.', name=dataset)\n",
    "#data = Dataset(root='/tmp/', name=dataset): this is for unix-based systems\n",
    "\n",
    "for _ in range(num_repeats):\n",
    "    \n",
    "    #############################  preprocessing ############################\n",
    "    adj, features, labels = data.adj, data.features, data.labels\n",
    "    idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "    #split idx_test into two parts : one node for attack and the rest for clean\n",
    "    # test_size = 1  # 1 node for attack others for test_clean\n",
    "    # idx_test_clean , idx_test_attack = train_test_split(idx_test, test_size=test_size, random_state=42)\n",
    "    # selected_node = idx_test_attack[0]\n",
    "    # print(f\"Selected node for attack: {selected_node}\")\n",
    "\n",
    "    #choose a node for attack manually (the one which has been chosen randomely from idx_test in the previous part)\n",
    "    selected_node = 1196\n",
    "    idx_test_attack = np.array([selected_node])\n",
    "    idx_test_clean = np.array([node for node in idx_test if node != selected_node])\n",
    "\n",
    "    # Split graph into two graphs for Crypto'Graph\n",
    "    proportion_of_common_links = 0.5\n",
    "    adj1, adj2 = split_dataset(adj, proportion_of_common_links) \n",
    "\n",
    "   \n",
    "    # print (\"idx_test_clean\",len (idx_test_clean))\n",
    "    # print (\"idx_test_attack\",len (idx_test_attack))\n",
    "    # print (\"idx_test\",len (idx_test))\n",
    "    # print (\"train\",len (idx_train))\n",
    "    # print (\"val\",len (idx_val))\n",
    "\n",
    "    # print (\"idx_test_clean\",idx_test_clean)\n",
    "    # print (\"idx_test_attack\",idx_test_attack)\n",
    "\n",
    "    ############################ tarin model initially and test accuracy ###########################\n",
    "    # Perform evaluation before attack to find the baseline accuracy\n",
    "\n",
    "    # Train GCN model \n",
    "    # 1. Model definition\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    # 2. Train model - patience= number of epochs to wait before early stopping , train_iters= number of iterations\n",
    "    model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    #model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200,metric=metric,\n",
    "               #object=object, initialize=True, verbose=False )\n",
    "    # 3. Evaluate model\n",
    "    model.eval()\n",
    "    output = model.test(idx_test)\n",
    "    #acc_test = accuracy(output, labels, idx_test)\n",
    "\n",
    "    # accuracies = model.test(idx_test) \n",
    "    # print(\"Test accuracy: \", accuracies)\n",
    "\n",
    "    # output_1 = model.test(idx_test_attack)\n",
    "    # output_2 = model.test(idx_test_clean)\n",
    "\n",
    "    accuracy_test_attack_1 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_1 = model.test(idx_test_clean)\n",
    "\n",
    "    print(\"Test accuracy on attack set: \", accuracy_test_attack_1)\n",
    "    print(\"Test accuracy on clean set: \", accuracy_test_clean_1)\n",
    "\n",
    "    \n",
    "    ################################ Mahsa attack ##############################\n",
    "    # Perform the attack\n",
    "    # version 0: attack on the whole graph - on idx_test_attack nodes\n",
    "\n",
    "    modified_adj1 =  adj1.copy()\n",
    "\n",
    "    # Create a NetworkX graph from the adjacency matrix\n",
    "    graph = nx.from_scipy_sparse_array(modified_adj1)\n",
    "\n",
    "    # Add labels to the graph\n",
    "    for node_id, label in enumerate(labels):\n",
    "        graph.nodes[node_id]['label'] = label\n",
    "    # print(f\"lenght of the labels : {len(labels)}\") \n",
    "    print(f\"graph edges : {graph.number_of_edges()}\")\n",
    "    print(f\"graph nodes : {graph.number_of_nodes()}\")\n",
    "    # Set the budget for the attack\n",
    "    budget = 50\n",
    "\n",
    "    #attacked_graph is initially set to graph, and then updated after each attack\n",
    "    # This means that each attack is performed on the graph resulting from the previous attacks.\n",
    "    attacked_graph = graph\n",
    "    for target_node in idx_test_attack:\n",
    "        non_neighbor_opposit = backdoor.find_non_neighbor_opposit_label(attacked_graph, target_node)\n",
    "        max_same_min_opposit_label_neighbors = backdoor.find_max_same_min_opposit_label_neighbors(attacked_graph, non_neighbor_opposit)\n",
    "        nodes_for_attack = backdoor.nodes_for_attack(attacked_graph, target_node, max_same_min_opposit_label_neighbors, budget)\n",
    "        attacked_graph = backdoor.insert_edge(attacked_graph, target_node, nodes_for_attack)\n",
    "        backdoor.evaluate_graph(attacked_graph, nodes_for_attack, target_node, budget)\n",
    "   \n",
    "    print ( f\"idx_test_attack: {idx_test_attack}\")\n",
    "    neighbors_same_label = backdoor.find_same_neighbor(graph, selected_node)\n",
    "    neighbors_opposit_label = backdoor.find_opposit_neighbor(graph, selected_node)\n",
    "    print ( f\"number of target same label neighbors: {len(neighbors_same_label)}\")\n",
    "    print ( f\"number of target opposit label neighbors: {len(neighbors_opposit_label)}\")\n",
    "    print ( f\"idx_test_attack same label neighbors: {neighbors_same_label}\")\n",
    "    print ( f\"idx_test_attack opposit label neighbors: {neighbors_opposit_label}\")\n",
    "    print ( f\"number of target NONE neighbors opposite label: {len(backdoor.find_non_neighbor_opposit_label(graph, selected_node))}\")\n",
    "    print ( f\"idx_test_attack opposit label NONE neighbors: {backdoor.find_non_neighbor_opposit_label(graph, selected_node)}\")\n",
    "\n",
    "    ################################## Plotting target node before attack  #######################################\n",
    "    target_subgraph = graph.subgraph([selected_node] + list(neighbors_same_label) + list(neighbors_opposit_label))\n",
    "    pos = nx.spring_layout(target_subgraph)  # positions for all nodes\n",
    "    # nodes\n",
    "    nx.draw_networkx_nodes(target_subgraph, pos, nodelist=neighbors_same_label, node_color='green')\n",
    "    nx.draw_networkx_nodes(target_subgraph, pos, nodelist=neighbors_opposit_label, node_color='pink')\n",
    "    # edges\n",
    "    nx.draw_networkx_edges(target_subgraph, pos, width=1.0, alpha=0.5)\n",
    "    # labels\n",
    "    nx.draw_networkx_labels(target_subgraph, pos, font_size=16)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "   \n",
    "    # Convert the graph to a CSR matrix\n",
    "    modified_adj1 =backdoor.convert(attacked_graph)\n",
    "    print(attacked_graph)\n",
    "    print(f\"total inserted edges : {(attacked_graph.number_of_edges() - graph.number_of_edges())}\")\n",
    "\n",
    "    ################################ evaluation after attack ##############################\n",
    "    # accuracy after attack\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    #data = data.to(device)\n",
    "    model.fit(features, modified_adj1, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    model.eval()\n",
    "\n",
    "    # output = model.test(idx_test)\n",
    "\n",
    "    #acc_test = accuracy(output, labels, idx_test)\n",
    "\n",
    "    # output_1 = model.test(idx_test_attack)\n",
    "    # output_2 = model.test(idx_test_clean)\n",
    "\n",
    "    accuracy_test_attack_2 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_2 = model.test(idx_test_clean)\n",
    "\n",
    "    print(\"Test accuracy on attack set after attack: \", accuracy_test_attack_2)\n",
    "    print(\"Test accuracy on clean set after attack: \", accuracy_test_clean_2)\n",
    "\n",
    "    ############################ Crypto'Graph defense ###########################\n",
    "    # Perform Crypto'Graph distributed defense\n",
    "\n",
    "    threshold = 2               # threshold for dropping dissimilar edges\n",
    "    metric = \"neighbors\"        # metric for dropping dissimilar edges (neighbors, jaccard, cosine)\n",
    "    object = \"links\"            # object for defense (links, features)\n",
    "\n",
    "    model = TwoPartyCNGCN(dataset=dataset, nfeat=features.shape[1], nhid=16, nclass=labels.max().item() + 1,\n",
    "                            device=device)\n",
    "    model.fit(modified_adj1.copy(), adj2.copy(), features, features, labels, idx_train, threshold, metric=metric, object=object,\n",
    "                train_iters=200, initialize=True, verbose=False, idx_val=idx_val)\n",
    "    model.eval()\n",
    "    accuracies = model.test(idx_test)  #accuracy of the model after the defense on all the test data - (all the nodes)\n",
    "    accuracy_test_attack_3 = model.test(idx_test_attack)\n",
    "    accuracy_test_clean_3 = model.test(idx_test_clean)\n",
    "    print(\"Test accuracy on attack set after Crypto'Graph: \", accuracy_test_attack_3)\n",
    "    print(\"Test accuracy on clean set after Crypto'Graph: \", accuracy_test_clean_3)\n",
    "\n",
    "    # At the end of each repeat, append the accuracy values to the lists:\n",
    "    accuracy_test_attack_1_values.append(accuracy_test_attack_1)\n",
    "    accuracy_test_clean_1_values.append(accuracy_test_clean_1)\n",
    "    accuracy_test_attack_2_values.append(accuracy_test_attack_2)\n",
    "    accuracy_test_clean_2_values.append(accuracy_test_clean_2)\n",
    "    accuracy_test_attack_3_values.append(accuracy_test_attack_3)\n",
    "    accuracy_test_clean_3_values.append(accuracy_test_clean_3)\n",
    "\n",
    "\n",
    "\n",
    "####################### Standard deviation values ############################\n",
    "# Calculate the standard deviation of the accuracy values:\n",
    "accuracy_test_attack_1_std = np.std(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_std = np.std(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_std = np.std(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_std = np.std(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_std = np.std(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_std = np.std(accuracy_test_clean_3_values)\n",
    "\n",
    "# print(\"Standard deviation of test accuracy on attack set 1: \", accuracy_test_attack_1_std)\n",
    "# print(\"Standard deviation of test accuracy on clean set 1: \", accuracy_test_clean_1_std)\n",
    "# print(\"Standard deviation of test accuracy on attack set 2: \", accuracy_test_attack_2_std)\n",
    "# print(\"Standard deviation of test accuracy on clean set 2: \", accuracy_test_clean_2_std)\n",
    "# print(\"Standard deviation of test accuracy on attack set 3: \", accuracy_test_attack_3_std)\n",
    "# print(\"Standard deviation of test accuracy on clean set 3: \", accuracy_test_clean_3_std)\n",
    "\n",
    "# Save the standard deviation values to a file\n",
    "with open('variables_std.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "                 accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "                 accuracy_test_attack_3_std, accuracy_test_clean_3_std], f)\n",
    "\n",
    "\n",
    "####################### Average accuracy values ############################\n",
    "# Calculate the average accuracy values:\n",
    "accuracy_test_attack_1_avg = np.mean(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_avg = np.mean(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_avg = np.mean(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_avg = np.mean(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_avg = np.mean(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_avg = np.mean(accuracy_test_clean_3_values)\n",
    "\n",
    "\n",
    "with open('variables.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "                 accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "                 accuracy_test_attack_3_avg, accuracy_test_clean_3_avg], f)\n",
    "    \n",
    "\n",
    "################################# Plotting Training Results#######################################\n",
    "labels = ['ACCs before attack', 'ACCs before attack', \n",
    "          'ACCs after attack', 'ACCs after attack', \n",
    "          'ACCs after CryptoGraph', 'ACCs after CryptoGraph']\n",
    "values = [accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "          accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "          accuracy_test_attack_3_avg, accuracy_test_clean_3_avg]\n",
    "std_devs = [accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "            accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "            accuracy_test_attack_3_std, accuracy_test_clean_3_std]\n",
    "\n",
    "# Define the x-coordinates of the bars and the width of the bars\n",
    "x = np.arange(len(labels)//2)\n",
    "width = 0.35\n",
    "\n",
    "# Create the bar chart with error bars\n",
    "bars1 = plt.bar(x - width/2, values[::2], width, yerr=std_devs[::2], label='Attack set', color='red', capsize=5)\n",
    "bars2 = plt.bar(x + width/2, values[1::2], width, yerr=std_devs[1::2], label='Clean set', color='blue', capsize=5)\n",
    "\n",
    "# Add a title and labels to the axes\n",
    "plt.title('Average Accuracies')\n",
    "plt.xlabel('Levels of Attack and Defense')\n",
    "plt.ylabel('Average Accuracy')\n",
    "\n",
    "# Make the x-labels vertical\n",
    "plt.xticks(x, labels[::2])\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "# Add exact values on each bar\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "\n",
    "# Adjust the layout to prevent the labels from being cut off\n",
    "plt.tight_layout()\n",
    "# Display the chart\n",
    "plt.show()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# V1: Attack by removing edges ###############################\n",
    "################################# V2: Attack by removing edges + consider cummon neighbors for Crypto ###############################\n",
    "\n",
    "# Define the number of repeats\n",
    "num_repeats = 1\n",
    "accuracy_test_attack_1_values = []\n",
    "accuracy_test_clean_1_values = []\n",
    "accuracy_test_attack_2_values = []\n",
    "accuracy_test_clean_2_values = []\n",
    "accuracy_test_attack_3_values = []\n",
    "accuracy_test_clean_3_values = []\n",
    "\n",
    "################################ Data loading #######################################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "dataset = \"polblogs\"\n",
    "# Use the current directory for windows\n",
    "data = Dataset(root='.', name=dataset)\n",
    "#data = Dataset(root='/tmp/', name=dataset): this is for unix-based systems\n",
    "\n",
    "for _ in range(num_repeats):\n",
    "    \n",
    "    #############################  preprocessing ############################\n",
    "    adj, features, labels = data.adj, data.features, data.labels\n",
    "    idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "    #split idx_test into two parts : one node for attack and the rest for clean\n",
    "    # test_size = 1  # 1 node for attack others for test_clean\n",
    "    # idx_test_clean , idx_test_attack = train_test_split(idx_test, test_size=test_size, random_state=42)\n",
    "    # selected_node = idx_test_attack[0]\n",
    "    # print(f\"Selected node for attack: {selected_node}\")\n",
    "\n",
    "    #choose a node for attack manually (the one which has been chosen randomely from idx_test in the previous part)\n",
    "    selected_node = 1196\n",
    "    idx_test_attack = np.array([selected_node])\n",
    "    idx_test_clean = np.array([node for node in idx_test if node != selected_node])\n",
    "\n",
    "    # Split graph into two graphs for Crypto'Graph\n",
    "    proportion_of_common_links = 0.5\n",
    "    adj1, adj2 = split_dataset(adj, proportion_of_common_links) \n",
    "\n",
    "   \n",
    "    # print (\"idx_test_clean\",len (idx_test_clean))\n",
    "    # print (\"idx_test_attack\",len (idx_test_attack))\n",
    "    # print (\"idx_test\",len (idx_test))\n",
    "    # print (\"train\",len (idx_train))\n",
    "    # print (\"val\",len (idx_val))\n",
    "    # print (\"idx_test_clean\",idx_test_clean)\n",
    "    # print (\"idx_test_attack\",idx_test_attack)\n",
    "\n",
    "    ############################ tarin model initially and test accuracy ###########################\n",
    "    # Perform evaluation before attack to find the baseline accuracy\n",
    "\n",
    "    # Train GCN model \n",
    "    # 1. Model definition\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    # 2. Train model - patience= number of epochs to wait before early stopping , train_iters= number of iterations\n",
    "    model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    #model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200,metric=metric,\n",
    "               #object=object, initialize=True, verbose=False )\n",
    "    # 3. Evaluate model\n",
    "    model.eval()\n",
    "    output = model.test(idx_test)\n",
    "    #acc_test = accuracy(output, labels, idx_test)\n",
    "    # accuracies = model.test(idx_test) \n",
    "    # print(\"Test accuracy: \", accuracies)\n",
    "    # output_1 = model.test(idx_test_attack)\n",
    "    # output_2 = model.test(idx_test_clean)\n",
    "\n",
    "    accuracy_test_attack_1 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_1 = model.test(idx_test_clean)\n",
    "    print(\"Test accuracy on attack set: \", accuracy_test_attack_1)\n",
    "    print(\"Test accuracy on clean set: \", accuracy_test_clean_1)\n",
    "\n",
    "    \n",
    "    ################################ Mahsa attack ##############################\n",
    "    # Perform the attack\n",
    "    # version 1: attack on the whole graph - on idx_test_attack nodes - by only removing edges\n",
    "\n",
    "    modified_adj1 =  adj1.copy()\n",
    "\n",
    "    # Create a NetworkX graph from the adjacency matrix\n",
    "    graph = nx.from_scipy_sparse_array(modified_adj1)\n",
    "    # Add labels to the graph\n",
    "    for node_id, label in enumerate(labels):\n",
    "        graph.nodes[node_id]['label'] = label\n",
    "    # print(f\"lenght of the labels : {len(labels)}\") \n",
    "    print(f\"graph edges : {graph.number_of_edges()}\")\n",
    "    print(f\"graph nodes : {graph.number_of_nodes()}\")\n",
    "    \n",
    "    # Set the budget for the attack\n",
    "    budget = 50\n",
    "\n",
    "    #attacked_graph is initially set to graph, and then updated after each attack\n",
    "    # This means that each attack is performed on the graph resulting from the previous attacks.\n",
    "    attacked_graph = graph\n",
    "    for target_node in idx_test_attack:\n",
    "        neighbor_same = backdoor.find_same_neighbor(attacked_graph, target_node)\n",
    "        max_same_min_opposit_label_neighbors = backdoor.find_max_same_min_opposit_label_neighbors(attacked_graph, neighbor_same)\n",
    "        # step1: we dont consider common neighbors\n",
    "        # attacked_graph = backdoor.remove_edge1(attacked_graph, target_node, max_same_min_opposit_label_neighbors, budget)\n",
    "        \n",
    "        # step2: we consider common neighbors\n",
    "        nodes_for_remove = backdoor.nodes_for_remove(attacked_graph, target_node, max_same_min_opposit_label_neighbors, budget)\n",
    "        attacked_graph = backdoor.remove_edge2(attacked_graph, target_node, nodes_for_remove)\n",
    "        backdoor.check_removing(attacked_graph,nodes_for_remove , target_node, budget)\n",
    "   \n",
    "    print ( f\"idx_test_attack: {idx_test_attack}\")\n",
    "    neighbors_same_label = backdoor.find_same_neighbor(graph, selected_node)\n",
    "    neighbors_opposit_label = backdoor.find_opposit_neighbor(graph, selected_node)\n",
    "    print ( f\"number of target same label neighbors: {len(neighbors_same_label)}\")\n",
    "    print ( f\"number of target opposit label neighbors: {len(neighbors_opposit_label)}\")\n",
    "    print ( f\"idx_test_attack same label neighbors: {neighbors_same_label}\")\n",
    "    print ( f\"idx_test_attack opposit label neighbors: {neighbors_opposit_label}\")\n",
    "    print ( f\"number of target NONE neighbors opposite label: {len(backdoor.find_non_neighbor_opposit_label(graph, selected_node))}\")\n",
    "    print ( f\"idx_test_attack opposit label NONE neighbors: {backdoor.find_non_neighbor_opposit_label(graph, selected_node)}\")\n",
    "\n",
    "    \n",
    "    ################################## Plotting target node before attack  #######################################\n",
    "    target_subgraph = graph.subgraph([selected_node] + list(neighbors_same_label) + list(neighbors_opposit_label))\n",
    "    pos = nx.spring_layout(target_subgraph)  # positions for all nodes\n",
    "    # nodes\n",
    "    nx.draw_networkx_nodes(target_subgraph, pos, nodelist=neighbors_same_label, node_color='green')\n",
    "    nx.draw_networkx_nodes(target_subgraph, pos, nodelist=neighbors_opposit_label, node_color='pink')\n",
    "    # edges\n",
    "    nx.draw_networkx_edges(target_subgraph, pos, width=1.0, alpha=0.5)\n",
    "    # labels\n",
    "    nx.draw_networkx_labels(target_subgraph, pos, font_size=16)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "   \n",
    "    # Convert the graph to a CSR matrix\n",
    "    modified_adj1 =backdoor.convert(attacked_graph)\n",
    "    print(attacked_graph)\n",
    "    print(f\"total removed edges : {(graph.number_of_edges() - attacked_graph.number_of_edges())}\")\n",
    "\n",
    "    ################################ evaluation after attack ##############################\n",
    "    # accuracy after attack\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    #data = data.to(device)\n",
    "    model.fit(features, modified_adj1, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    model.eval()\n",
    "\n",
    "    # output = model.test(idx_test)\n",
    "\n",
    "    #acc_test = accuracy(output, labels, idx_test)\n",
    "\n",
    "    # output_1 = model.test(idx_test_attack)\n",
    "    # output_2 = model.test(idx_test_clean)\n",
    "\n",
    "    accuracy_test_attack_2 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_2 = model.test(idx_test_clean)\n",
    "\n",
    "    print(\"Test accuracy on attack set after attack: \", accuracy_test_attack_2)\n",
    "    print(\"Test accuracy on clean set after attack: \", accuracy_test_clean_2)\n",
    "\n",
    "    ############################ Crypto'Graph defense ###########################\n",
    "    # Perform Crypto'Graph distributed defense\n",
    "\n",
    "    threshold = 2               # threshold for dropping dissimilar edges\n",
    "    metric = \"neighbors\"        # metric for dropping dissimilar edges (neighbors, jaccard, cosine)\n",
    "    object = \"links\"            # object for defense (links, features)\n",
    "\n",
    "    model = TwoPartyCNGCN(dataset=dataset, nfeat=features.shape[1], nhid=16, nclass=labels.max().item() + 1,\n",
    "                            device=device)\n",
    "    model.fit(modified_adj1.copy(), adj2.copy(), features, features, labels, idx_train, threshold, metric=metric, object=object,\n",
    "                train_iters=200, initialize=True, verbose=False, idx_val=idx_val)\n",
    "    model.eval()\n",
    "    accuracies = model.test(idx_test)  #accuracy of the model after the defense on all the test data - (all the nodes)\n",
    "    accuracy_test_attack_3 = model.test(idx_test_attack)\n",
    "    accuracy_test_clean_3 = model.test(idx_test_clean)\n",
    "    print(\"Test accuracy on attack set after Crypto'Graph: \", accuracy_test_attack_3)\n",
    "    print(\"Test accuracy on clean set after Crypto'Graph: \", accuracy_test_clean_3)\n",
    "\n",
    "    # At the end of each repeat, append the accuracy values to the lists:\n",
    "    accuracy_test_attack_1_values.append(accuracy_test_attack_1)\n",
    "    accuracy_test_clean_1_values.append(accuracy_test_clean_1)\n",
    "    accuracy_test_attack_2_values.append(accuracy_test_attack_2)\n",
    "    accuracy_test_clean_2_values.append(accuracy_test_clean_2)\n",
    "    accuracy_test_attack_3_values.append(accuracy_test_attack_3)\n",
    "    accuracy_test_clean_3_values.append(accuracy_test_clean_3)\n",
    "\n",
    "\n",
    "\n",
    "####################### Standard deviation values ############################\n",
    "# Calculate the standard deviation of the accuracy values:\n",
    "accuracy_test_attack_1_std = np.std(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_std = np.std(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_std = np.std(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_std = np.std(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_std = np.std(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_std = np.std(accuracy_test_clean_3_values)\n",
    "\n",
    "# print(\"Standard deviation of test accuracy on attack set 1: \", accuracy_test_attack_1_std)\n",
    "# print(\"Standard deviation of test accuracy on clean set 1: \", accuracy_test_clean_1_std)\n",
    "# print(\"Standard deviation of test accuracy on attack set 2: \", accuracy_test_attack_2_std)\n",
    "# print(\"Standard deviation of test accuracy on clean set 2: \", accuracy_test_clean_2_std)\n",
    "# print(\"Standard deviation of test accuracy on attack set 3: \", accuracy_test_attack_3_std)\n",
    "# print(\"Standard deviation of test accuracy on clean set 3: \", accuracy_test_clean_3_std)\n",
    "\n",
    "# Save the standard deviation values to a file\n",
    "with open('variables_std.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "                 accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "                 accuracy_test_attack_3_std, accuracy_test_clean_3_std], f)\n",
    "\n",
    "\n",
    "####################### Average accuracy values ############################\n",
    "# Calculate the average accuracy values:\n",
    "accuracy_test_attack_1_avg = np.mean(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_avg = np.mean(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_avg = np.mean(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_avg = np.mean(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_avg = np.mean(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_avg = np.mean(accuracy_test_clean_3_values)\n",
    "\n",
    "\n",
    "with open('variables.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "                 accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "                 accuracy_test_attack_3_avg, accuracy_test_clean_3_avg], f)\n",
    "    \n",
    "\n",
    "################################# Plotting Training Results #######################################\n",
    "labels = ['ACCs before attack', 'ACCs before attack', \n",
    "          'ACCs after attack', 'ACCs after attack', \n",
    "          'ACCs after CryptoGraph', 'ACCs after CryptoGraph']\n",
    "values = [accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "          accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "          accuracy_test_attack_3_avg, accuracy_test_clean_3_avg]\n",
    "std_devs = [accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "            accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "            accuracy_test_attack_3_std, accuracy_test_clean_3_std]\n",
    "\n",
    "# Define the x-coordinates of the bars and the width of the bars\n",
    "x = np.arange(len(labels)//2)\n",
    "width = 0.35\n",
    "\n",
    "# Create the bar chart with error bars\n",
    "bars1 = plt.bar(x - width/2, values[::2], width, yerr=std_devs[::2], label='Attack set', color='red', capsize=5)\n",
    "bars2 = plt.bar(x + width/2, values[1::2], width, yerr=std_devs[1::2], label='Clean set', color='blue', capsize=5)\n",
    "\n",
    "# Add a title and labels to the axes\n",
    "plt.title('Average Accuracies')\n",
    "plt.xlabel('Levels of Attack and Defense')\n",
    "plt.ylabel('Average Accuracy')\n",
    "\n",
    "# Make the x-labels vertical\n",
    "plt.xticks(x, labels[::2])\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "# Add exact values on each bar\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "\n",
    "# Adjust the layout to prevent the labels from being cut off\n",
    "plt.tight_layout()\n",
    "# Display the chart\n",
    "plt.show()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# TESTTTTTTT for analysis of the graph and nodes before attack ###############################\n",
    "\n",
    "################################ Data loading #######################################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "dataset = \"polblogs\"\n",
    "# Use the current directory for windows\n",
    "data = Dataset(root='.', name=dataset)\n",
    "#data = Dataset(root='/tmp/', name=dataset): this is for unix-based systems\n",
    "\n",
    "#############################  preprocessing ############################\n",
    "adj, features, labels = data.adj, data.features, data.labels\n",
    "idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "modified_adj =  adj.copy()\n",
    "\n",
    "# Create a NetworkX graph from the adjacency matrix\n",
    "graph = nx.from_scipy_sparse_array(modified_adj)\n",
    "# Add labels to the graph\n",
    "for node_id, label in enumerate(labels):\n",
    "    graph.nodes[node_id]['label'] = label\n",
    "# print(f\"lenght of the labels : {len(labels)}\") \n",
    "print(f\"graph edges : {graph.number_of_edges()}\")\n",
    "print(f\"graph nodes : {graph.number_of_nodes()}\")\n",
    "\n",
    "#########################analysis of the graph and nodes before attack ###############################\n",
    "\n",
    "# all \n",
    "def count_neighbor_labels(graph, labels):\n",
    "    count_dict = {} # dictionary type variable with key: node, and value of: (same_label, opposite_label)\n",
    "    for node in graph.nodes():\n",
    "        neighbors = list(graph.neighbors(node))\n",
    "        same_label = sum(labels[neighbor] == labels[node] for neighbor in neighbors)\n",
    "        opposite_label = len(neighbors) - same_label\n",
    "        count_dict[node] = (same_label, opposite_label)\n",
    "    return count_dict\n",
    "\n",
    "count_dict = count_neighbor_labels(graph, labels)\n",
    "# Sort nodes by the number of same-label neighbors. \n",
    "# x is tuple (node, (same_label, opposite_label)). so x[1][0] is index 0 from the second element of the tuple = same_lable \n",
    "sorted_nodes = sorted(count_dict.items(), key=lambda x: x[1][0], reverse=True) \n",
    "\n",
    "print(f\"Nodes and their same-label and opposite-label neighbors: {count_dict}\")\n",
    "\n",
    "# returns a dict of nodes which have most same label and most opposite labels with the target node\n",
    "def sort_classly(count_dict, labels, target_node):\n",
    "    nodes_class_same = {node: counts for node, counts in count_dict.items() if labels[node] == labels[target_node]}\n",
    "    nodes_class_opp = {node: counts for node, counts in count_dict.items() if labels[node] != labels[target_node]}\n",
    "    sorted_nodes_same = sorted(nodes_class_same.items(), key=lambda x: x[1][0], reverse=True)\n",
    "    sorted_nodes_opp = sorted(nodes_class_opp.items(), key=lambda x: x[1][0], reverse=True)\n",
    "    return sorted_nodes_same, sorted_nodes_opp\n",
    "\n",
    "sorted_nodes_same, sorted_nodes_opp = sort_classly(count_dict, labels, 499)\n",
    "# Print the top 10 nodes for each class\n",
    "print(f\"The most same-label neighbors in same class of label with node {499}: {sorted_nodes_same[:10]}\")\n",
    "print(f\"The most same-label neighbors in class 1: {sorted_nodes_opp[:10]}\")\n",
    "print (f\"label of node is: {labels[671]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# V3: Attack by removing edges + adding edge ###############################\n",
    "################### Attack by removing edges + adding edges: for 10% nodes, for one node, for manually selection of nodes \n",
    "# Define the number of repeats\n",
    "num_repeats = 10\n",
    "accuracy_test_attack_1_values = []\n",
    "accuracy_test_clean_1_values = []\n",
    "accuracy_test_attack_2_values = []\n",
    "accuracy_test_clean_2_values = []\n",
    "accuracy_test_attack_3_values = []\n",
    "accuracy_test_clean_3_values = []\n",
    "\n",
    "################################ Data loading #######################################\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "dataset = \"polblogs\"\n",
    "# Use the current directory for windows\n",
    "data = Dataset(root='.', name=dataset)\n",
    "#data = Dataset(root='/tmp/', name=dataset): this is for unix-based systems\n",
    "\n",
    "for _ in range(num_repeats):\n",
    "    \n",
    "    #############################  preprocessing ############################\n",
    "    adj, features, labels = data.adj, data.features, data.labels\n",
    "    idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
    "\n",
    "    ################### split idx_test into two parts : one node for attack randomley and the rest for clean\n",
    "    # test_size = 1  # 1 node for attack others for test_clean\n",
    "    # idx_test_clean , idx_test_attack = train_test_split(idx_test, test_size=test_size, random_state=42)\n",
    "    # selected_node = idx_test_attack[0]\n",
    "    # print(f\"Selected node for attack: {selected_node}\")\n",
    "    ######################\n",
    "\n",
    "    ############### choose a node for attack manually (the one which has been chosen randomely from idx_test in the previous part)\n",
    "    #selected_node = 1196\n",
    "    # idx_test_attack = np.array([selected_node])\n",
    "    # idx_test_clean = np.array([node for node in idx_test if node != selected_node])\n",
    "    ######################\n",
    "\n",
    "    ################ split idx_test into two parts randomly with a specific ratio %\n",
    "    test_size = 0.10  # 10% for test_attack, 90% for test_clean\n",
    "    idx_test_clean , idx_test_attack = train_test_split(idx_test, test_size=test_size, random_state=42)\n",
    "    ######################\n",
    "\n",
    "    # Split graph into two graphs for Crypto'Graph\n",
    "    proportion_of_common_links = 0.5\n",
    "    adj1, adj2 = split_dataset(adj, proportion_of_common_links) \n",
    "\n",
    "   \n",
    "    # print (\"idx_test_clean\",len (idx_test_clean))\n",
    "    # print (\"idx_test_attack\",len (idx_test_attack))\n",
    "    # print (\"idx_test\",len (idx_test))\n",
    "    # print (\"train\",len (idx_train))\n",
    "    # print (\"val\",len (idx_val))\n",
    "    # print (\"idx_test_clean\",idx_test_clean)\n",
    "    # print (\"idx_test_attack\",idx_test_attack)\n",
    "\n",
    "    ############################ tarin model initially and test accuracy ###########################\n",
    "    # Perform evaluation before attack to find the baseline accuracy\n",
    "\n",
    "    # Train GCN model \n",
    "    # 1. Model definition\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    # 2. Train model - patience= number of epochs to wait before early stopping , train_iters= number of iterations\n",
    "    model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    #model.fit(features, adj, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200,metric=metric,\n",
    "               #object=object, initialize=True, verbose=False )\n",
    "    # 3. Evaluate model\n",
    "    model.eval()\n",
    "    output = model.test(idx_test)\n",
    "\n",
    "    accuracy_test_attack_1 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_1 = model.test(idx_test_clean)\n",
    "    print(\"Test accuracy on attack set: \", accuracy_test_attack_1)\n",
    "    print(\"Test accuracy on clean set: \", accuracy_test_clean_1)\n",
    "\n",
    "    \n",
    "    ################################ Mahsa attack ##############################\n",
    "    # Perform the attack\n",
    "    # version 1: attack on the whole graph - on idx_test_attack nodes - by only removing edges\n",
    "\n",
    "    modified_adj1 =  adj1.copy()\n",
    "\n",
    "    # Create a NetworkX graph from the adjacency matrix\n",
    "    graph = nx.from_scipy_sparse_array(modified_adj1)\n",
    "    # Add labels to the graph\n",
    "    for node_id, label in enumerate(labels):\n",
    "        graph.nodes[node_id]['label'] = label\n",
    "    # print(f\"lenght of the labels : {len(labels)}\") \n",
    "    print(f\"graph edges : {graph.number_of_edges()}\")\n",
    "    print(f\"graph nodes : {graph.number_of_nodes()}\")\n",
    "    \n",
    "    # Set the budget for the attack\n",
    "    budget = 5\n",
    "\n",
    "    #attacked_graph is initially set to graph, and then updated after each attack\n",
    "    # This means that each attack is performed on the graph resulting from the previous attacks.\n",
    "    attacked_graph = graph\n",
    "    count_dict = backdoor.count_neighbor_labels(graph, labels)\n",
    "    for target_node in idx_test_attack:\n",
    "        sorted_nodes_same, sorted_nodes_opp = backdoor.sort_classly(count_dict, labels, target_node)# sort nodes based on the number of same and opposite label neighbors\n",
    "        remove_budget = budget // 2\n",
    "        add_budget = budget - remove_budget\n",
    "        attacked_graph,removed_edges,added_edges = backdoor.add_remove(attacked_graph, target_node, sorted_nodes_same, sorted_nodes_opp, remove_budget, add_budget)\n",
    "            \n",
    "               \n",
    "    print(f\"Removed {len(removed_edges)} edges: {removed_edges}\")\n",
    "    print(f\"Added {len(added_edges)} edges: {added_edges}\")    \n",
    "    \n",
    "    print ( f\"idx_test_attack: {idx_test_attack}\")\n",
    "    neighbors_same_label = backdoor.find_same_neighbor(graph, selected_node)\n",
    "    neighbors_opposit_label = backdoor.find_opposit_neighbor(graph, selected_node)\n",
    "    print ( f\"number of target same label neighbors before attack: {len(neighbors_same_label)}\")\n",
    "    print ( f\"number of target opposit label neighbors before attack: {len(neighbors_opposit_label)}\")\n",
    "    print( f\"idx_test_attack same all over the graph : {len(sorted_nodes_same)}\")\n",
    "    print( f\"idx_test_attack opposit label all over the graph: {len(sorted_nodes_opp)}\")\n",
    "    \n",
    "    neighbors_same_after = backdoor.find_same_neighbor(attacked_graph, selected_node)\n",
    "    neighbors_opposit_after = backdoor.find_opposit_neighbor(attacked_graph, selected_node)\n",
    "    print ( f\"idx_test_attack same label neighbors after attack: {len(neighbors_same_after)}\")\n",
    "    print ( f\"idx_test_attack opposit label neighbors after attack: {len(neighbors_opposit_after)}\")\n",
    "\n",
    "\n",
    "    print ( f\"idx_test_attack same label neighbors: {neighbors_same_label}\")\n",
    "    print ( f\"idx_test_attack opposit label neighbors: {neighbors_opposit_label}\")\n",
    "    print (f\"same label all over graph : (node, (num of same label, num of opposit label)){sorted_nodes_same}\")\n",
    "    print (f\"as above for opposite lables{sorted_nodes_opp}\")\n",
    "    \n",
    "    def is_neighbor(graph, node1, node2):\n",
    "        return graph.has_edge(node1, node2) or graph.has_edge(node2, node1)\n",
    "\n",
    "    is_neighbor = is_neighbor(attacked_graph, 300, 499)\n",
    "    print ( f\"label of target node is: {labels[499]}\")\n",
    "    print ( f\"label of node 300 is: {labels[300]}\")\n",
    "    print ( is_neighbor)\n",
    "\n",
    "    ################################## Plotting target node before attack  #######################################\n",
    "    target_subgraph = graph.subgraph([selected_node] + list(neighbors_same_label) + list(neighbors_opposit_label))\n",
    "    pos = nx.spring_layout(target_subgraph)  # positions for all nodes\n",
    "    # nodes\n",
    "    nx.draw_networkx_nodes(target_subgraph, pos, nodelist=neighbors_same_label, node_color='green')\n",
    "    nx.draw_networkx_nodes(target_subgraph, pos, nodelist=neighbors_opposit_label, node_color='pink')\n",
    "    # edges\n",
    "    nx.draw_networkx_edges(target_subgraph, pos, width=1.0, alpha=0.5)\n",
    "    # labels\n",
    "    nx.draw_networkx_labels(target_subgraph, pos, font_size=16)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "   \n",
    "    # Convert the graph to a CSR matrix\n",
    "    modified_adj1 =backdoor.convert(attacked_graph)\n",
    "    print(attacked_graph)\n",
    "    #print(f\"total removed edges : {(graph.number_of_edges() - attacked_graph.number_of_edges())}\")\n",
    "\n",
    "    ################################ evaluation after attack ##############################\n",
    "    # accuracy after attack\n",
    "    model = GCN(nfeat=features.shape[1], nclass=labels.max().item()+1,\n",
    "                nhid=16, device=device, dropout=0.5)\n",
    "    model = model.to(device)\n",
    "    #data = data.to(device)\n",
    "    model.fit(features, modified_adj1, labels, idx_train, idx_val=idx_val, patience=30, train_iters=200)\n",
    "    model.eval()\n",
    "\n",
    "    # output = model.test(idx_test)\n",
    "\n",
    "    #acc_test = accuracy(output, labels, idx_test)\n",
    "\n",
    "    # output_1 = model.test(idx_test_attack)\n",
    "    # output_2 = model.test(idx_test_clean)\n",
    "\n",
    "    accuracy_test_attack_2 = model.test(idx_test_attack) \n",
    "    accuracy_test_clean_2 = model.test(idx_test_clean)\n",
    "\n",
    "    print(\"Test accuracy on attack set after attack: \", accuracy_test_attack_2)\n",
    "    print(\"Test accuracy on clean set after attack: \", accuracy_test_clean_2)\n",
    "\n",
    "    ############################ Crypto'Graph defense ###########################\n",
    "    # Perform Crypto'Graph distributed defense\n",
    "\n",
    "    threshold = 2               # threshold for dropping dissimilar edges\n",
    "    metric = \"neighbors\"        # metric for dropping dissimilar edges (neighbors, jaccard, cosine)\n",
    "    object = \"links\"            # object for defense (links, features)\n",
    "\n",
    "    model = TwoPartyCNGCN(dataset=dataset, nfeat=features.shape[1], nhid=16, nclass=labels.max().item() + 1,\n",
    "                            device=device)\n",
    "    model.fit(modified_adj1.copy(), adj2.copy(), features, features, labels, idx_train, threshold, metric=metric, object=object,\n",
    "                train_iters=200, initialize=True, verbose=False, idx_val=idx_val)\n",
    "    model.eval()\n",
    "    accuracies = model.test(idx_test)  #accuracy of the model after the defense on all the test data - (all the nodes)\n",
    "    accuracy_test_attack_3 = model.test(idx_test_attack)\n",
    "    accuracy_test_clean_3 = model.test(idx_test_clean)\n",
    "    print(\"Test accuracy on attack set after Crypto'Graph: \", accuracy_test_attack_3)\n",
    "    print(\"Test accuracy on clean set after Crypto'Graph: \", accuracy_test_clean_3)\n",
    "\n",
    "    # At the end of each repeat, append the accuracy values to the lists:\n",
    "    accuracy_test_attack_1_values.append(accuracy_test_attack_1)\n",
    "    accuracy_test_clean_1_values.append(accuracy_test_clean_1)\n",
    "    accuracy_test_attack_2_values.append(accuracy_test_attack_2)\n",
    "    accuracy_test_clean_2_values.append(accuracy_test_clean_2)\n",
    "    accuracy_test_attack_3_values.append(accuracy_test_attack_3)\n",
    "    accuracy_test_clean_3_values.append(accuracy_test_clean_3)\n",
    "\n",
    "\n",
    "\n",
    "####################### Standard deviation values ############################\n",
    "# Calculate the standard deviation of the accuracy values:\n",
    "accuracy_test_attack_1_std = np.std(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_std = np.std(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_std = np.std(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_std = np.std(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_std = np.std(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_std = np.std(accuracy_test_clean_3_values)\n",
    "\n",
    "# Save the standard deviation values to a file\n",
    "with open('variables_std.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "                 accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "                 accuracy_test_attack_3_std, accuracy_test_clean_3_std], f)\n",
    "\n",
    "\n",
    "####################### Average accuracy values ############################\n",
    "# Calculate the average accuracy values:\n",
    "accuracy_test_attack_1_avg = np.mean(accuracy_test_attack_1_values)\n",
    "accuracy_test_clean_1_avg = np.mean(accuracy_test_clean_1_values)\n",
    "accuracy_test_attack_2_avg = np.mean(accuracy_test_attack_2_values)\n",
    "accuracy_test_clean_2_avg = np.mean(accuracy_test_clean_2_values)\n",
    "accuracy_test_attack_3_avg = np.mean(accuracy_test_attack_3_values)\n",
    "accuracy_test_clean_3_avg = np.mean(accuracy_test_clean_3_values)\n",
    "\n",
    "\n",
    "with open('variables.pkl', 'wb') as f:\n",
    "    pickle.dump([accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "                 accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "                 accuracy_test_attack_3_avg, accuracy_test_clean_3_avg], f)\n",
    "    \n",
    "\n",
    "################################# Plotting Training Results #######################################\n",
    "labels = ['ACCs before attack', 'ACCs before attack', \n",
    "          'ACCs after attack', 'ACCs after attack', \n",
    "          'ACCs after CryptoGraph', 'ACCs after CryptoGraph']\n",
    "values = [accuracy_test_attack_1_avg, accuracy_test_clean_1_avg, \n",
    "          accuracy_test_attack_2_avg, accuracy_test_clean_2_avg, \n",
    "          accuracy_test_attack_3_avg, accuracy_test_clean_3_avg]\n",
    "std_devs = [accuracy_test_attack_1_std, accuracy_test_clean_1_std, \n",
    "            accuracy_test_attack_2_std, accuracy_test_clean_2_std, \n",
    "            accuracy_test_attack_3_std, accuracy_test_clean_3_std]\n",
    "\n",
    "# Define the x-coordinates of the bars and the width of the bars\n",
    "x = np.arange(len(labels)//2)\n",
    "width = 0.35\n",
    "\n",
    "# Create the bar chart with error bars\n",
    "bars1 = plt.bar(x - width/2, values[::2], width, yerr=std_devs[::2], label='Attack set', color='red', capsize=5)\n",
    "bars2 = plt.bar(x + width/2, values[1::2], width, yerr=std_devs[1::2], label='Clean set', color='blue', capsize=5)\n",
    "\n",
    "# Add a title and labels to the axes\n",
    "plt.title('Average Accuracies')\n",
    "plt.xlabel('Levels of Attack and Defense')\n",
    "plt.ylabel('Average Accuracy')\n",
    "\n",
    "# Make the x-labels vertical\n",
    "plt.xticks(x, labels[::2])\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "# Add exact values on each bar\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "\n",
    "# Adjust the layout to prevent the labels from being cut off\n",
    "plt.tight_layout()\n",
    "# Display the chart\n",
    "plt.show()                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
